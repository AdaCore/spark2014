\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{xspace}
\usepackage{url}
\usepackage{fullpage}

\newcommand{\version}{0.1}

\title{ALFA v\version:\\Annotated Language of Functions in Ada}

\usepackage{color}

\newlength\sidebar
\newlength\envrule
\newlength\envborder

\setlength\sidebar{1.5mm}
\setlength\envrule{0.4pt}
\setlength\envborder{2.5mm}

\definecolor{exampleborder}{rgb}{0,0,.7}
\definecolor{examplebg}{rgb}{.9,.9,1}
\definecolor{statementborder}{rgb}{.9,0,0}
\definecolor{statementbg}{rgb}{1,.9,.9}

\newsavebox\envbox

\newcounter{example}

\newenvironment{example}[1][EXAMPLE \theexample]{%
\par
\refstepcounter{example}%
\SpecialEnv{#1}{exampleborder}{examplebg}{}{\theexample}%
}{%
\endSpecialEnv
}

\newenvironment{statement}[1][]{% Default statement has no title
\par
\SpecialEnv{#1}{statementborder}{stateme
ntbg}{statementborder}{}%
}{%
\endSpecialEnv
}

\def\Empty{}

% #1 title (if any)
% #2 sidebar (and title bg) color
% #3 background color
% #4 border color (or null for no border)
% #5 Counter, if any.
\newenvironment{SpecialEnv}[5]{%
\par
\def\EnvSideC{#2}% To use later (in end)
\def\EnvBackgroundC{#3}%
\def\EnvFrameC{#4}%
\flushleft
\setlength\leftskip{-\sidebar}%
\addtolength\leftskip{-\envborder}%
\noindent \nobreak
% Check if title is null:
\ifx\delimiter#1\delimiter\else
% If a title is specified, then typeset it in reverse color
\colorbox{\EnvSideC}{%
\hspace{-\leftskip}% usually positive
\hspace{-\fboxsep}%
\footnotesize\sffamily\bfseries\textcolor{white}{#1}%
\hspace{\envborder}}%
\par\nobreak
\setlength\parskip{-0.2pt}% Tiny overlap to counter pixel round-off errors
\nointerlineskip
\fi
% Make side-bar
\textcolor{\EnvSideC}{\vrule width\sidebar}%
% collect body in \envbox:
\begin{lrbox}\envbox
\begin{minipage}{\hsize}%
% insert counter, if any:
\ifx\delimiter#5\delimiter\else
% \theexample. Yannick: i don't like it.
\enspace
\fi
\ignorespaces
}{\par
\end{minipage}\end{lrbox}%
% body is collected. Add background color
\setlength\fboxsep\envborder
\ifx\EnvFrameC\Empty % no frame
\colorbox{\EnvBackgroundC}{\usebox\envbox}%
\else % frame
\setlength\fboxrule\envrule
\addtolength\fboxsep{-\envrule}%
\fcolorbox{\EnvFrameC}{\EnvBackgroundC}{
\usebox\envbox}%
\fi
\nobreak \hspace{-2\envborder}\null
\endflushleft
}

\newcommand{\bnf}[1]{$\mathit{#1}$}
\newcommand{\kw}[1]{\textbf{#1}}
\newcommand{\spark}{$\tau_S$}
\newcommand{\why}{$\tau_W$}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\heap}{\code{Heap}\xspace}
\newcommand{\pred}[1]{\ensuremath{\mathit{pred}(#1)}\xspace}
\newcommand{\allwrites}{$\mathcal{W^+}$\xspace}
\newcommand{\Outallwrites}{\ensuremath{\mathcal{W}^{+out}}\xspace}
\newcommand{\Inallwrites}{\ensuremath{\mathcal{W}^{+in}}\xspace}
\newcommand{\inallwrites}[1]{\ensuremath{\mathcal{W}^{+in}(#1)}\xspace}
\newcommand{\outallwrites}[1]{\ensuremath{\mathcal{W}^{+out}(#1)}\xspace}
\newcommand{\writes}{$\mathcal{W}$\xspace}
\newcommand{\Outwrites}{\ensuremath{\mathcal{W}^{out}}\xspace}
\newcommand{\Inwrites}{\ensuremath{\mathcal{W}^{in}}\xspace}
\newcommand{\inwrites}[1]{\ensuremath{\mathcal{W}^{in}(#1)}\xspace}
\newcommand{\outwrites}[1]{\ensuremath{\mathcal{W}^{out}(#1)}\xspace}
\newcommand{\allreads}{$\mathcal{R^+}$\xspace}
\newcommand{\Outallreads}{\ensuremath{\mathcal{R}^{+out}}\xspace}
\newcommand{\Inallreads}{\ensuremath{\mathcal{R}^{+in}}\xspace}
\newcommand{\inallreads}[1]{\ensuremath{\mathcal{R}^{+in}(#1)}\xspace}
\newcommand{\outallreads}[1]{\ensuremath{\mathcal{R}^{+out}(#1)}\xspace}
\newcommand{\reads}{$\mathcal{R}$\xspace}
\newcommand{\Inreads}{\ensuremath{\mathcal{R}^{in}}\xspace}
\newcommand{\Outreads}{\ensuremath{\mathcal{R}^{out}}\xspace}
\newcommand{\inreads}[1]{\ensuremath{\mathcal{R}^{in}(#1)}\xspace}
\newcommand{\outreads}[1]{\ensuremath{\mathcal{R}^{out}(#1)}\xspace}
\newcommand{\union}{~\cup~}
\newcommand{\bigunion}{~\bigcup~}
\newcommand{\inter}{~\cap~}
\newcommand{\biginter}{~\bigcap~}
\newcommand{\minus}{~\backslash~}

\newcommand{\vpath}[1]{\ensuremath{\pi(#1)}\xspace}
\newcommand{\sel}{\ensuremath{\sigma}\xspace}

\newcommand{\etc}{\textit{etc.}\xspace}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.1in}

\begin{document}

\maketitle
\sloppy

\newpage

\setcounter{tocdepth}{2}
\tableofcontents

\newpage

\section{Ada 2012}

Ada 2012 is the next version of the Ada standard, expected to be finalized in
2012. It contains many extensions that facilitate the expression of
specifications, for either dynamic or static checking.

\subsection{Introduction to Ada}

\subsubsection{Module System}

Programs in Ada are structured in packages, which consist in:
\begin{itemize}
\item a package specification, which defines the external API of the package,
  consisting of types, variables and subprogram declarations whose lifetime and
  visibility are the same as the one of the package itself;
\item an optional package body, which defines the entities declared in the
  package specification, plus additional entities which are not part of the
  external API of the package.
\end{itemize}

The package specification may be divided in a public part and a private part,
so that the private part is visible to the compiler, for use in separate
compilation, but not visible to the external program. Thus, a type may be
declared as having a private definition, so that the compiler knows its precise
definition (size, initialization, etc.) but the program cannot depend on this
definition outside the package.

Packages may be defined in any declarative section: at the outtermost level as
library-level compilation units, or inside other packages and subprogram
bodies. Subprograms too can be defined either as library-level compilation
units, or in local declarative sections. Variables and types can only be
defined in local declarative sections.

Child packages are derived from their parent package with which they have
special visibility relations, which depends on the public/private status of the
child package.

\subsubsection{Type System}

Ada enforces a strong type system by default, although it can be circumvented
by using specific conversion functions (e.g. on addresses), for example to
connect the program to external sensors/actuators.

Integers come in a variety of flavors. New integer types can be defined which
are incompatible, so that type checking uncovers mistakes where different
integer types are mixed, and a subprogram can be overloaded for different
integer types. Subtypes of existing integer types can define a range constraint
which should hold for all initialized values of this subtype, and the compiler
inserts a run-time check anywhere the constraint could be violated. Given a
subtype S of a type T, there exists a base machine type B for both T and S such
that all arithmetic operations on S and/or T are performed in B.  After the
result is computed, it is stored back in a variable of type S or T and the
corresponding range check is performed.

Enumerations define named enumerators which are the only values of this
type. Although pattern-matching is available for all discrete types, it is
mostly used for enumerations. As part of type checking, the compiler checks
that pattern-matching is complete and that no case is redundant.

Floating-point types follow the IEEE-754 standard. Fixed-point types limit the
precision of values to a fixed number of figures.

Aggregate types come in two flavors: records aggregate heterogeneous data
components, while arrays aggregate homogeneous data components. Records may
have one or more discriminants: discriminants of enumerated type are used to
provide a form of algebraic datatypes, as the discriminant is used to provide a
variant distinction between different sets of components; discriminants of
integer type are used to provide dependent types, as the discriminant is used
to give the size of some array component.

Pointer types, a.k.a. access types in Ada, follow a set of somewhat complex
rules to prevent dangling pointer references. In the following, we will mostly
ignore pointers.

The set of non-aggregate types are called elementary types.

\subsubsection{Metaprogramming}

Generic packages and generic subprograms define template entities that are
instantiated at compile-time. They come with a set of formal parameters for
types, variables, values, subprograms and packages. There are individual
constraints on individual formal parameters and relational constraints between
formal parameters, so that once the compiler has checked a generic entity, any
instantiation with correct arguments will generate a compilable entity.

\subsubsection{Object-Oriented Programming}

Classes are known in Ada as tagged (record) types. Objects are values of tagged
types. Methods are known as primitive operations, which can take their
dispatching type in any position. When the first operand is the dispatching
one, the usual object-dot-method notation is allowed for calls.

An object can be considered either of type T, in which case there is no
dispatching involved when calling a primitive operation of T, or of type
T'Class, in which case all primitive operations on this object are dispatching.

Interfaces can be defined which only introduce primitive operations and no
components.

\subsubsection{Calling Conventions}

Parameters of elementary types are passed by copy.  Parameters of tagged type
are passed by reference. For most other parameters, the compiler is free to
choose between by-reference and by-copy.

Parameters have a mode, which can be by default \emph{in} or else \emph{out}
and \emph{in out}:
\begin{itemize}
\item parameters of mode \emph{in} can only be read;
\item parameters of mode \emph{out} can be both read and written: although the
  user indicates by not making them \emph{in out} that he does not intend to
  read their initial values, he should still be able to read their value after
  writing them, so the compiler cannot check in general this data-flow
  property;
\item parameters of mode \emph{in out} can be both read and written.
\end{itemize}

The Ada standard does not rule out aliasing between parameters or between
parameters and global variables accessed directly in general. However, the
standard rules out any possible different behaviors which could arise from the
compiler choosing to pass some parameters by-reference or by-copy, which would
lead to an ambiguous definition of a program. This is a theoretical rule that
the compiler does not try to enforce, although GNAT will generate warnings for
overlapping exported parameters, following the adoption of ``in out'' formal
parameters for functions in Ada 2012.

\subsection{New in Ada 2012}

The standard defines the following extensions to Ada 2005, which facilitate the
expression of specifications as subprogram contracts or type invariants:

\begin{itemize}
\item AI05-0001: bounded containers
\item AI05-0183: aspect specifications
\item AI05-0147: conditional expressions
\item AI05-0188: case expressions
\item AI05-0177: parameterized expressions
\item AI05-0176: quantified expressions
\item AI05-0146: type invariants
\item AI05-0153: subtype predicates
\end{itemize}

While the ARG website is the final authority on these extensions
(http://www.ada-auth.org/AI05-SUMMARY.HTML), we sketch in the following the
semantics and interest of each one.

Bounded containers introduce bounded versions of the existing generic
containers in Ada 2005 container library (vector, list, hashed set, ordered
set, hashed map, ordered map). The bound on the size of the container is used
to preallocate an array of the desired size, so that dynamic allocation is not
used for these containers. This opens up the possibility to perform proofs on
programs using containers, as the validity of cursors is far simpler in this
new model.

Aspect specifications allow defining contracts for subprograms, a contract
being a pair of a precondition (\verb|Pre|) and a postcondition
(\verb|Post|). Special contracts can also be issued for overriding, so that an
overriding subprogram can only weaken the inherited precondition and strengthen
the inherited postcondition. The standard defines a general syntax for aspects
which allows the definition of compiler-specific aspects, like the test-case
aspect in GNAT described below. In the postcondition, attribute \verb|'Old|
applied on a name indicates the value attached to this name at subprogram
entry, and attribute \verb|'Result| applied to the name of the current function
indicates the result returned by this function. Preconditions and
postconditions may be compiled into executable assertions if the right option
is given to the compiler (-gnata in GNAT).

\begin{example}
A contract for a square-root function is:
\begin{verbatim}
function Sqrt (X : Integer) return Integer with
  Pre  => X >= 0,
  Post => Sqrt'Result >= 0 and then
          Sqrt'Result ** 2 <= X and then
          (Sqrt'Result + 1) ** 2 > X;
\end{verbatim}
\end{example}

Conditional expressions and case expressions allow the use of ``if'' and
``case'' in expressions, which simplifies specifications.

Parameterized expressions are a simple form of function definitions (or lambda
expressions) allowed in the specification part of a package. In particular,
simple boolean predicates on accessors to a (private) type, which are typically
the predicates one needs to write subprogram contracts, can be defined as
parameterized expressions. This has the advantage for proofs that parameterized
expressions (contrary to functions) 1) cannot have write side-effects, 2) have
a much simpler form than the usual functions, which is easier to translate into
proof predicates, 3) can be defined in a package specification which makes them
available for proof even if the package body is not.

Quantified expressions allow the expression of predicates which hold for all
elements in a range or a container, or for some element in a range or a
container.

Type invariants express invariant properties of private types, which should be
typically observed for any value of the type outside its package. However, the
standard only defines specific points at which this property is checked on a
value of the type, like entry and exit points of a subprogram. This does not
enforce by itself that the property always holds.

Subtype predicates express fine-grain properties of subtypes, like the various
enumeration values allowed for the discriminant of a record. Like for type
invariants, the standard only defines specific points at which this property is
checked.

\subsection{GNAT-Specific Extensions}
\label{sub:formal-containers}

GNAT defines an aspect called \verb|Test\_Case|, which applies to subprograms
exactly like the standard \verb|Pre| and \verb|Post|. A test-case is an
aggregate with exactly three components, all of which are compulsory:
\begin{enumerate}
\item a \verb|Name| component, of type string, which gives the name of the
  test-case;
\item a \verb|Requires| component, of type boolean, which defines the entry
  condition for the test-case;
\item an \verb|Ensures| component, of type boolean, which defines the exit
  condition for the test-case.
\end{enumerate}

A test-case (N,Req,Ens) is a part of the specification which indicates that
under entry condition Req, the subprogram terminates with condition Ens. Thus,
the \verb|Requires| component bears much resemblance with the precondition, and
the \verb|Ensures| component bears much resemblance with the
postcondition. Indeed, they share the same semantic restrictions
(w.r.t. \verb|'Old| and \verb|'Result|).  More than one test-case can be
defined for a subprogram. No two test-cases on a subprogram should have the
same name.

Contrary to preconditions and postconditions, test-cases are not compiled into
executable assertions by the compiler. GNAT only checks that test-cases are
properly defined. Test-cases should be used by the verification toolkit either
for unit testing or for unit proof.

For unit testing, it is sufficient to write a test procedure which exercises a
test-case to consider this test-case successful. To exercise a test-case, a
test procedure must in order:
\begin{enumerate}
\item generate suitable arguments, by calling one or more subprograms
  called \textit{fixtures};
\item check that the requires is satisfied on these arguments;
\item optionally check that the precondition is satisfied on these arguments;
\item call the subprogram tested on these arguments;
\item optionally check that the postconditions is satisfied on these arguments;
\item check that the ensures is satisfied.
\end{enumerate}

The part about checking the contract of the subprogram is optional because some
test-cases may correspond to cases beyond the normal behavior of the subprogram
described in its contract. Typically, robustness tests deal with such abnormal
behavior.

For unit proof, it is sufficient to prove that the subprogram implements a
special contract, with 1) the requires, optionally and'ed with the original
precondition, as precondition and 2) the ensures as postcondition.  The
original precondition should be and'ed with the requires for those test-cases
which correspond to normal behavior, and the requires should be the only
precondition for those test-cases which correspond to abnormal behavior.

\begin{example}
  A contract with test-cases for an integer square-root function is:
\begin{verbatim}
function Sqrt (X : Integer) return Integer with
  Pre  => X >= 0,
  Post => Sqrt'Result >= 0 and then
          Sqrt'Result ** 2 <= X and then
          (Sqrt'Result + 1) ** 2 > X,
  Test_Case => (Name     => "test case 1",
                Requires => X = 100, 
                Ensures  => Sqrt'Result = 10),
  Test_Case => (Name     => "test case 2",
                Requires => X < 100, 
                Ensures  => Sqrt'Result >= 0 and then 
                            Sqrt'Result < 10),
  Test_Case => (Name     => "robustness test case",
                Requires => X = -1, 
                Ensures  => Sqrt'Result = 0);
\end{verbatim}
\end{example}

GNAT introduces a new form of containers called the formal containers, to be
used for proof of programs which manipulate containers. These are variants of
Ada 2012 bounded containers, with a different API meant to facilitate proofs.

\section{ALFA}

ALFA is a sub-language of Ada 2012 which identifies which subprograms are fit
for formal verification. ALFA is not a profile, as defined in the Ada standard,
as the complete program does not need to be in ALFA for individual subprograms
to be in ALFA. Rather, subprograms are in ALFA or not depending exclusively on
their specification and body. In particular, the location in the source where a
subprogram is defined (inside a package or another subprogram, in the public or
private part, \etc) should not influence whether it is in ALFA.

ALFA is expected to be extended to support more Ada programs, the current
version described in this document is version \version.

\subsection{ALFA Extensions}

In ALFA, the pragma Assert immediately at the start of a loop body has a
special meaning. It defines a loop-invariant for this loop, which is used for
unit proof.

\begin{example}
  The following implementation of the integer square-root function has a
  loop-invariant:
\begin{verbatim}
function Sqrt (X : Integer) return Integer is
   Res, Two_Res, Res_Square : Integer := 0;
begin
   while Res_Square <= X loop
      pragma Assert (Res >= 0 and then
                     Two_Res = 2 * Res and then
                     Res_Square = Res * Res);
      Res_Square := Res_Square + Two_Res + 1;
      Two_Res    := Two_Res + 2;
      Res        := Res + 1;
  end loop;
  return Res - 1;
end Sqrt;
\end{verbatim}
\end{example}

The loop-invariant to be used for unit proof should be 1) true the first time
the loop is entered and 2) provable from assuming it at some previous iteration
through the loop and examining the effect of the loop body.

\subsection{ALFA Restrictions}

In the following, we refer to entities in the program with the name of the
corresponding non-terminal in the Ada BNF, like \bnf{subprogram\_body} for a
subprogram body. As a general rule, an entity is in ALFA only if all the
sub-entities which define it are in ALFA. As an example, a
\bnf{subprogram\_body} is defined in Ada BNF as:

\hspace*{1cm}\bnf{subprogram\_body} ::=\\
\hspace*{2cm}\lbrack\bnf{overriding\_indicator}\rbrack\\
\hspace*{2cm}\bnf{subprogram\_specification} is\\
\hspace*{3cm}  \bnf{declarative\_part}\\
\hspace*{2cm}  begin\\
\hspace*{3cm}    \bnf{handled\_sequence\_of\_statements}\\
\hspace*{2cm}  end \lbrack\bnf{designator}\rbrack;\\

Thus, a \bnf{subprogram\_body} is in ALFA only if the following are in ALFA:
\begin{itemize}
\item its \bnf{overriding\_indicator} (if present);
\item its \bnf{subprogram\_specification};
\item its \bnf{declarative\_part};
\item its \bnf{handled\_sequence\_of\_statements};
\item its \bnf{designator} (if present).
\end{itemize}

This general rule applies individually to all production rules in the BNF
which define program entities. Thus, some production rules defining a
non-terminal may be in ALFA while others for the same non-terminal are not in
ALFA.

The additional rules below further restrict which entities are in ALFA. These
rules build on the report written by Marc Sango for his internship on the
definition of a verification profile for Ada~\cite{Sango2010RR}. 

\subsubsection{Lexical Elements}

ALFA only supports the Latin-1 Character Set, not the full Universal Character
Set (ISO/IEC 10646:2003) supported by Ada.

Based forms of real literals are not in ALFA.

[what about pragmas?]

\subsubsection{Declarations}

All entities related to access types are not in ALFA:
\begin{itemize}
\item the \bnf{aliased} keyword, wherever it appears;
\item \bnf{access\_type\_definition};
\item \bnf{access\_to\_object\_definition};
\item \bnf{general\_access\_modifier};
\item \bnf{access\_to\_subprogram\_definition};
\item \bnf{null\_exclusion};
\item \bnf{access\_definition}.
\end{itemize}

All entities related to fixed-point types are not in ALFA:
\begin{itemize}
\item \bnf{fixed\_point\_definition};
\item \bnf{ordinary\_fixed\_point\_definition};
\item \bnf{decimal\_fixed\_point\_definition};
\item \bnf{digits\_constraint};
\item \bnf{delta\_constraint}.
\end{itemize}

Notice that this rules out the type cursor in Ada 2005 containers and Ada 2012
containers, as it contains a pointer to the underlying container. The formal
containers as described in Section~\ref{sub:formal-containers} define cursors
that are in ALFA. Although the complete definition of formal containers may not
be in ALFA by the rules described here, they are specially included in ALFA as
a whole.

All entities related to interfaces are not in ALFA:
\begin{itemize}
\item \bnf{interface\_type\_definition};
\item \bnf{interface\_list}.
\end{itemize}

[what about \bnf{aspect\_clause} in \bnf{component\_item}?]\\

Note in particular that a \bnf{default\_expression} in a
\bnf{component\_declaration} is allowed, as well as a \bnf{variant\_part} in
a \bnf{component\_list}.

\subsubsection{Names and Expressions}

An \bnf{identifier} or a \bnf{name} which has a corresponding declaration is in
ALFA if-and-only-if its declaration is in ALFA. As a consequence, a call is in
ALFA only if the declaration of the subprogram called is in ALFA. 

[what about \bnf{aspect\_clause} in \bnf{basic\_declarative\_item}?]

All entities related to access types are not in ALFA:
\begin{itemize}
\item \bnf{explicit\_dereference};
\item \bnf{implicit\_dereference};
\item the \bnf{Access} terminal defining an \bnf{attribute\_designator};
\item the \bnf{null} terminal defining a \bnf{primary};
\item \bnf{allocator}.
\end{itemize}

Operations \bnf{and}, \bnf{or} and \bnf{xor} on Boolean arguments are not in
ALFA. The same operations on arrays of Boolean elements are in ALFA.  Only the
lazy operations \bnf{and\ then} and \bnf{or\ else} on Boolean arguments are 
in ALFA.

Quantified expressions are in ALFA only if they appear in predicate position,
that is, at the top-level of the boolean structure of an expression used in
assertions.

\begin{example}
\label{ex:alfa-quantifiers}
The following quantified expression appearing in predicate position is in ALFA:
\begin{verbatim}
procedure P with Pre => (for all X in Index => Prop (X));
\end{verbatim}

The following quantified expression appearing in term position is not in ALFA:
\begin{verbatim}
procedure P with Pre => if (for all X in Index => Prop (X)) then Y;
\end{verbatim}

The following quantified expression appearing in program position is not in
ALFA:
\begin{verbatim}
B : Boolean := (for all X in Index => Prop (X));
\end{verbatim}
\end{example}

Additionally, an expression in ALFA which appears as part of an assertion
cannot contain calls to functions. Instead, it may contain contain calls to
parameterized expressions. A precondition, a postcondition, a type invariant or
a subtype predicate count as assertions.

\subsubsection{Statements}

\bnf{goto\_statement} is not in ALFA.

Note in particular that all possible \bnf{exit\_statement} are in ALFA,
including those which exit an outter loop.

\subsubsection{Subprograms}

A subprogram may have both a \bnf{subprogram\_declaration} and a
\bnf{subprogram\_body}. Such a subprogram is in ALFA only if both its
declaration and body are in ALFA. Additionally, the subprogram should have a
postcondition attached to its declaration. The requirement that a subprogram
has a postcondition ensures that the user states desired properties to prove on
this subprogram, and that callers can rely on a precise indication of what this
subprogram does. Of course, such a postcondition can be simply \verb|True| in
which case the user chooses not to give any more precise information.

\bnf{extended\_return\_statement} is not in ALFA.

\subsubsection{Package Specifications and Declarations}

No special rules. In particular, renamings and the optional statements in a
package body are in ALFA.

\subsubsection{Use Clauses}

No special rules.

\subsubsection{Tasks and Synchronisation}

Most probably, the same restrictions as in RavenSPARK should be enforced for
the sequential verification results to apply to concurrent code.

\subsubsection{Program Structure and Compilation Issues}

No special rules.

\subsubsection{Exceptions}

All entities related to exception handling are not in ALFA:
\begin{itemize}
\item \bnf{exception\_handler};
\item \bnf{choice\_parameter\_specification};
\item \bnf{exception\_choice}.
\end{itemize}

However, defining exceptions and raising exceptions are in ALFA.

\subsubsection{Generic Units}

No special rules.

\subsubsection{Representation Issues}

[To be discussed.]

\section{Formal Verification}
\label{sec:formal-verification}

We target three types of formal verification goals:
\begin{enumerate}
\item Data-flow verification (DFV) ensures that there are no reads of
  uninitialized data, and that there is no possible unintended aliasing.
\item Contract verification (CV) ensures that subprograms respect their
  contract.
\item Verification of absence of run-time errors (RTE) ensures that subprograms
  are free from most types of run-time errors.
\end{enumerate}

All of data-flow verification, contract verification and verification of
absence of run-time errors can be performed independently. However, there is a
natural ordering which arises from the logical dependencies between them: 
\begin{center}
  DFV $<$ CV $<$ RTE
\end{center}

Indeed, the results of CV are valid only if DFV is verified, and the results of
RTE are valid only if DFV and RTE are verified. In practice, this means that
DFV, CV and RTE should be usually performed in this order.

On the one hand, both CV and RTE depend on contracts and intermediate
assertions (loop-invariants and other assertions). For example, loop-invariants
usually contain information on the range of values, which are both used for
proving absence of run-time error and functional properties. Thus, contracts
and intermediate assertions should be assumed for RTE. On the other hand,
proving contracts and intermediate assertions can be performed without assuming
absence of run-time errors. Indeed, what is proved in this case is that,
provided there are no run-time errors, the contracts and intermediate
assertions hold.

It should be possible to perform CV and RTE independently, first because the
user may be interested in only one of these, second because we will aim at CV
principally through Why and RTE principally through SPARK.

\subsection{Data-Flow Verification (DFV)}
\label{sub:DFV}

Data-flow verification should be performed as a static analysis, similar to
what the Examiner does for SPARK code. However, we aim at finer-grain data-flow
verification than the one provided in SPARK. Instead of considering entire
variables, we consider components of aggregate variables as the elementary
entities whose initialization should be tracked.

\begin{example}
\label{ex:component-init}
  The following is not allowed in SPARK, as \verb|Zero_X| and \verb|Zero_Y|
  only initialize part of a \verb|Point|. It should be allowed in ALFA.
\begin{verbatim}
type Point is record X, Y : Val; end record;
procedure Zero_X (P : in out Point) is begin P.X := 0; end Zero_X;
procedure Zero_Y (P : in out Point) is begin P.Y := 0; end Zero_X;

procedure Zero (P : out Point) is
begin
   Zero_X (P); Zero_Y (P);
end Zero;
\end{verbatim}
\end{example}

We draw a distinction between external subprograms and internal
subprograms. External subprograms are those subprograms for which we do not
know all the calling contexts, such as library-level subprograms, either
defined as such or declared inside library-level package
specifications. Internal subprograms are subprograms for which we do know all
the calling contexts, such as local subprograms whose address is not taken.
Data-flow verification of external subprograms in ALFA should assume that all
parameters and globals read are initialized at subprogram entry, and it should
check that the subprogram initializes the parameters and globals written on all
syntactic program paths. Data-flow verification of internal subprograms should
do the same at the component level.

\begin{example}
  Data-flow verification on \verb|Zero_X| and \verb|Zero_Y| as defined in
  Example~\ref{ex:component-init} should succeed if they are defined as
  internal subprograms, and fail if they are defined as external subprograms.
  Data-flow verification on \verb|Zero| should succeed in both cases.
\end{example}

Reads of components of local variables are only allowed if all syntactic paths
through the subprogram before reaching the read do initialize completely the
corresponding component which is read. This restriction is similar to the SPARK
one, except that it applies to components of variables instead of entire
variables.

[need expansion of what is a data-flow error, regarding useless computations]

Aliasing between parameters and globals accessed by a subprogram is forbidden,
unless all aliasing parameters and globals are read. This restriction is
similar to the SPARK one.

\subsection{Contract Verification (CV)}

The contract of a subprogram in ALFA is verified by assuming that the
subprograms it calls do respect their contracts, which includes a possible
recursive call (in which case the assumption is made only for the recursive
call). For the purpose of contract verification, possible run-time errors are
ignored, both in the program and in the contracts. Thus, the results of
contract verification hold for all executions which do not raise a run-time
error.

As part of CV, all intermediate assertions and loop-invariants are also
proved. This includes the contracts, intermediate assertions and
loop-invariants that are useful to prove absence of run-time errors, if RTE is
also an objective.

\subsection{Verification of Absence of Run-Time Errors (RTE)}

Verifying that a subprogram in ALFA is free from run-time errors is verified by
assuming that the subprograms it calls do respect their contracts and that they
are free from run-time errors, which includes a possible recursive call (in
which case the assumption is made only for the recursive call).

RTE includes proving that the evaluation of assertions (including contracts and
loop-invariants) does not lead to run-time errors. To that end, the checks
inserted by the compiler to prove absence of runt-time error should be proved.

\begin{example}
  Proving RTE on the procedure \verb|Do_Something_On_Array| involves proving
  that evaluating its postcondition cannot lead to a run-time error:
  \verb|I + J| and \verb|A(I) + A(J)| should not overflow; \verb|I|, \verb|J|
  and \verb|I + J| should be allowed indexes for \verb|A|. Proving RTE on a
  caller of procedure \verb|Do_Something_On_Array| involves proving that
  evaluating its precondition cannot lead to a run-time error: \verb|I| and
  \verb|J| should be allowed indexes for \verb|A|.
\begin{verbatim}
procedure Do_Something_On_Array (A : My_Array; I, J : Index) with
   Pre  => A(I) /= A(J),
   Post => A(I + J) = A(I) + A(J);
\end{verbatim}
\end{example}

Although SPARK already generates VCs for absence of run-time errors on the
subset of Ada it defines, we will not use these capabilities directly. Instead,
we will rely on the compiler to insert the proper checks, which translate in
SPARK as assertions, for which it also generate VCs. The benefits of this
approach are that 1) the compiler controls which run-time checks should be
proved, which can be modified on option, and reduced to fewer checks if the
compiler is able to prove some of them (typically for checks that deal with
type checking constraints); 2) the same process applies to checks that SPARK
would generate and checks that SPARK does not know about, because they
originate in language constructs that are not in SPARK; 3) the same checks are
generated whatever the proof chain used, through SPARK or through Why.

\subsection{Verification Modes}

CV and RTE require different (although compatible) choices during the
translation.  Therefore, we define three modes for the translation:
\begin{enumerate}
\item mode CV for contract verification;
\item mode RTE for verification of absence of run-time errors;
\item mode CV+RTE for combined contract verification and verification of
  absence of run-time errors.
\end{enumerate}

In all three modes, the only part of the program which is translated
differently is the logic part, having to do with the translation of
assertions. Modes CV and RTE both insert different assertions, which means that
more reads are performed, thus putting more constraints on the data-flow in
terms of non-aliasing and initialization. Thus, it is sufficient to prove DFV
in mode CV+RTE for data-flow to be verified in both modes CV and RTE. Hence DFW
should be performed in mode CV+RTE.

\section{Translation to SPARK/Why}

A subprogram in ALFA should be translated into an intermediate representation
in SPARK or in Why. From this representation, the Examiner or Why tools can
generated Verification Conditions (VCs) to prove using an automatic prover.  In
order to facilitate fine-grain modular proof, each subprogram should lead to
the generation of a separate unit (package in SPARK, module in Why), which can
be proved independently. Notice that the generated SPARK is not executable, and
does not match in general the structure of the source Ada program, even if this
program is written in the SPARK subset of Ada. Ideally, the generated SPARK
should correspond to a simple subset of SPARK (for example no need for
visibility rules in this subset as everything is public). Thus, it should be
easier to formalize this subset and prove the correctness of transformations or
analyzes on this subset if needed.

\subsection{Introduction to SPARK/Why}

\subsubsection{Common Basis of SPARK and Why}

SPARK and Why are both programming languages designed for deductive
verification, more than execution. They both mix coding constructs with logic
constructs whose aim is to state invariant properties of the program.

The central logic construct is the contract, which serves to fully describe the
effect of calling a subprogram, for the purpose of separate verification. Each
subprogram in SPARK/Why must be defined with a proper contract:
\begin{enumerate}
\item a precondition describes constraints on the calling context;
\item a frame condition describes both the variables on which the result of the
  subprogram depends (variables read) and the variables which may be modified
  as a result of the call (variables written);
\item a postcondition describes constraints on the result of the subprogram.
\end{enumerate}

Both SPARK and Why define references which are used to pass parameters to
subprogram calls. None defines pointer types. Both SPARK and Why define static
rules to check that the only parameters and globals (mentioned in the frame
condition) which may be aliased are those which are only read.

Both languages come equipped with a verification condition generator (VCGen)
which produces formulas which should be proved (automatically or manually) for
the contracts expressed on the SPARK or Why code to hold. The VCGen for Why is
the Why tool; it can produce VCs in a variety of languages, among which Why
itself and SMTLIB format.  The VCGen for SPARK is the Examiner; it produces VCs
in FDL, which can be translated by the ViCToR tool into a variety of languages,
among which SMTLIB format.

\subsubsection{SPARK Specificities}

SPARK code, when stripped from its logic constructs, is a subset of
Ada. Thus, SPARK inherits many constructs of Ada, and it is of course
executable.

SPARK enforces strict data-flow properties, that are checked statically by the
Examiner tool:
\begin{itemize}
\item to read any part of a variable, the entire variable must be initialized
  on all syntactic program paths from the start of the current subprogram to
  the program point where the read is performed;
\item a parameter of mode ``in'' or ``in out'' in a call counts as a read;
\item every parameter of mode ``out'' in the current subprogram must be
  initialized on all syntactic program paths from the start of the subprogram
  to the end of the subprogram;
\item every parameter of mode ``in'' or ``in out'' in the current subprogram
  must be partially read on at least one syntactic program path from the start
  of the subprogram to the end of the subprogram;
\item global variables mentioned in the frame condition must respect the same
  constraints as parameters.
\end{itemize}

Essentially, these data-flow properties enforce a programming discipline which
ensures that there is no read of an uninitialized value anywhere in the
program, and which the Examiner checks statically.  As part of the same static
analysis, the Examiner also issues errors if some variables or statements are
unused.

As SPARK is a subset of Ada, it knows all about the possible run-time errors in
this subset, and it generates VCs guarding against such errors.

\subsubsection{Why Specificities}

Why is a functional language with imperative features, of an OCaml flavor. Why
allows mixing freely axiomatized entities and defined entities, which means
that Why programs cannot be executed.

Why defines four primitive types:
\begin{itemize}
\item \emph{int} for mathematical integers;
\item \emph{bool} for Booleans;
\item \emph{real} for mathematical real numbers;
\item \emph{unit} for the type of statements.
\end{itemize}

There are no predefined aggregate types (records and arrays) in Why. In
general, these should be defined as abstract types and axiomatized. In this
respect, Why is closer to the translation in FDL of SPARK data structures than
to SPARK itself. However, Why provides a definition for functional arrays in
its prelude (its automatically loaded standard library), and a predefined type
array acting as a mutable reference on functional arrays. This type is
polymorphic, so that it can be instantiated to define arrays over whatever
element type.

Why also provides algebraic types which allow defining enumerations, LISP-like
lists, discriminated unions, \etc, together with pattern-matching expressions
(the equivalent of Ada case-statements and case-expressions) on algebraic
types~\cite{Paskevich09RR}.

Why distinguishes between logic and programs, and between terms and predicates
in the logic. For example, a quantification is of type \verb|prop| which is
different from the Boolean type for terms \verb|bool|.

\subsection{Generation of Contracts}

In contract-based verification, a subprogram body is verified independently
from other subprograms, by relying on subprogram contracts only to assess the
effect of calls. Thus, it is crucial that subprogram contracts are precise. In
particular, the frame condition which is not present in the source Ada code
needs to be generated as precisely as possible. Thus, we aim at generating
frame conditions which distinguish between components of variables, so that a
read of component \verb|X| of variable \verb|V| does not count as a read of
all the components of variable \verb|V|.

\begin{example}
Consider a procedure which sets a field of an element of an array of points:
\begin{verbatim}
type Point is record X, Y : Val; end record;
type Points is array (Index) of Point;

procedure Set_X_Of_Nth (P : in out Points; V : Val; N : Index) with
  Post => P(N).X = V;
\end{verbatim}

The postcondition of \verb|Set_X_Of_Nth| only says something about the value of
\verb|P(N).X| in the post-state. It says nothing about the value of
\verb|P(N).Y|, or the value of \verb|P(M).X| and \verb|P(M).Y| for some
\verb|M| different from \verb|N|.\\

The only way to add this information in Ada is to explicitly state in the
postcondition that these other values have not changed:
\begin{verbatim}
  Post => P(N).X = V and then P(N).Y = P(N).Y'Old and then
          (for all M in Index => 
             (if M /= N then P(M).X = P'Old(M).X)) and then
          (for all M in Index => 
             (if M /= N then P(M).Y = P'Old(M).Y));
\end{verbatim}

This detailed postcondition is needed if we generate in SPARK/Why an imprecise
frame condition which only says that array \verb|P| is written. But if we
generate a more precise frame condition saying that only field \verb|X| of an
element of \verb|P| is written, then the postcondition is Ada can be reduced,
because it is known in SPARK/Why that no field \verb|Y| has changed:
\begin{verbatim}
  Post => P(N).X = V and then
          (for all M in Index => 
             (if M /= N then P(M).X = P'Old(M).X));
\end{verbatim}
\end{example}

The frame condition of a valid SPARK/Why subprogram needs to indicate
explicitly which parameters and global variables can be read and/or written
during the execution of this subprogram. In order to distinguish between
variable components at the Ada level, each variable component must be
translated into a different parameter or global variable in the SPARK/Why
program; and the generation of the frame condition should be precise at the
variable component level.

As the frame condition must account for direct and indirect accesses, through
any number of calls, this global information must be retrieved by performing a
global analysis on the closed set of subprograms called directly and
indirectly.

A special global variable called \heap represents all the dynamically allocated
memory plus all variables whose address is taken, so that reads and writes to
dynamically allocated memory show in SPARK or Why contracts as reads and writes
to \heap. Notice that without this \heap variable, contracts would be wrong and
break the consistency of the proof system. 

\begin{example}
  If reads and writes to \heap were not computed, it would be possible to prove
  that \verb|Problem| below always returns \verb|True|, because \verb|Set|
  would be seen as a noop, and \verb|Get| would be seen as a constant function:

\begin{verbatim}
X : access Integer;

procedure Set is X.all := 0; end Set;
function Get return Integer is (X.all);

function Problem return Boolean is
   X1 : Integer := Get;
begin
   Set;
   return X1 = Get;
end Problem;
\end{verbatim}
\end{example}

Contracts (precondition and postcondition) in SPARK/Why have a
slightly different semantics than contracts in Ada 2012, because contracts in
SPARK/Why completely ignore the possibility of a run-time error being
raised while evaluating the contract. When checking for absence of run-time
errors (which can be separated from contract checking), the absence of run-time
errors in contracts should also be proved, which requires the extension of
contracts with additional conjuncts in SPARK/Why. 

\begin{example}
  The following contract in Ada:
\begin{verbatim}
function Get (A : My_Array; X : Integer) return Element
   with Pre => A (X) /= Nil_Element;
\end{verbatim}

is equivalent to the following contract in SPARK:
\begin{verbatim}
function Get (A : My_Array; X : Integer) return Element;
--# pre X in My_Array'Range and then A (X) /= Nil_Element;
\end{verbatim}
\end{example}

\subsection{From Ada to Unambiguous Ada}

Ada functions may write global variables, so that the compiler choice of
evaluation order for expressions may influence the result. Whatever it is, this
choice should be the same for execution and verification, which is obtained by
lifting function calls outside of expressions in the specified order of
evaluation. This consists in a simple walk through the AST following the order
of evaluation, and introducing temporary variables for every function
call. 

\begin{example}
  With a left-to-right evaluation order, the statement
\begin{verbatim}
X := F(X) + G(H(Y),K(Z));
\end{verbatim}
  should be translated into:
\begin{verbatim}
Tmp1 := F(X);
Tmp2 := H(Y);
Tmp3 := K(Z);
Tmp4 := G(Tmp2,Tmp3);
X := Tmp1 + Tmp4;
\end{verbatim}
\end{example}

To simplify further passes, array concatenation \verb|&| should be replaced at
this stage by equivalent concatenation functions, and treated as such.

Likewise, Ada arithmetic expressions may be reordered by the compiler when not
enough parenthesized, so the translation will introduce the necessary
parentheses which force the natural evaluation order given by operators
associativity. 

\begin{example}
  The expression \verb|X + Y + Z| should be translated into \verb|(X + Y) + Z|.
\end{example}

\subsection{From Unambiguous Ada to Expanded Ada}

This translation should be different for CV and RTE. It is based on the
expansion phase in the GNAT front-end which will simplify the work needed in
subsequent phases:
\begin{itemize}
\item it unfolds all aggregate initializations;
\item it makes all checks for run-time errors explicit;
\item it removes renamings;
\item \etc [add some more here]
\end{itemize}

In particular, types which depend on some dynamic bounds should be translated
into types with static bounds, by creating additional variables to hold the
dynamic bounds. Then, the run-time checks should mention these dynamic bounds.
This concerns discrete subtypes with dynamic bounds and array types with
dynamic bounds. Parameters of array type with dynamic bounds should be
translated into three parameters: one for the array and two for the bounds.

Whenever a subprogram has an in-variable of such a type with dynamic bounds, an
additional precondition should be generated stating that the variable is within
bounds.  Whenever a subprogram has an out-variable of such a type with dynamic
bounds, an additional postcondition should be generated stating that the
variable is within bounds.

Each discriminant of a record type should be translated into a normal
component. When this discriminant controls a variant, all components of the
different cases should be added as components of the record. When this
discriminant controls the size of an array, this array component should be
translated like an array with dynamic bounds.

Declarations of generic entities should be instantiated for each generic
instantiation in the program. Bodies of generic entities should be kept not
instantiated, so that each generic body is verified only once.

\subsection{Computing the Frame Condition}
\label{sub:data-flow}

\subsubsection{Variable Paths}
\label{sub:variable-path}

A variable in ALFA may only have a scalar type (discrete or real) or an
aggregate type (record or array) such that all sub-components have themselves a
scalar type or an aggregate type with the same restriction. Given a variable
$v$ in ALFA, we associate a set of paths \vpath{v} to $v$. More generally, we
associate a set of paths \vpath{v} to an individual path $v$ (which may be a
variable) as follows:
\begin{itemize}
\item if $v$ has a scalar type, $\vpath{v} = \{v\}$;
\item if $v$ has a record type with components $c_i$, 
  $\vpath{v} = \bigunion \vpath{v.c_i}$;
\item if $v$ has an array type whose element type $t$ is a scalar type,
  $\vpath{v} = \{v\}$;
\item if $v$ has an array type whose element type $t$ is a record type with
  components $c_i$, $\vpath{v} = \bigunion \vpath{v.c_i}$. (Here, we do as if $v$
  was of type $t$ so that we can refer to its $c_i$ components.)
\end{itemize}

\begin{example}
  On the following code, the set of paths of \verb|X| is: \verb|X.B.J|,
  \verb|X.B.K|, \verb|X.A.J|, \verb|X.A.K|.

\begin{verbatim}
type Base is record 
  J : Integer;
  K : Integer range 0 .. 5;
end record;
type Base_Array is array (Boolean) of Base;
type Ext is record 
  B : Base;
  A : Base_Array;
end record;
X : Ext;
\end{verbatim}
\end{example}

A path is a sequence of selectors $\sel_1.\sel_2...\sel_n$.  If any selector
$\sel_i$ on the path refers to an array, we say that the path is an array
path. Otherwise, we say that the path is a record path. A record path refers to
a single value of scalar type, while an array path usually refers to more than
one value of scalar type.
 
\subsubsection{Problem Statement}

For the purpose of data-flow verification, we consider a package body as a
special form of subprogram, where the body of the subprogram is given by the
various initializations performed in the declarations of variables, as well as
the optional sequence of statements.

A data-flow analysis of the source Ada program should associate each subprogram
with three sets of variables paths:
\begin{itemize}
\item the read-set of variable paths possibly read by the subprogram;
\item the write-set of variable paths alway written by the subprogram;
\item the read-write-set of variable paths possibly read and written by
  the subprogram.
\end{itemize}

Note that a variable path which is always written by the subprogram before
being read, so that the initial value of the variable path is never read,
belongs to the write-set, not the read-write-set.

A special global variable called \heap represents all the dynamically allocated
memory plus all variables whose address is taken.

The algorithm should compute various maps from program points $p$ to sets of
(local and global) variable paths:
\begin{itemize}
\item \writes stores variable paths completely written on all program paths
  to $p$;
\item \allwrites stores variable paths partially written on some program
  path to $p$;
\item \reads stores variable paths whose initial value at subprogram entry has
  been partially read on some program path to $p$;
\item \allreads stores variable paths partially read on some program path to
  $p$.
\end{itemize}

As \reads depends on \writes which depends on \allreads, \allreads should be
computed first, then \writes, then \reads. \allwrites can computed at any time, as it is independent from the other maps.

As \writes, \allwrites, \reads and
\allreads take program entities as parameters, they are decomposed into
(\Inwrites,\Outwrites), (\Inallwrites,\Outallwrites), (\Inreads,\Outreads) and
(\Inallreads,\Outallreads) respectively, where the ``in'' part describes the
program point immediately before the entity and the ``out'' part describes the
program point immediately after the entity.

In the following, we give data-flow equations defining each one of \writes,
\allwrites, \reads and \allreads. These equations provide an algorithm for
computing the sets, and since the sets only grow, the algorithm necessarily
reaches a fixpoint and terminates. Note that \writes, \allwrites, \reads and
\allreads should only contain global variables when applied to subprograms
(local variables are removed in this case).

The control-flow graph of a subprogram allows defining for each statement $s$
the set of its predecessor statements \pred{s}.

\subsubsection{Computing \allwrites}

There are two sources of partial writes: assignment statements and calls. A
statement $s$ partially writes a variable path $w$ in the following cases:
\begin{itemize}
\item $s$ is an assignment statement to $w$;
\item $s$ is an assignment statement through a dereference, and $w$ is \heap;
\item $s$ contains a call to a subprogram $f$, and $w \in \outallwrites{f}$.
\end{itemize}

Given a statement $s$ partially writing variable path $w$, the following
equations define \allwrites:
\begin{eqnarray*}
\outallwrites{s} &=& \inallwrites{s} \union \{w\}\\
\inallwrites{s} &=& \bigunion \outallwrites{\pred{s}}
\end{eqnarray*}

\subsubsection{Computing \allreads}

There are two sources of reads: expressions and calls. A statement $s$
partially reads a variable path $r$ in the following cases:
\begin{itemize}
\item $s$ contains an occurence of $r$ that does not count as write, as
  described above;
\item $s$ contains a dereference that does not count as write, as described
  above, and $r$ is \heap;
\item $s$ contains a call to a subprogram $f$, and $r \in \outallreads{f}$.
\end{itemize}

Notice that an expression used to define the dynamic bounds of a subtype counts
as a read of any variable path occurring in this expression.

Given a statement $s$ partially reading variable paths $r_i$, the following
equations define \allreads:
\begin{eqnarray*}
\inallreads{s} &=& \bigunion \outallreads{\pred{s}}\\
\outallreads{s} &=& \inallreads{s} \union \{r_i\}
\end{eqnarray*}

\subsubsection{Computing \writes}

There are two natural sources of complete writes: assignment statements and
calls. A statement $s$ completely writes a global variable path $w$ in the
following cases:
\begin{itemize}
\item $s$ is an assignment statement to $w$, and $w$ is a record path;
\item $s$ contains a call to a subprogram $f$, and $w \in \outwrites{f}$.
\end{itemize}
Additionally, if $l_1$ is a loop and $w$ a variable path such that:
\begin{enumerate}
\item there is a set of loops $l_1...l_n$ such that each $l_i$ ranges over the
  set of indexes of an array selector in $w$, and there is one loop for every
  array selector;
\item for all $i$, $l_i$ contains
  $l_{i+1}$ as a statement in its outter sequence of statements;
\item $l_1$ does not contain any exit statement (even in inner loops);
\item $w \notin \outallreads{l_1}$;
\item $l_n$ contains a statement assigning to $w$, where all indexes used for
  array accesses are exactly all the loop variables;
\end{enumerate}
then loop $l_1$ completely writes variable path $w$.

The aim of this special rule for loops is to allow the initialization of array
paths through loops, which is both common in user code and which arises as a
result of expansion, in particular due to default expressions for record
components.

Given a statement $s$ completely writing variable paths $w$, the following
equations define \writes:
\begin{eqnarray*}
\inwrites{s} &=& \biginter \outwrites{\pred{s}}\\
\outwrites{s} &=& \inwrites{s} \union \{w\}
\end{eqnarray*}

\subsubsection{Computing \reads}

There are two sources of reads: expressions and calls. A statement $s$
partially reads the initial value of a variable path $r$ in the following
cases:
\begin{itemize}
\item $s$ contains an occurence of $r$ that does not count as write, as
  described above;
\item $s$ contains a dereference that does not count as write, as described
  above, and $r$ is \heap;
\item $s$ contains a call to a subprogram $f$, and $r \in \outreads{f}$.
\end{itemize}

Given a statement $s$ partially reading the initial value of variable paths
$r_i$, the following equations define \reads:
\begin{eqnarray*}
\inreads{s} &=& \bigunion \outreads{\pred{s}}\\
\outreads{s} &=& \inreads{s} \union (\{r_i\} \minus \inwrites{s})
\end{eqnarray*}

\subsubsection{Computing the read-set, write-set and read-write-set}

Given subprogram $f$:
\begin{itemize}
\item the initial read-set for $f$ is $\outreads{f} \minus \outallwrites{f}$;
\item the initial write-set for $f$ is $\outwrites{f} \minus \outreads{f}$;
\item the initial read-write-set for $f$ is $\outreads{f} \inter
  \outallwrites{f}$.
\end{itemize}

Then, the write-set of $f$ should be augmented with all the local variable paths
defined in $f$, whether in the declarative part of the subprogram or in a block
statement inside the body.

The goal of this computation is that:
\begin{itemize}
\item for the translation to SPARK:
\begin{itemize}
\item the global ``in'' annotation should be the read-set;
\item the global ``out'' annotation should be the write-set;
\item the global ``in out'' annotation should be the read-write-set.
\end{itemize}
\item and for the translation to Why:
\begin{itemize}
\item the ``reads'' annotation should be the union of the read-set and the
  read-write-set;
\item the ``writes'' annotation should be the union of the write-set and the
  read-write-set.
\end{itemize}
\end{itemize}

The reason for augmenting the write-set with local variable paths is that the
translation will put these local variable paths in another package, and they
will appear as global variable paths from within $f$. Defining these in the
write-set makes sure that SPARK will not consider them as initialized prior to
calling $f$, so that all reads will have to be preceded by appropriate
writes. In order to prevent warnings that some of these variable paths may not
be written on some path before returning, an initialization subprogram should
be declared, which takes all local variable paths in its ``in out''
annotation. This initialization subprogram should be called prior to returning
from the subprogram, which ensures the translated subprogram respects its
data-flow contracts for local variable paths. Only the absence of any read to
some local variable path could be detected and displayed as an error, which is
safe to do.

\subsection{From Expanded Ada to Extended SPARK}

As a general remark, the translation should be free to introduce copies of any
values (for example to translate extended returns), which should not have any
effect on the validity of the proofs.

\subsubsection{Declarations}

An abstract subprogram declaration should be translated into a normal
subprogram declaration, as the constraint that such subprograms are not defined
is a compile-time constraint checked by the compiler.

A null subprogram declaration should be translated into a normal subprogram
declaration and a body with a single null statement. [unless SPARK defines null
procedures as a way to specify axioms or lemmas at the source level, see
J925-004]

Incomplete type declarations should be dropped, as they are redundant with the
corresponding complete type declarations.

Each variable should be translated into a set of variables, one for each
variable path as defined in Section~\ref{sub:variable-path}. This applies also
to parameters, so that one parameter in expanded Ada might be translated in
many parameters in extended SPARK. For external subprograms, as defined in
Section~\ref{sub:DFV}, a parameter should be translated into the set of all
path variables thus created. For internal subprograms, a parameter should be
translated into the set of path variables which are mentioned in its read-set,
write-set or read-write-set, and the mode of the new parameter corresponds to
the set it comes from.

\begin{example}
  Take a procedure \verb|Set| which only initializes part of its \verb|Point|
  parameter:
\begin{verbatim}
type Point is record X, Y : Val; end record;
procedure Set (P : out Point) is begin P.X := 0; end Set;
\end{verbatim}

  If the procedure \verb|Set| below is an internal procedure, it should mention
  only path variables that are part of its frame condition:
\begin{verbatim}
procedure Set (P_X : out Val) is begin P_X := 0; end Set;
\end{verbatim}

  If the procedure \verb|Set| below is an external procedure, it should mention
  all path variables derived from its initial parameter, so that the lack of
  initialization of \verb|P.Y| would be detected here by DFV:
\begin{verbatim}
procedure Set (P_X, P_Y : out Val) is begin P_X := 0; end Set;
\end{verbatim}
\end{example}

All anonymous types should be explicitly named. This concerns:
\begin{itemize}
\item anonymous subtypes in type definitions (for example, the bounds in an
  array);
\item anonymous subtypes in object and component declarations;
\item anonymous array types in object declarations.
\end{itemize}

Object declarations with an initialization should be split so that the
initialization is performed instead in assignment statement in the appropriate
subprogram.

Various translations remove entities not defined in SPARK and/or in Why:
\begin{itemize}
\item named numbers should be inlined;
\item the keywords \kw{abstract} and \kw{limited} in a derived type definition
  should be dropped, as they have no dynamic semantics;
\item derived scalar types should be replaced by subtypes with the same bounds;
\item character literals used in enumerations should be renamed into usual
  enumeration values.
\end{itemize}

\subsubsection{Names and Expressions}

All names should be made unique in their package. This takes care of
overloading, which is allowed in Ada but not in SPARK or Why. In particular,
operator symbols should be renamed so that operators become regular functions.

[It is not clear how slices should be translated in all cases. At first, I
thought slices appearing as parameters could be translated as the complete
array with additional bound parameters. But this does not work for a
multi-dimensional slice, say A(0)(1..10).]

\subsubsection{Statements}

Translation of statements is delayed until final translation to SPARK/Why. [in
particular, translation of arbitrary exit and return statements to SPARK is not
solved. It is ok in Why.]

\paragraph{Return Statements} 

SPARK mandates that procedures do not contain return statements, and that
functions contain a single return statement as last statement. 

Thus, all return
statements of a procedure \verb|P| should be translated into calls to a local
procedure \verb|P_Return| which:
\begin{enumerate}
\item \label{it:no-param} takes no parameters;
\item \label{it:in-globals} has the out-parameters and out-globals of \verb|P|
  as in-globals;
\item \label{it:out-globals} has the local variables of \verb|P| as out-globals;
\item \label{it:pre} has the postcondition of \verb|P| as precondition;
\item \label{it:in-globals-more} has all variables mentioned in the
  postcondition of \verb|P| as in-globals;
\item \label{it:post} has \verb|False| as postcondition.
\end{enumerate}
(\ref{it:in-globals}) ensures that at the calling point of \verb|P_Return|, all
out-variables of \verb|P| are initialized. (\ref{it:out-globals}) ensures that
no flow error will be generated due to some (locally dead) path through this
call not initializing some local variables. (\ref{it:pre}) ensures that at the
calling point of \verb|P_Return|, the postcondition of \verb|P|
holds. (\ref{it:in-globals-more}) adds the variables mentioned in the
precondition of \verb|P_Return| as in-globals, which is compulsory in SPARK.
(\ref{it:post}) ensures that any path through this call is considered as a dead
path when proving VCs.

\begin{example}
  Take procedure \verb|P| with local variable V, which should be declared in
  SPARK as:
\begin{verbatim}
procedure P (X : in T; Y : out T; Z : in out T);
--# global in     A;
--#           out B;
--#        in out C;
--# post Prop (X, Z~, B);
\end{verbatim}
Any return statement in \verb|P| should be translated into a call to local
procedure \verb|P_Return|, declared as:
\begin{verbatim}
procedure P_Return;
--# global in     Y, B,      --  out-variables of P
--#               X, Z_Old;  --  added because used in the pre
--#           out V;
--# pre  Prop (X, Z_Old, B);
--# post False;
\end{verbatim}
where \verb|Z_Old| is a variable declared to hold the value of \verb|Z| at the
entry to \verb|P|.
\end{example}

Likewise, a return statement of a function \verb|F| which is not the final
return statement should be translated into an assignment of the returned value
to a new local variable \verb|F_Result| followed by a call to a local procedure
\verb|F_Return| which:
\begin{enumerate}
\item \label{it:fn-no-param} takes no parameters;
\item \label{it:fn-in-globals} has the out-parameters and out-globals of
  \verb|F| as in-globals;
\item \label{it:fn-out-globals} has the local variables of \verb|F| as
  out-globals;
\item \label{it:fn-pre} has the postcondition of \verb|F| as precondition;
\item \label{it:fn-in-globals-more} has all variables mentioned in the
  postcondition of \verb|P| as in-globals;
\item \label{it:fn-post} has \verb|False| as postcondition.
\end{enumerate}
These conditions provide the same guarantees than in the procedure
case. Additionally, a statement returning \verb|Result| should be inserted as
final statement if no final return statement is present. This will lead to a
flow error if-and-only-if there is a path which can reach the exit of the
function without a return statement.

\begin{example}
  Take function \verb|F| with local variable V, which would be declared in
  pseudo-SPARK as:
\begin{verbatim}
function F (X : in T; Y : out T; Z : in out T) return Integer;
--# global in     A;
--#           out B;
--#        in out C;
--# return Res => Prop (X, Z~, B, Res);
\end{verbatim}
  Any non-terminal return statement in \verb|F| should be translated into an
  assignment to \verb|F_Result| followed by a call to local procedure
  \verb|F_Return|, declared as:
\begin{verbatim}
procedure F_Return;
--# global in     Y, B,                --  out-variables of P
--#               F_Result, X, Z_Old;  --  used in the pre
--#           out V;
--# pre  Prop (X, Z_Old, B, Res);
--# post False;
\end{verbatim}
\end{example}

\paragraph{Raise Statements} 

Raising an exception is very similar to returning from a subprogram, except the
postcondition and data-flow contract do not have to be respected in this case.

Thus, all raise statements in a subprogram \verb|S| should be translated into
calls to a local procedure \verb|S_Raise| which:
\begin{enumerate}
\item \label{it:exc-no-param} takes no parameters;
\item \label{it:exc-out-globals} has the local variables of \verb|S| as
  out-globals;
\item \label{it:exc-post} has \verb|False| as postcondition.
\end{enumerate}
(\ref{it:exc-out-globals}) ensures that no flow error will be generated due to
some (locally dead) path through this call not initializing some local
variables. (\ref{it:exc-post}) ensures that any path through this call is
considered as a dead path when proving VCs.

\subsubsection{Subprograms}

\paragraph{Parameters} 

For each global variable of mode ``in'', it may be
necessary to add a precondition to the subprogram which asserts the implicit
corresponding type invariant, when the original type for this variable has a
dynamic flavor (subtype with dynamic bounds, discriminant record).

\begin{example}
The parameter \verb|X| below has a type with dynamic bounds:
\begin{verbatim}
subtype Index is Integer range A .. B;
procedure P (X : Index);
\end{verbatim}

It should be translated into a variable \verb|X| which is constrained in the
precondition to be within the allowed bounds:
\begin{verbatim}
X : Integer;
procedure P;
--# global in X;
--# pre X in Index_First .. Index_Last;
\end{verbatim}
\end{example}

Various translations remove entities not defined in SPARK and/or in Why:
\begin{itemize}
\item user-defined operators should be translated as regular functions;
\item default expressions for parameters should be inlined at call sites, so
  that they do not appear as default expressions anymore;
\item the \kw{overriding} keyword should be simply removed, as it only serves
  as a visual reminder of the status of the subprogram;
\item parameters in calls should be given in the order of their definition,
  even in the case where use of parameter associations in the Ada code gives
  them outside of their definition order;
\item extended returns should be translated in either:
  \begin{itemize}
  \item a simple return when there is no return statement;
  \item otherwise, the declaration of a corresponding local variable (in the
    $<$data$>$ package) and corresponding initialization code, followed by a
    simple return.
  \end{itemize}
\item null procedure declarations should be translated into procedures with a
  null body statement.
\end{itemize}

\subsubsection{Package Specifications and Declarations}

The first requirement is to break the mutual dependencies between packages and
between subprograms in Ada, in order to 1) achieve modular verification at the
subprogram level and 2) prevent circular dependencies between units and between
elements of units, which are either not supported or supported with
restrictions in both SPARK and Why. These mutual dependencies come from
recursion between subprograms as well as cross calls between packages (P.F
calls Q.G which calls P.H) even without recursion. To that end, each
declarative part leads to the generation of two units: one for the data+types
of this declarative part, one for the subprogram specifications of this
declarative part.

As an example, a package P defining data and subprograms should lead to the
generation of a unit P\_Data for its data+types and P\_Spec for its subprogram
specifications. Then, a subprogram P.F in ALFA should be translated into the
only subprogram in unit P\_F, which manipulates data from P\_Data and calls
subprograms from P\_Spec (including potential calls to F in P\_Spec, which
correspond to recursive calls in the source program).

As another example, a subprogram F in ALFA defining local variables and local
subprograms should lead to the generation of a unit F\_Data for its local
variables (including the variables defined in block statements inside F) and
F\_Spec for its local subprogram specifications (including the local
subprograms defined in block statements inside F). Then, F's body should be
translated into the only subprogram in unit F, which manipulates data from
F\_Data and calls subprograms from F\_Spec.

Thus, the generated units should be layered in:
\begin{enumerate}
\item $<$data$>$: units which define global data in SPARK or Why, corresponding
  to either global or local variables in Ada. These units also define types.
\item $<$spec$>$: units which define subprogram specifications in SPARK or Why,
  corresponding to all subprograms specifications and definitions in Ada. These
  units also define parameterized expressions.
\item $<$body$>$: units which define a single subprogram specification and body
  in SPARK or Why from a subprogram in ALFA.
\end{enumerate}

Entities declared in the package specification and those declared in the
package body should be treated identically. In particular, all entities
declared in the package body should become visible from outside the package in
the generated SPARK code. Likewise, the private part of a package specification
should be merged in its public part, so that all entities become public. As a
consequence, all private views of types should be removed [should they be
kept?].

The set of global variables defined in the package specification and package
body should become the ``own'' global variables of the corresponding $<$data$>$
package.

A subprogram should be generated for the initialization part of variable
declarations, both in the package body and in the package declaration, as well
as the optional sequence of statements in the package body. This subprogram
should have the global annotations computed as described in
section~\ref{sub:data-flow}, and additionally:
\begin{itemize}
\item there should not be any ``in'' or ``in out'' global variables, to prevent
  undue dependencies on the order of elaboration;
\item the ``out'' global variables should be the ``initializes'' global
  variables of the corresponding $<$data$>$ package.
\end{itemize}

\subsubsection{Use Clauses}

Various translations remove entities not defined in SPARK and/or in Why:
\begin{itemize}
\item use clauses (not allowed in SPARK) should be replaced by use-type clauses
  (allowed in SPARK) for all types in the package, so that operations are still
  permitted on the types exported;
\item renamings, which provide a proxy name for an entity, and which are
  strongly limited in SPARK, should be removed and each occurrence of the
  new name should be replaced by the entity being renamed;
\end{itemize}

\subsubsection{Tasks and Synchronisation}

\subsubsection{Program Structure and Compilation Issues}

Library-level subprograms should be wrapped in a library-level package.

Use clauses should be removed.

The treatment of subunits should be no different if they were defined inlined.

\subsubsection{Exceptions}

\subsubsection{Generic Units}

Specifications of generic unit instantiations should be generated, so that the
corresponding instantiated subprograms are called.

\subsubsection{Representation Issues}

\subsection{From Extended SPARK to SPARK}

\subsubsection{Types}

Ada derived scalar types should be translated into SPARK subtypes. Indeed,
after the front-end has checked that derived types are properly used and after
overloading has been resolved, the constraints respected by a derived type are
the same as those respected by a subtype with the same bounds. Notice that this
may require that new packages are withed to make inherited primitive operations
for the parent type available.

\subsubsection{Expressions}

[how to translate quantified expression in code? maybe ALFA should be limited
to quantification in the logic.]

\subsubsection{Subprograms}

Ada functions may write global variables, which is not allowed in SPARK. Thus,
functions should be translated into procedures by introducing an additional
``out'' parameter.

\subsection{From Extended SPARK to Why}

\subsubsection{Types}

\paragraph{Integer Types}

Ada integer types (signed and modular) should be translated into Why abstract
types. Convertion functions in Why between such an abstract type and type
\verb|int|, suitably axiomatized, will provide:
\begin{itemize}
\item a way to enforce the static type range;
\item a representation for the usual arithmetic operations;
\item a representation giving the expected order.
\end{itemize}

Ada integer subtypes (signed and modular) should be translated into Why
abstract types. Convertion functions in Why between such an abstract type and
type \verb|int| provide a way to translate all allowed type conversions in Ada.
 
\paragraph{Enumeration Types}

Ada enumeration types should be translated into Why enumeration
types. Convertions to and from Why \verb|int| type provide a way to get an
order on the enumeration, as well as positions (Ada \verb|'Pos|
attribute). Subtypes of enumerations in Ada should be translated into abstract
types in Why, with suitable conversion functions, to and from their underlying
enumeration type.

The Ada \verb|Boolean| type should be translated into Why predefined
\verb|bool| type in all cases where the features of \verb|Boolean| as an
enumeration type are not used. In the remaining cases, for example to range
over values of type \verb|Boolean|, an enumeration type
\verb|standard__boolean| should be defined in Why.

\paragraph{Real Types}

The translation of real types (floating-point and fixed-point) remains
undecided for now.

\paragraph{Array Types}

Ada array types should be translated into instances of the Why array type. 

\subsubsection{Expressions}

\paragraph{Indexed Components} 

Simple reads and writes of array elements should be translated in the
corresponding calls to \verb|access| and \verb|update| from the prelude of Why,
which encode the usual theory of functional arrays.

\begin{example}
  The following Ada code increments array element \verb|A(I)| through a
  temporary:
\begin{verbatim}
Tmp := A(I); A(I) := Tmp + 1;
\end{verbatim}

Here is its translation in Why:
\begin{verbatim}
Tmp := access (!A, I); A := update (!A, I, Tmp + 1)
\end{verbatim}
\end{example}

Indexed components passed as ``in'' parameters should be translated like simple
reads. Indexed components passed as ``out'' or ``in out'' parameters should be
copied back after the call from a local reference passed in
parameter. Additionally, the local reference should be initialized from the
indexed component before the call for an ``in out'' parameter.

\begin{example}
  The following Ada code sets all elements of an array to 1 through repeated
  calls to \verb|One|:
\begin{verbatim}
procedure One (X : out Integer) is begin X := 1; end One;

procedure All_One (A : in out Arr) is
begin
   for J in Index loop
      One (A(J));
   end loop;
end All_One;
\end{verbatim}

Here is the translation of the loop body in Why:
\begin{verbatim}
let tmp = ref any_integer() in
One (tmp);
A := update (!A, J, tmp);
\end{verbatim}
\end{example}

\paragraph{Slices}

[still not known]

\paragraph{If Expressions} Ada if-expressions should be translated into Why
if-expressions.

\paragraph{Case Expressions} Ada case-expressions over an enumerated type
should be translated into Why pattern-matching expressions. Ada
case-expressions over a discrete type which is not enumerated should be
translated as a series of if-expressions.

\paragraph{Quantified Expressions} A quantified expression in Ada should be
translated into the corresponding logic proposition in Why (\verb|for all| in
Ada becomes \verb|forall| in Why; \verb|for some| in Ada becomes \verb|exists|
in Why). A quantified expression over integer ranges tran

\begin{example}
The quantified expresssion shown in Example~\ref{ex:alfa-quantifiers}:
\begin{verbatim}
for all X in Index => Prop (X)
\end{verbatim}
translates into the following predicate:
\begin{verbatim}
forall X : Index. Prop (X)
\end{verbatim}
\end{example}

[what about quantification over containers?]

\bibliographystyle{plain}
\bibliography{alfa}

\end{document}
