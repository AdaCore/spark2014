\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{xspace}

\title{ALFA: Annotated Language of Functions in Ada}

\newcommand{\bnf}[1]{$\mathit{#1}$}
\newcommand{\kw}[1]{\textbf{#1}}
\newcommand{\spark}{$\tau_S$}
\newcommand{\why}{$\tau_W$}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\heap}{\code{Heap}\xspace}
\newcommand{\pred}[1]{\ensuremath{\mathit{pred}(#1)}\xspace}
\newcommand{\allwrites}{$\mathcal{W^+}$\xspace}
\newcommand{\Outallwrites}{\ensuremath{\mathcal{W}^{+out}}\xspace}
\newcommand{\Inallwrites}{\ensuremath{\mathcal{W}^{+in}}\xspace}
\newcommand{\inallwrites}[1]{\ensuremath{\mathcal{W}^{+in}(#1)}\xspace}
\newcommand{\outallwrites}[1]{\ensuremath{\mathcal{W}^{+out}(#1)}\xspace}
\newcommand{\writes}{$\mathcal{W}$\xspace}
\newcommand{\Outwrites}{\ensuremath{\mathcal{W}^{out}}\xspace}
\newcommand{\Inwrites}{\ensuremath{\mathcal{W}^{in}}\xspace}
\newcommand{\inwrites}[1]{\ensuremath{\mathcal{W}^{in}(#1)}\xspace}
\newcommand{\outwrites}[1]{\ensuremath{\mathcal{W}^{out}(#1)}\xspace}
\newcommand{\reads}{$\mathcal{R}$\xspace}
\newcommand{\Inreads}{\ensuremath{\mathcal{R}^{in}}\xspace}
\newcommand{\Outreads}{\ensuremath{\mathcal{R}^{out}}\xspace}
\newcommand{\inreads}[1]{\ensuremath{\mathcal{R}^{in}(#1)}\xspace}
\newcommand{\outreads}[1]{\ensuremath{\mathcal{R}^{out}(#1)}\xspace}
\newcommand{\union}{~\cup~}
\newcommand{\bigunion}{~\bigcup~}
\newcommand{\inter}{~\cap~}
\newcommand{\biginter}{~\bigcap~}
\newcommand{\minus}{~\backslash~}
\begin{document}

\maketitle
\sloppy
\section{Ada 2012}

Ada 2012 is the next version of the Ada standard, expected to be finalized in
2012. It contains many extensions that facilitate the expression of
specifications, for either dynamic or static checking.

\subsection{Introduction to Ada}

\subsubsection{Module System}

Programs in Ada are structured in packages, which consist in:
\begin{itemize}
\item a package specification, which defines the external API of the package,
  consisting of types, variables and subprogram declarations whose lifetime and
  visibility scope are the same as the one of the package itself;
\item an optional package body, which defines the entities declared in the
  package specification, plus additional entities which are not part of the
  external API.
\end{itemize}

The package specification may be divided in a public part and a private part,
so that the private part is visible to the compiler, for use in separate
compilation, but not visible to the external program. Thus, a type may be
declared as having a private definition, so that the compiler knows its precise
definition (size, initialization, etc.) but the program cannot depend on it
outside the package.

Packages may be defined in any declarative section: at the outtermost level as
library-level compilation units, or inside other packages and subprogram
bodies. Subprograms too can be defined either as library-level compilation
units, or in local declarative sections. Variables and types can only be
defined in local declarative sections.

Child packages are derived from their parent package with which they have
special visibility relations, which depends on the public/private status of the
child package.

\subsubsection{Type System}

Ada enforces a strong type system by default, although it can be circumvented
by using specific conversion functions (e.g. on addresses), for example to
connect the program to external sensors/actuators.

Integers come in a variety of flavors. New integer types can be defined which
are incompatible, so that type checking uncovers mistakes where different
integer types are mixed, and a subprogram can be overloaded for different
integer types. Subtypes of existing integer types can define a range constraint
which should hold for all initialized values of this subtype, and the compiler
inserts a run-time check anywhere the constraint could be violated. Given a
subtype S of a type T, there exists a base machine type B for both T and S such
that all arithmetic operations on S and/or T are performed in B.  After the
result is computed, it is stored back in a variable of type S or T and the
corresponding range check is performed.

Enumerations define named enumerators which are the only values of this
type. Although pattern-matching is available for all discrete types, it is
mostly used for enumerations. As part of type checking, the compiler checks
that pattern-matching is complete and that no case is redundant.

Floating-point types follow the IEEE-754 standard. Fixed-point types limit the
precision of values to a fixed number of figures.

Aggregate types come in two flavors: records aggregate heterogeneous data
components, while arrays aggregate homogeneous data components. Records may
have one or more discriminants: discriminants of enumerated type are used to
provide a form of algebraic datatypes, as the discriminant is used to provide a
variant distinction between different sets of components; discriminants of
integer type are used to provide dependent types, as the discriminant is used
to give the size of some array component.

Pointer types, a.k.a. access types in Ada, follow a set of somewhat complex
rules to prevent dangling pointer references. In the following, we will mostly
ignore pointers.

The set of non-aggregate types are called elementary types.

\subsubsection{Metaprogramming}

Generic packages and subprograms define template entities to instantiate at
compile-time. They come with a set of formal parameters for types, variables,
values and subprograms. Formal parameters declare individual constraints and
relations with other formal parameters, so that once the compiler has checked a
generic entity, any instantiation with correct arguments will generate a
compilable entity.

\subsubsection{Object-Oriented Programming}

Classes are known in Ada as tagged (record) types. Objects are values of tagged
types. Methods are known as primitive operations, which can take their
dispatching type in any position. When the first operand is the dispatching
one, the usual object-dot-method syntax is allowed for calls.

An object can be considered either of type T, in which case there is no
dispatching involved when calling a primitive operation of T, or of type
T'Class, in which case all primitive operations on this object are dispatching.

Interfaces can be defined which only introduce primitive operations, not
components.

\subsubsection{Calling Conventions}

Parameters of elementary types are passed by copy.  Parameters of tagged type
are passed by reference. For most other parameters, the compiler is choosing
between by-reference and by-copy.

Parameters have a mode, which can be by default \emph{in} or else \emph{out}
and \emph{in out}:
\begin{itemize}
\item parameters of mode \emph{in} can only be read;
\item parameters of mode \emph{out} can only be written;
\item parameters of mode \emph{in out} can be both read and written.
\end{itemize}

\subsection{New in Ada 2012}

The standard defines the following extensions to Ada 2005, which facilitate the
expression of specifications as subprogram contracts or type invariants:

\begin{itemize}
\item AI05-0001: bounded containers
\item AI05-0183: aspect specifications
\item AI05-0147: conditional expressions
\item AI05-0188: case expressions
\item AI05-0177: parameterized expressions
\item AI05-0176: quantified expressions
\item AI05-0146: type invariants
\item AI05-0153: subtype predicates
\end{itemize}

While the ARG website is the final authority on these extensions
(http://www.ada-auth.org/AI05-SUMMARY.HTML), we sketch in the following the
semantics and interest of each one.

Bounded containers introduce bounded versions of the existing generic
containers in Ada 2005 container library (vector, list, hashed set, ordered
set, hashed map, ordered map). The bound on the size of the container is used
to preallocate an array of the desired size, so that dynamic allocation is not
used for these containers. This opens up the possibility to perform proofs on
programs using containers, as the validity of cursors is far simpler in this
new model.

Aspect specifications allow defining contracts for subprograms, a contract
being a pair of a precondition (Pre) and a postcondition (Post). Special
contracts can also be issued for overriding, so that an overriding subprogram
can only weaken the inherited precondition and strengthen the inherited
postcondition. The standard defines a general syntax for aspects which allows
the definition of compiler-specific aspects, like the test-case aspect in GNAT
described below. In the postcondition, attribute 'Old applied on a name
indicates the value attached to this name at subprogram entry, and attribute
'Result applied to the name of the current function indicates the result
returned by this function. Preconditions and postconditions may be compiled
into executable assertions if the right option is given to the compiler (-gnata
in GNAT).  As an example, a contract for a square-root function is:

\begin{verbatim}
function Sqrt (X : Integer) return Integer with
  Pre  => X >= 0,
  Post => Sqrt'Result >= 0 and then
          Sqrt'Result ** 2 <= X and then
          (Sqrt'Result + 1) ** 2 > X;
\end{verbatim}

Conditional expressions and case expressions allow the use of 'if' and 'case'
in expressions, which simplifies specifications.

Parameterized expressions are a simple form of function definitions (or lambda
expressions) allowed in the specification part of a package. In particular,
simple boolean predicates on accessors to a (private) type, which are typically
the predicates one needs to write subprogram contracts, can be defined as
parameterized expressions. This has the advantage for proofs that parameterized
expressions (contrary to functions) 1) cannot have write side-effects, 2) have
a much simpler form than the usual functions, which is easier to translate into
proof predicates, 3) can be defined in a package specification which makes them
available for proof even if the package body is not.

Quantified expressions allow the expression of predicates which hold for all
elements in a range or a container, or for some element in a range or a
container.

Type invariants express invariant properties of private types, which should be
typically observed by any value of the type outside its package. However, the
standard only defines specific points at which this property is checked on a
value of the type, like entry and exit points of a subprogram. This does not
enforce by itself that the property always holds.

Subtype predicates express fine-grain properties of subtypes, like the various
enumeration values allowed for the discriminant of a record. Like for type
invariants, the standard only defines specific points at which this property is
checked.

\subsection{GNAT-Specific Extensions}

GNAT defines an aspect called Test\_Case, which applies to subprograms exactly
like the standard Pre and Post. A test-case is an aggregate with exactly three
components, all of which are compulsory:
\begin{itemize}
\item a Name component, of type string, which gives the name of the test-case;
\item a Requires component, of type boolean, which defines the entry condition
  for the test-case;
\item an Ensures component, of type boolean, which defines the exit condition
  for the test-case.
\end{itemize}

A test-case (N,Req,Ens) is a part of the specification which indicates that
under entry condition Req, the subprogram terminates with condition Ens. Thus,
the Requires component bears much resemblance with the precondition, and the
Ensures component bears much resemblance with the postcondition. Indeed, they
share the same semantic restrictions (w.r.t. 'Old and 'Result).  More than one
test-case can be defined for a subprogram. No two test-cases on a subprogram
should have the same name.

Contrary to preconditions and postconditions, test-cases are not compiled into
executable assertions by the compiler. GNAT only checks that test-cases are
properly defined. Test-cases should be used by the verification toolkit either
for unit testing or for unit proof.

For unit testing, it is sufficient to write a test procedure which exercises a
test-case to consider this test-case successful. To exercise a test-case, a
test procedure must in order:
\begin{enumerate}
\item generate suitable arguments, by calling one or more subprograms
  called \textit{fixtures};
\item check that the requires is satisfied on these arguments;
\item optionally check that the precondition is satisfied on these arguments;
\item call the subprogram tested on these arguments;
\item optionally check that the postconditions is satisfied on these arguments;
\item check that the ensures is satisfied.
\end{enumerate}

The part about checking the contract of the subprogram is optional because some
test-cases may correspond to cases beyond the normal behavior of the subprogram
described in its contract. Typically, robustness tests deal with such abnormal
behavior.

For unit proof, it is sufficient to prove that the subprogram implements a
special contract, with:
\begin{itemize}
\item the requires, optionally and'ed with the original precondition, as
  precondition;
\item the ensures as postcondition.
\end{itemize}

The original precondition should be and'ed with the requires for those
test-cases which correspond to normal behavior, and the requires should be the
only precondition for those test-cases which correspond to abnormal behavior.

As an example, a contract with test-cases for an integer square-root function
is:

\begin{verbatim}
function Sqrt (X : Integer) return Integer with
  Pre  => X >= 0,
  Post => Sqrt'Result >= 0 and then
          Sqrt'Result ** 2 <= X and then
          (Sqrt'Result + 1) ** 2 > X,
  Test_Case => (Name     => "test case 1",
                Requires => X = 100, 
                Ensures  => Sqrt'Result = 10),
  Test_Case => (Name     => "test case 2",
                Requires => X < 100, 
                Ensures  => Sqrt'Result >= 0 and then 
                            Sqrt'Result < 10);
\end{verbatim}

\section{ALFA}

ALFA is a sub-language of Ada 2012 which identifies which subprograms are fit
for formal verification. ALFA does not work as an Ada profile, as the complete
program does not need to be in ALFA for individual subprograms to be in
ALFA. Rather, subprograms are in ALFA or not depending exclusively on their
specification and body. In particular, the location in the source where a
subprogram is defined (inside a package or another subprogram, in the public or
private part, etc.) should not influence whether it is in ALFA.

\subsection{ALFA Extensions}

ALFA considers that the pragma Assert immediately at the start of a loop
statement list have a special meaning. They define a loop-invariant for this
loop, which is used for unit proof.  As an example, the following
implementation of the integer square-root function has a loop-invariant:

\begin{verbatim}
function Sqrt (X : Integer) return Integer is
   Res, Two_Res, Res_Square : Integer := 0;
begin
   while Res_Square <= X loop
      pragma Assert (Res >= 0 and then
                     Two_Res = 2 * Res and then
                     Res_Square = Res * Res);
      Res_Square := Res_Square + Two_Res + 1;
      Two_Res    := Two_Res + 2;
      Res        := Res + 1;
  end loop;
  return Res - 1;
end Sqrt;
\end{verbatim}

The loop-invariant to be used for unit proof should be:
\begin{itemize}
\item true the first time the loop is entered;
\item provable from assuming it at some previous iteration through the loop and
  examining the effect of the loop body.
\end{itemize}

ALFA introduces a new form of containers called the formal containers, to be
used for proof of programs which manipulate containers. These are a variant of
bounded containers, with a different API meant to facilitate proofs.

\subsection{ALFA Restrictions}

In the following, we refer to entities in the program with the name of the
corresponding non-terminal in the Ada BNF, like \bnf{subprogram\_body} for a
subprogram body. As a general rule, an entity is in ALFA only if all its
sub-entities which define it are in ALFA. As an example, a
\bnf{subprogram\_body} is defined in Ada BNF as:

\begin{verbatim}
subprogram_body ::=
  [overriding_indicator]
  subprogram_specification is
    declarative_part
  begin
    handled_sequence_of_statements
  end [designator];
\end{verbatim}

Thus, a \bnf{subprogram\_body} is in ALFA only if the following are in ALFA:
\begin{itemize}
\item its \bnf{overriding\_indicator} (if present);
\item its \bnf{subprogram\_specification};
\item its \bnf{declarative\_part};
\item its \bnf{handled\_sequence\_of\_statements};
\item its \bnf{designator} (if present).
\end{itemize}

This general rule applies individually to every production rule in the BNF
which define program entities. Thus, some production rules defining a
non-terminal may be in ALFA while others for the same non-terminal are not in
ALFA.

The additional rules below further restrict which entities are in ALFA. These
rules build on the report written by Marc Sango for his internship on the
definition of a verification profile for Ada. 

\subsubsection{Lexical Elements}

No special rules.

\subsubsection{Declarations}

All entities related to access types are not in ALFA:
\begin{itemize}
\item the \bnf{aliased} keyword, wherever it appears;
\item \bnf{access\_type\_definition};
\item \bnf{access\_to\_object\_definition};
\item \bnf{general\_access\_modifier};
\item \bnf{access\_to\_subprogram\_definition};
\item \bnf{null\_exclusion};
\item \bnf{access\_definition}.
\end{itemize}

\noindent
[what about \bnf{aspect\_clause} in \bnf{component\_item}?]\\

Note in particular that a \bnf{default\_expression} in a
\bnf{component\_declaration} is allowed, as well as a \bnf{variant\_part} in
a \bnf{component\_list}.

\subsubsection{Names and Expressions}

An \bnf{identifier} or a \bnf{name} which has a corresponding declaration is in
ALFA if-and-only-if its declaration is in ALFA. As a consequence, a call is in
ALFA only if the declaration of the subprogram called is in ALFA.\\

\noindent
[what about \bnf{aspect\_clause} in \bnf{basic\_declarative\_item}?]\\

All entities related to access types are not in ALFA:
\begin{itemize}
\item \bnf{explicit\_dereference};
\item \bnf{implicit\_dereference};
\item the \bnf{Access} terminal defining an \bnf{attribute\_designator};
\item the \bnf{null} terminal defining a \bnf{primary};
\item \bnf{allocator}.
\end{itemize}

Uses of the keywords \bnf{and}, \bnf{or} and \bnf{xor} are not in ALFA. Only
the keywords for the lazy operations \bnf{and\ then} and \bnf{or\ else} are in
ALFA.\\

An expression in ALFA which appears as part of an assertion must respect
additional constraints, where an assertion is any of a pragma Assert, a
precondition or postcondition, a type invariant or a subtype predicate:
\begin{enumerate}
\item it may contain calls to parameterized expressions, but no calls to
  functions;
\item it may contain uses of formal containers, but no uses of other
  containers.
\end{enumerate}

\subsubsection{Statements}

\noindent
\bnf{goto\_statement} is not in ALFA.

Note in particular that all possible \bnf{exit\_statement} are in ALFA,
including those which exit an outter loop.

\subsubsection{Subprograms}

A subprogram may have both a \bnf{subprogram\_declaration} and a
\bnf{subprogram\_body}. Such a subprogram is in ALFA only if both its
declaration and body are in ALFA. Additionally, the subprogram should have a
postcondition attached to its declaration. The requirement that a subprogram
has a postcondition ensures that the user states desired properties to prove on
this subprogram, and that callers can rely on a precise indication of what this
subprogram does. Of course, such a postcondition can be simply 'True' in which
case the user chooses not to give any more precise information.

Note that \bnf{extended\_return\_statement} is in ALFA.

\subsubsection{Package Specifications and Declarations}

No special rules. In particular, renamings and the optional statements in a
package body are in ALFA.

\subsubsection{Use Clauses}

No special rules.

\subsubsection{Tasks and Synchronisation}

Most probably, the same restrictions as in RavenSPARK should be enforced for
the sequential verification to apply to the concurrent code.

\subsubsection{Program Structure and Compilation Issues}

No special rules.

\subsubsection{Exceptions}

All entities related to exception handling are not in ALFA:
\begin{itemize}
\item \bnf{exception\_handler};
\item \bnf{choice\_parameter\_specification};
\item \bnf{exception\_choice}.
\end{itemize}

\subsubsection{Generic Units}

No special rules.

\subsubsection{Representation Issues}

[To be discussed.]

\section{Formal Verification}

All of data-flow verification, contract verification and verification of
absence of run-time errors can be performed independently. The results of
contract verification and verification of absence of run-time errors are only
valid if data-flow is correct, which in practice means that data-flow
verification should be performed as a pre-requisite.

\subsection{Data-Flow Verification}

The \bnf{mode} part of a \bnf{parameter\_specification} has a stronger
semantics in ALFA than in Ada, similar to what is found in SPARK:
\begin{itemize}
\item a \bnf{parameter\_specification} of mode \bnf{in} must be initialized at
  subprogram entry, and there must exist at least one syntactic path through
  the subprogram which reads it;
\item a \bnf{parameter\_specification} of mode \bnf{out} must be initialized on
  all syntactic paths through the subprogram before reaching subprogram exit;
\item a \bnf{parameter\_specification} of mode \bnf{in\ out} must be initialized
  at subprogram entry, and there must exist at least one syntactic path through
  the subprogram which assigns to it before reaching subprogram exit.
\end{itemize}

Reads of variables are only allowed if all syntactic paths through the
subprogram before reaching the read do initialize the complete aggregate object
from which a part is read. This restriction is similar to the SPARK one. It
applies both to local variables and parameters.

[need expansion of what is a data-flow error, regarding useless computations]

Aliasing between parameters and globals accessed by a subprogram is forbidden,
unless all aliasing paramaters and globals are read. This restriction is
similar to the SPARK one.

\subsection{Contract Verification}

The contract of a subprogram in ALFA is verified by assuming that the
subprograms it calls do respect their contracts, which includes a possible
recursive call (in which case the assumption is made only for the recursive
call). For the purpose of contract verification, possible run-time errors are
ignored, both in the program and in the contracts. Thus, the results of
contract verification hold for all executions which do not raise a run-time
error.

\subsection{Verification of Absence of Run-Time Errors}

Verifying that a subprogram in ALFA is free from run-time errors is verified by
assuming that the subprograms it calls do respect their contracts and that they
are free from run-time errors, which includes a possible recursive call (in
which case the assumption is made only for the recursive call).

\section{Translation to SPARK / Why}

A subprogram in ALFA should be translated into an intermediate representation
in SPARK or in Why. From this representation, the Examiner or Why tools can
generated Verification Conditions (VCs) to prove using an automatic prover.  In
order to facilitate fine-grain modular proof, each subprogram should lead to
the generation of a separate unit (package in SPARK, module in Why), which can
be proved independently. Notice that the generated SPARK is not executable, and
does not match in general the structure of the source Ada program, even if this
program is written in the SPARK subset of Ada. Ideally, the generated SPARK
should correspond to a simple subset of SPARK (for example no need for
visibility rules in this subset as everything is public). Thus, it should be
easier to formalize this subset and prove the correctness of transformations or
analyzes on this subset if needed.

\subsection{Introduction to SPARK/Why}

\subsubsection{Common Basis of SPARK and Why}

SPARK and Why are both programming languages designed for deductive
verification, more than execution. They both mix coding constructs with logic
constructs whose aim is to state invariant properties of the program.

The central logic construct is the contract, which serves to fully describe the
effect of calling a subprogram, for the purpose of separate verification. Each
subprogram in SPARK/Why must be defined with a proper contract:
\begin{itemize}
\item a precondition describes constraints on the calling context;
\item a frame condition describes both the variables on which the result of the
  subprogram depends (variables read) and the variables which may be modified
  as a result of the call (variables written);
\item a postcondition describes constraints on the result of the subprogram.
\end{itemize}

Both SPARK and Why define references which are used to pass parameters to
subprogram calls. None defines pointer types. Both SPARK and Why define static
rules to check that the only parameters which may be aliased are those which
are only read.

\subsubsection{SPARK Specificities}

SPARK code, when stripped from its logic constructs, is a subset from
Ada. Thus, SPARK inherits many constructs of Ada, and it is of course
executable.

SPARK enforces strict data-flow properties, that are checked statically.

\subsubsection{Why Specificities}

Why is a functional language with imperative features, of an OCaml flavor. Why
allows mixing freely axiomatized entities and defined entities, so that Why
programs cannot be executed.

Why defines four primitive types:
\begin{itemize}
\item \emph{int} for mathematical integers;
\item \emph{bool} for Booleans;
\item \emph{real} for mathematical real numbers;
\item \emph{unit} for the type of statements.
\end{itemize}

There are no aggregate types in Why. These should be defined as abstract types
and axiomatized. In this respect, Why is closer to the translation in FDL of
SPARK data structures than to SPARK.

\subsection{Generation of Annotations}

A valid SPARK or Why subprogram needs to indicate explicitly which global
variables can be read and/or written during the execution of this
subprogram. As this information is not present in the source Ada program, it
must be generated by our translation. As these reads and writes must account
for direct and indirect accesses, through any number of calls, this global
information must be retrieved by performing a global analysis on the closed set
of subprograms called directly and indirectly.

A special global variable called \heap represents all the dynamically allocated
memory plus all variables whose address is taken, so that reads and writes to
dynamically allocated memory show in SPARK or Why contracts as reads and writes
to \heap. Notice that without this \heap variable, contracts would be wrong and
break the consistency of the proof system. For example, it would be possible to
prove that Problem below always returns True, because Set would be seen as a
noop, and Get would be seen as a constant function:

\begin{verbatim}
X : access Integer;

procedure Set is
   X.all := 0;
end Set;

function Get return Integer is
begin
   return X.all;
end Get;

function Problem return Boolean is
   X1 : Integer := Get;
begin
   Set;
   return X1 = Get;
end Problem;
\end{verbatim}

Contracts (precondition and postcondition) in SPARK and Why have a
slightly different semantics than contracts in Ada 2012, because contracts in
SPARK and Why completely ignore the possibility of a run-time error being
raised while evaluating the contract. When checking for absence of run-time
errors (which can be separated from contract checking), the absence of run-time
errors in contracts should also be proved, which requires the extension of
contracts with additional conjuncts in SPARK and Why. For example, the
following contract in Ada:

\begin{verbatim}
function Get (A : My_Array; X : Integer) return Element
   with Pre => A (X) /= Nil_Element;
\end{verbatim}

would become in SPARK:

\begin{verbatim}
function Get (A : My_Array; X : Integer) return Element;
--# pre X in My_Array'Range and then A (X) /= Nil_Element;
\end{verbatim}

\subsection{General Architecture}

The first requirement is to break the mutual dependencies between packages and
between subprograms in Ada, in order to 1) achieve modular verification at the
subprogram level and 2) prevent circular dependencies between units and between
elements of units, which are either not supported or supported with
restrictions in both SPARK and Why. These mutual dependencies come from
recursion between subprograms as well as cross calls between packages (P.F
calls Q.G which calls P.H) even without recursion. To that end, each
declarative part leads to the generation of two units: one for the data+types
of this declarative part, one for the subprogram specifications of this
declarative part.

As an example, a package P defining data and subprograms should lead to the
generation of a unit P\_Data for its data+types and P\_Spec for its subprogram
specifications. Then, a subprogram P.F in ALFA should be translated into the
only subprogram in unit P\_F, which manipulates data from P\_Data and calls
subprograms from P\_Spec (including potential calls to F in P\_Spec, which
correspond to recursive calls in the source program).

As another example, a subprogram F in ALFA defining local variables and local
subprograms should lead to the generation of a unit F\_Data for its local
variables (including the variables defined in block statements inside F) and
F\_Spec for its local subprogram specifications (including the local
subprograms defined in block statements inside F). Then, F's body should be
translated into the only subprogram in unit F, which manipulates data from
F\_Data and calls subprograms from F\_Spec.

Thus, the generated units should be layered in:
\begin{enumerate}
\item $<$data$>$: units which define global data in SPARK or Why, corresponding
  to either global or local variables in Ada. These units also define types.
\item $<$spec$>$: units which define subprogram specifications in SPARK or Why,
  corresponding to all subprograms specifications and definitions in Ada. These
  units also define parameterized expressions.
\item $<$body$>$: units which define a single subprogram specification and body
  in SPARK or Why from a subprogram in ALFA.
\end{enumerate}

\subsection{Generation of Data-Flow Annotations}
\label{sub:data-flow}

A data-flow analysis of the source Ada program should associate each subprogram
with three sets of global variables:
\begin{itemize}
\item the read-set of variables possibly read by the subprogram;
\item the write-set of variables possibly written by the subprogram;
\item the read-write-set of variables possibly read and written by the
  subprogram.
\end{itemize}

Note that a variable which is always written by the subprogram before being
read, so that the initial value of the variable is never read, belongs to the
write-set, not the read-write-set.

A special global variable called \heap represents all the dynamically allocated
memory plus all variables whose address is taken.

The algorithm should compute various maps from program points $p$ to sets of
global variables:
\begin{itemize}
\item the map \writes of global variables written on all paths to $p$;
\item the map \allwrites of global variables written on some path to $p$;
\item the map \reads of global variable whose initial value at subprogram
  entry has been possibly read on some path to $p$.
\end{itemize}

As \reads depends on \writes, \writes should be computed first. As \writes,
\allwrites and \reads take program entities as parameters, they are decomposed
into (\Inwrites,\Outwrites), (\Inallwrites,\Outallwrites) and
(\Inreads,\Outreads) respectively, where the ``in'' part describes the program
point immediately before the entity and the ``out'' part describes the program
point immediately after the entity.

The control-flow graph of a subprogram allows defining for each statement $s$
the set of its predecessor statements \pred{s}.

\subsubsection{Computing \writes}

There are two sources of writes: assignment statements and calls. A statement
$s$ writes a global variable $w$ in the following cases:
\begin{itemize}
\item $s$ is an assignment statement to $w$ or a part of $w$;
\item $s$ is an assignment statement through a dereference, and $w$ is \heap;
\item $s$ contains a call to a subprogram $f$, and $w \in \outwrites{f}$.
\end{itemize}

Then, given a statement $s$ writing global variables $w$, the algorithm
iterates the following transition relation, which mutually defines the set of
global variables written on all paths immediately after the statement
\outwrites{s} and the set of global variables written on all paths immediately
before the statement \inwrites{s}:

\begin{eqnarray*}
\outwrites{s} &=& \inwrites{s} \union \{w\}\\
\inwrites{s} &=& \biginter \outwrites{\pred{s}}\\
\end{eqnarray*}

Likewise:

\begin{eqnarray*}
\outallwrites{s} &=& \inwrites{s} \union \{w\}\\
\inallwrites{s} &=& \bigunion \outallwrites{\pred{s}}\\
\end{eqnarray*}

As a result of this data-flow analysis, the set of global variables written is
propagated through the subprogram body so that, for example, a sequence of
statements is associated with the set of variables written by any statement in
the sequence.

As these sets grow, the algorithm necessarily reaches a fixpoint and
terminates.

\subsubsection{Computing \reads}

All occurences of names of global variables should either count as writes, as
described above, or else as reads, for the enclosing statement. Then, given a
statement $s$ reading global variables $r_i$, the algorithm iterates the
following transition relation, which mutually defines the set of global
variables read on some path immediately after the statement \outreads{s} and
the set of global variables read on some path immediately before the statement
\inreads{s}:

\begin{eqnarray*}
\outreads{s} &=& \inreads{s} \union (\{r_i\} \minus \inwrites{s})\\
\inreads{s} &=& \bigunion \outreads{\pred{s}}\\
\end{eqnarray*}

As these sets grow, the algorithm necessarily reaches a fixpoint and
terminates.

\subsubsection{Computing the read-set, write-set and read-write-set}

Given subprogram $f$:
\begin{itemize}
\item the initial read-set for $f$ is $\outreads{f} \minus \outallwrites{f}$;
\item the initial write-set for $f$ is $\outwrites{f} \minus \outreads{f}$;
\item the initial read-write-set for $f$ is $\outreads{f} \inter
  \outallwrites{f}$.
\end{itemize}

Then, the write-set of $f$ should be augmented with all the local variables
defined in $f$, whether in the declarative part of the subprogram or in a block
statement inside the body. 

The goal of this computation is that:
\begin{itemize}
\item for the translation to SPARK:
\begin{itemize}
\item the global ``in'' annotation should be the read-set;
\item the global ``out'' annotation should be the write-set;
\item the global ``in out'' annotation should be the read-write-set.
\end{itemize}
\item and for the translation to Why:
\begin{itemize}
\item the ``reads'' annotation should be the read-set;
\item the ``writes'' annotation should be the union of the write-set and the
  read-write-set.
\end{itemize}
\end{itemize}

The reason for augmenting the write-set with local variables is that the
translation will put these local variables in another package, and they will
appear as global variables from within $f$. Defining these in the write-set
makes sure that SPARK will not consider them as initialized prior to calling
$f$, so that all reads will have to be preceded by appropriate writes. In order
to prevent warnings that some of these variables may not be written on some
path before returning, an initialization subprogram should be declared, which
takes all local variables in its ``in out'' annotation. This initialization
subprogram should be called prior to returning from the subprogram, which
ensures the translated subprogram respects its data-flow contracts for local
variables. Only the absence of any read to some local variable will be detected
and displayed as an error, which is safe to do.

\subsection{Contract Verification and Verification of Absence of Run-Time Errors}

The two verifications should be performed independently, first because the user
may be interested in only one of these, second because we will aim at contract
verification through Why and verification of absence of run-time errors through
SPARK. The two are nonetheless related, which raises questions as to what is
assumed for each verification, so that performing both effectively gives
assurance that contracts are verified and there are no possible run-time
errors.

On the one hand, both types of verification depend on contracts and
intermediate assertions (loop-invariants and other assertions). For example,
loop-invariants usually contain information on the range of values, which are
both used for proving absence of run-time error and functional
properties. Thus, contracts and intermediate assertions should be assumed for
verification of absence of run-time errors. On the other hand, proving
contracts and intermediate assertions can be performed without assuming absence
of run-time errors. Indeed, what is proved in this case is that, provided there
are no run-time errors, the contracts and intermediate assertions hold.

Thus, the translation should be different for contract verification and for
verification of absence of run-time errors. 

% We denote the former as \why
% (translation to Why) and the latter as \spark (translation to SPARK).

\subsection{Shared Translation From Ada to SPARK}

Additional copied may be introduced (extended returns, etc.)

\subsubsection{Lexical Elements}

\subsubsection{Declarations}

\subsubsection{Names and Expressions}

calls to functions into calls to statements, with special result variable value
read just after the call and stored in local temp

\subsubsection{Statements}

\subsubsection{Subprograms}

Both procedures and functions in Ada should be translated into SPARK
procedures. Indeed, Ada functions may write global variables, so that the
compiler choice of evaluation order for expressions may influence the
result. Whatever it is, this choice should be the same for execution and
verification, which is obtained by forcing the compiler evaluation order when
translating function calls in expressions into sequential procedure calls.  In
particular, this applies also to user-defined operators.  In order to translate
a function F into a procedure, we should add a global variable F\_Result in the
scope where the function is defined, which is used to store the result of the
function.

Various translations remove entities not defined in SPARK and/or in Why:
\begin{itemize}
\item default expressions for parameters should be inlined at call sites, so
  that they do not appear as default expressions anymore;
\item the \kw{overriding} keyword should be simply removed, as it only serves
  as a visual reminder of the status of the subprogram;
\item parameters in calls should be given in the order of their definition,
  even in the case where use of parameter associations in the Ada code gives
  them outside of their definition order;
\item extended returns should be translated in either:
  \begin{itemize}
  \item a simple return when there is no return statement;
  \item otherwise, the declaration of a corresponding local variable (in the
    $<$data$>$ package) and corresponding initialization code, followed by a
    simple return.
  \end{itemize}
\item null procedure declarations should be translated into procedures with a
  null body statement.
\end{itemize}

\subsubsection{Package Specifications and Declarations}

\subsubsection{Use Clauses}

\subsubsection{Tasks and Synchronisation}

\subsubsection{Program Structure and Compilation Issues}

\subsubsection{Exceptions}

\subsubsection{Generic Units}

\subsubsection{Representation Issues}

\subsection{End of Translation From SPARK to SPARK}

\subsection{End of Translation From SPARK to Why}

from intermediate SPARK code in a reduced subset of SPARK

\end{document}
