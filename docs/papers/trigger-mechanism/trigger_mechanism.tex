\documentclass[a4paper,11pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[francais,english]{babel}
\usepackage{mathpartir}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}

\newcommand{\atoms}{\mathit{atoms}}
\newcommand{\terms}{\mathit{terms}}
\newcommand{\atom}{\mathit{atom}}
\newcommand{\F}{\mathit{form}}
\newcommand{\T}{\mathit{lab}}
\newcommand{\A}{\mathit{assume}}
\newcommand{\B}{\mathit{bcp}}
\newcommand{\Si}{\mathit{size}}
\newcommand{\impbox}{\vDash\bot}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\renewcommand{\qedsymbol}{\ensuremath{\diamondsuit}}

%opening
\title{A model of the trigger mechanism in SMT Solvers}
\author{Claire Dross}

\begin{document}
\selectlanguage{english}
\maketitle

\section{Introduction}
The SAT plus theory kernel used by SMT-Solvers only works on ground clauses. To handle first-order formulas,
some SMT-solvers are using an instantiation mechanism
which takes universally quantified formulas and returns ground instances. The main concern is to
decide which instances are relevant. Indeed, if too many instances are generated, the solver will be
overwhelmed and if too few are generated, it will miss some proofs. A common mechanism to decide
which instances of quantified formulas are relevant is the trigger mechanism, first described
by David Detlefs, Greg Nelson, and James B. Saxe~\cite{simplify}.
Sets of terms called triggers are added to quantified formulas.
Each time a ground literal is assumed by the solver, all its sub-terms are
added to the set of encountered terms. A relevant instance is an instance for which every term
in the trigger is mapped to a term contained in the set of encountered terms.

With this trigger mechanism, the burden of choosing relevant instances is transformed into the
burden of choosing appropriate triggers. And indeed, it is difficult to generate them
automatically. Yelting Ge has developed some heuristics for instantiation in CVC3~\cite{Ge-2010}
but algorithms based on instantiation are only complete on some fragments of first-order logic.
What is more, putting them by hand requires a rather important understanding of the
trigger mechanism. Micha\l{} Moskal~\cite{moskal-2009} presents some triggering patterns and some
developmental practices to use the control given by the trigger mechanism.
In this paper, we focus on giving a simple model of the trigger mechanism.
We believe it will help people writing efficient triggers and also lead to an efficient way
of automatically generating them.

As a running example, let's consider the set of first-order formulas in Figure \ref{fo-ex}.
Ignoring the trigger in the first formula, this set is clearly unsatisfiable. With the trigger,
we will see that the behavior of the solver is unpredictable (it can either return \emph{Sat}
or \emph{Unsat}).
\begin{figure}
 \begin{eqnarray*}
 \forall x[P(x)]. (P(x)\vee Q(x))\rightarrow R(x)\\
 P(c)\vee Q(c)\\
 \neg R(c)
\end{eqnarray*}
\caption{\label{fo-ex}Example of a set of first-order formulas with triggers.}
\end{figure}

The first five sections describe a propositional model of the trigger mechanism. The first section
describes an extended propositional model, the second focuses on obtaining a predictable behavior,
the third describes environments that model the state of the solver, the fourth gives the rules for a
simplified solver and the fifth describes some interesting properties of our model.
The last section quickly reproduces the same steps for a first-order model.
\section{Description of the Propositional Model}
Classically, propositional logic deals with formulas over atoms.
Here, we add what we call labeled formulas.
Concretely, we have the possibility to prefix a formula by a set of atoms, called a label, to express
that the formula is only available when these atoms have been encountered. This is written $[a]F$
were $a$ is label and $F$ a formula.
We consider a propositional version of the running example in Figure \ref{p-ex}. As before, the set
of formulas would clearly be unsatisfiable if it were not for the label in the first formula.

\begin{figure}
\begin{eqnarray*}
 [A]~(A\vee B)\rightarrow C\\
 A\vee B\\
 \neg C
\end{eqnarray*}
\caption{\label{p-ex}A Propositional version of the first-order example of Figure \ref{fo-ex}.}
\end{figure}

\subsection{Negation}
For labeled formulas to be usable, we need to define the negation of such a formula. Since $[a]F$
means that \emph{if the elements of $a$ are present then $F$}, the expected meaning of its negation is
\emph{assume the presence of every element in $a$ and also $\neg F$}. To express that, we add a new type
of labeled formulas called positively labeled and written $\langle a\rangle F$. In opposition, $[a]F$
is said to be negatively labeled.
As a consequence, a labeled formula is a classical formula over what we call \emph{elements}:
\begin{itemize}
 \item literals: $L$ can be $A$ or $\neg A$,
 \item positively labeled formulas: $\langle a\rangle F$ is true if every element of $a$ is present
and $F$ is true,
 \item negatively labeled formulas: $[a]F$ is true if, if every element of $a$ is present,
then $F$ is true.
\end{itemize}
where $a$ is a label and $F$ a labeled formula.
The negation over elements is defined as expected:
\begin{itemize}
 \item $\neg L=\overline L$,
 \item $\neg(\langle a\rangle F)=[a]\neg F$,
 \item $\neg([a]F)=\langle a\rangle\neg F$.
\end{itemize}
\subsection{Clausal form}
Like labeled formulas, \emph{labeled clauses} are clauses over elements.
The function $\downarrow$ puts formulas into clausal form. We request that $\downarrow F$
returns a set of labeled clauses, the conjunction of which is equivalent to $F$.

In the following sections, we call $D$ elements, $F$ labeled formulas and $C$ labeled clauses.

\section{Explicit Labelization}
In this section we describe a preprocessing that makes updates to the set of encountered atoms
explicit and we motivate on our running example the fact that this preprocessing should make the solver
predictable (the solver cannot return both \emph{Sat} and \emph{Unsat} on any set of formulas).
\subsection{Description}
The usual way of dealing with the set of encountered atoms is to add to this set every atom
contained in an assumed literal. This makes the solver unpredictable as we see on an example in
the next subsection.
To avoid the unpredictability of the solver, we make updates of the set of encountered atoms explicit.
We use we apply a preprocessing step that we call \emph{positive labelization}.
We replace each literal $L$ in the clausal form of a formula
by a positively labeled formula $\langle\atom(L)\rangle L$. By definition of positive labelization,
assuming such an element will add $\atom(L)$ to the set of encountered atoms and then assume $L$.
We define two labeling functions on literals:
\begin{itemize}
 \item $\T_+(L)=\langle\atom(L)\rangle L$,
 \item $\T_-(L)=[\atom(L)]L$.
\end{itemize}
$\T$ is defined on formulas so that it labels positive occurrences of literals with $\T_+$ and
negative occurrences with $\T_-$. It is easy to see that this is equivalent to labeling
positively literals that appear in the clausal form of the formula and that labeling preserves
clausal form.
\subsection{Motivation}
The usual way of dealing with the set of encountered atoms is to add to this set every atom present
in an assumed literal. But this makes the solver unpredictable as seen on the running
example. When handling the clause $A\vee B$, a SAT-solver can either focus on $A$ or $B$ first. If it is
$A$, two branches will be introduced, one will assume $A$ and the other $\neg A$. In both branches,
the atom $A$ will be added to the set of encountered atoms. Therefore, the labeled formula
$[A]~(A\vee B)\rightarrow C$ will be available in both branches and the solver will find the unsatisfiability
of the set of formulas.
\begin{eqnarray*}
&
\inferrule{
\{[A]~(A\vee B)\rightarrow C,\ A,\ \neg C\}\\
\{[A]~(A\vee B)\rightarrow C,\ \neg A,\ B,\ \neg C\}
}{\{[A]~(A\vee B)\rightarrow C,\ A\vee B,\ \neg C\}}
\end{eqnarray*}
If the solver focuses on $B$ first, then one branch will assume $B$, making
$A$ disappear, $[A]~(A\vee B)\rightarrow C$ will not be available and the solver will not find
a proof of unsatisfiability.
\begin{eqnarray*}
&
\inferrule{
\{[A]~(A\vee B)\rightarrow C,\ B,\ \neg C\}\\
\{[A]~(A\vee B)\rightarrow C,\ \neg B,\ A,\ \neg C\}
}{\{[A]~(A\vee B)\rightarrow C,\ A\vee B,\ \neg C\}}
\end{eqnarray*}

\begin{figure}
\begin{eqnarray*}
 [A]~(([A]A)\vee([B]B))\rightarrow\langle C\rangle C\\
 (\langle A\rangle A)\vee(\langle B\rangle B)\\
 \langle C\rangle\neg C
\end{eqnarray*}
\caption{\label{pl-ex}Formulas of Figure \ref{p-ex} explicitly labeled.}
\end{figure}

We apply $\T$ to our running example. We get the set of formulas in Figure \ref{pl-ex}.
Now, if the solver focuses on $\langle A\rangle A$ first, it will assume $[A]\neg A$ in the second branch.
This will no longer allow it to deduce the unsatisfiability of the set of formulas.
\begin{eqnarray*}
&
\inferrule{
\{[A]~\dots,\ \langle A\rangle A,\ \langle C\rangle\neg C\}\\
\{[A]~\dots,\ [A]\neg A,\ \langle B\rangle B,\ \langle C\rangle\neg C\}
}{\{[A]~(([A]A)\vee([B]B))\rightarrow\langle C\rangle C,\
(\langle A\rangle A)\vee(\langle B\rangle B),\ \langle C\rangle\neg C\}}
\end{eqnarray*}
\section{Environment}
In this section, we present our model of the state of a solver, called environment, define
what it means that a labeled clause is known to be true in a given state and finally describe how
the environment is modified when an element is assumed.
\bigskip

\noindent
Environments are quadruplets:
\begin{itemize}
 \item $K$ is a set of negatively labeled formulas,
 \item $\Delta$ is a set of labeled clauses,
 \item $G$ is a set of literals,
 \item $M$ is a set of atoms.
\end{itemize}
They model the state of the solver. For a solver in a state $\{K,\Delta,G,M\}$, negatively labeled
formulas in $K$, clauses in $\Delta$ and literals in $G$ are assumed and atoms in $M$ have been
encountered.
\subsection{Shallow Implication}
We need a notion of implication to model the fact that a solver already knows that a labeled clause
is true in its state. The shallow implication is an implication that does not descend
under triggers. It is defined both for an element $D$ and for a labeled clause $C$.
For a labeled clause $C$, we say that $\{K,\Delta,G,M\}\Vdash C$ when either:
\begin{itemize}
 \item there is a sub-clause $C'\subseteq C$ such that $C'\in\Delta$, or
 \item there is an element $D\in C$ such that $\{K,\Delta,G,M\}\Vdash D$.
\end{itemize}
For an element $D$, the shallow implication is defined as:
\begin{itemize}
 \item $\{K,\Delta,G,M\}\Vdash L$ if and only if $L\in G$,
 \item $\{K,\Delta,G,M\}\Vdash\langle a\rangle F$ if and only if $a\subseteq M$ and, 
for all $C\in\downarrow F$, $\{K,\Delta,G,M\}\Vdash C$ 
 \item $\{K,\Delta,G,M\}\Vdash[a]F$ if and only if $[a]F\in K$.
\end{itemize}
\subsection{Assumption of Elements}
The $\A$ function properly handles the way elements are added to the environment when assumed
by the solver:
\begin{itemize}
 \item $\A(\{K,\Delta,G,M\},L)=\{K,\Delta,G\cup L,M\}$,
 \item $\A(\{K,\Delta,G,M\},\langle a\rangle F)=\{K,\Delta\cup\downarrow F,G,M\cup a\}$,
 \item $\A(\{K,\Delta,G,M\},[a]F)=\{K\cup([a]F),\Delta,G,M\}$.
\end{itemize}
Literals and negatively labeled formulas are added respectively to $G$ and $K$. When a positively
labeled formula $\langle a\rangle F$ is assumed, elements of the label $a$ are added to the
set of encountered atoms $M$ and the clausal form of $F$ is added to $\Delta$.
\section{Derivation}
In this section, we introduce a simple set of rules to derive labeled propositional formulas and then
specify when a solver is allowed to return \emph{Sat} or \emph{Unsat} thanks to these rules.
Here we assume no previous treatment of formulas. It would have been possible to suppose them to be in
CNF or lazy-CNF to show that the treatment is independent of the form of the formulas. To substantiate
this claim, we use lazy-CNF for first-order formulas. Neither do we
consider the optimization of Boolean constraint propagation.
\subsection{Rule System}
The set of rules in Figure \ref{p-sr} models the way a solver tries to derive a proof of unsatisfiability
an environment $\{K,\Delta,G,M\}$ written $\{K,\Delta,G,M\}\impbox$. The rule \textsc{Base} states that
an environment is unsatisfiable if it has assumed contradictory literals ($\vdash$ is the usual
implication). The rules \textsc{Unsat} and
\textsc{Sat} represent a simple SAT-solver. The rule \textsc{Instantiation} models the way labels
are handled, allowing the use of a labeled formula $[a]F$ only if every atom in $a$ is present.

\begin{figure}
\begin{eqnarray*}
&
\inferrule [Unsat]{
\Box\in \Delta
}{
\{K,\Delta,G,M\}\impbox
}\qquad
\inferrule [Base]{
G\vdash\Box
}{
\{K,\Delta,G,M\}\impbox
}\\
&
\inferrule [Instantiation]{
[a]F \in K  \\ a \subseteq M \\ \{K,\Delta\cup\downarrow F,G,M\}\impbox
}{
\{K,\Delta,G,M\}\impbox
}\\
&
\inferrule [Sat]{
\A(\{K,\Delta,G,M\},D)\impbox\\ \A(\{K,\Delta\cup C,G,M\},\neg D)\impbox
}{
\{K,\Delta\cup(D\vee C),G,M\}\impbox
}
\end{eqnarray*}
\caption{\label{p-sr} Rule system for propositional formulas.}
\end{figure}

\subsection{Saturation}
A solver can return \emph{Unsat} on a set of formulas $R$ if it has derived a proof of
$\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\}\impbox$. We now want to define when
it is allowed to return \emph{Sat}. We say an environment $\{K,\Delta,G,M\}$ is saturated if
\begin{enumerate}
 \item $G\nvdash\Box$
 \item $\{K,\varnothing,G,M\}\Vdash\Delta$
 \item $\forall [a]F\in K.\ a\subseteq M\Rightarrow \{K,\varnothing,G,M\}\Vdash\downarrow F$.
\end{enumerate}
Intuitively, nothing more can be deduced on a saturated environment, neither by \textsc{Base}
by 1, nor by \textsc{Unsat} or \textsc{Sat} by 2, nor by \textsc{Instantiation} by 3.
As a consequence, a solver can return \emph{Sat} on a set of formulas $R$ if it has reached
a saturated state while deriving a proof of
$\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\}\impbox$.
\section{Properties of the model}
We previously stated that the explicit labelization of formulas made the solver predictable.
In this section, we show that this is indeed the case by stating an encoding from
explicitly labeled formulas to classical propositional formulas that preserves satisfiability.
We then relate the satisfiability of a set of formulas to the satisfiability of
its explicit labelization and give the proof of this relation.
\subsection{Predictability}
We define a function $\F$ that constructs a classical formula from a labeled formula. We use
a function, named $p$, which maps atoms to fresh atoms that encode their presence. $\F$ is
structurally defined on labeled formulas as:
\begin{itemize}
 \item $\F([A_1,\ \dots,\ A_n]F)=p(A_1)\wedge\dots\wedge p(A_n)\rightarrow \F(F)$,
 \item $\F(\langle A_1,\ \dots,\ A_n\rangle F)= p(A_1)\wedge\dots\wedge p(A_n)\wedge \F(F)$.
\end{itemize}
$\F$ keeps every other construction unchanged. It makes the effect of labels explicit. Since a
negatively labeled formula $[A_1,\ \dots,\ A_n]F$ should mean $F$ if $A_1,\ \dots,\ A_n$ are
present, it is translated as $p(A_1)\wedge\dots\wedge p(A_n)\rightarrow \F(F)$. We extend
$\F$ to environments as expected:
\begin{itemize}
 \item $\F(\{K,\Delta,G,M\})=\{\F(F)|F\in K\}\cup\{\F(F)|F\in\Delta\}\cup G\cup\{p(A)|A\in M\}$.
\end{itemize}
We want to show that the result of a run of the SAT-Solver on an environment $e$ is constrained by
the satisfiability of the classical formula $\F(e)$. We first need some simple lemmas for which we do
not give the proof.
{\lemma $\F(F)\Leftrightarrow\F(\downarrow F)$.}\\
Putting a formula into clausal form does not change its meaning.
{\lemma $\F(\A(e,D))\Leftrightarrow\F(e)\cup\F(D)$.}\\
The call $\A(e,D)$ exactly adds the information that the element $D$ is true to the information
already in the environment $e$.
{\lemma If $e\Vdash C$ then $\F(e)\vdash\F(C)$.}\\
The shallow implication is correct, even if it is obviously not complete.

The following theorems are linking the possible results of a run of the solver to the satisfiability
of the classical formula handed out by $\F$.
{\theorem\label{pred1} If a solver can return \emph{Unsat} on a set of formulas $R$ then we have
$\F(\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\})\vdash\Box$.}
\begin{proof}
By definition, if the solver can return \emph{Unsat} on $R$ there is a proof of
$\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\}\impbox$. Let us show that,
for any environment $e$, if there is a proof of $e\impbox$ then $\F(e)\vdash\Box$ by structural
induction over the proof of $\{K,\Delta,G,M\}\impbox$.
\begin{itemize}
 \item if the last applied rule is \textsc{Base} or \textsc{Unsat}, the conclusion is trivial.
 \item if the last applied rule is \textsc{Instantiation}, there is $[a]F\in K$ such that
$a\subseteq M$ and $\{K,\Delta\cup\downarrow F,G,M\}\impbox$. By induction hypothesis,
$\F(\{K,\Delta\cup\downarrow F,G,M\})\vdash\Box$. Since $[a]F\in K$ and $a\subseteq M$,
$\F(\{K,\Delta,G,M\})\vdash\F(F)$. As a conclusion, since $\F(F)\Leftrightarrow\F(\downarrow F)$,
$\F(\{K,\Delta,G,M\})\vdash\F(\{K,\Delta\cup\downarrow F,G,M\})\vdash\Box$.
 \item if the last applied rule is \textsc{Sat}, there is a clause $D\vee C$ such that
$\A(\{K,\Delta,G,M\},D)\impbox$ and $\A(\{K,\Delta\cup C,G,M\},\neg D)\impbox$.
By induction hypothesis, $\F(\A(\{K,\Delta,G,M\},D))\vdash\Box$ and
$\F(\A(\{K,\Delta\cup C,G,M\},\neg D))\vdash\Box$. Since, for all environment $e$,
$\F(\A(e,D))\Leftrightarrow\F(e)\cup\F(D)$,
$\F(\{K,\Delta\cup(D\vee C),G,M\})\vdash\Box$.
\end{itemize}
\end{proof}
{\theorem\label{pred2} If a solver can return \emph{Sat} on a set of formulas $R$ then we have
$\F(\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\})\nvdash\Box$.}
\begin{proof}
By definition, if the solver can return \emph{Sat} on $R$ there is a derivation from
$\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\}$ to a saturated state $\{K,\Delta,G,M\}$. Since
if $\F(\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\})\vdash\Box$ then
$\F(\{K,\Delta,G,M\})\vdash\Box$ (immediate induction on the derivation), it is enough to show that
$\F(\{K,\Delta,G,M\})\nvdash\Box$.
Let's consider $I$ the model that maps $\{A|A\in G\}\cup\{p(A)|A\in M\}$ to true and the rest to false.
We show that $I\vdash\F(e)$. Since $\{K,\Delta,G,M\}$ is saturated, $G\nvdash\Box$ and
$I\vdash G\cup\{p(A)|A\in M\}$. For all $[a]F\in K$ either $a\nsubseteq M$, $I\nvdash\{p(A)|A\in a\}$
and $I\vdash\F([a]F)$ or $a\subseteq M$. Since $\{K,\Delta,G,M\}$ is saturated,
$\{K,\varnothing,G,M\}\Vdash\downarrow F$. By construction of $\Vdash$, $\{K|_{<F},\varnothing,G,M\}
\Vdash\downarrow F$ where
$K|_{<F}$ is the restriction of $K$ to formulas of smaller size\footnote{
We define the size:
\begin{itemize}
 \item of a literal: $\Si(L)=1$
 \item of a labeled formula: $\Si([a]F)=\Si(\langle a\rangle F)=1+\Si(F)$
 \item of a clause: $\Si(C)=\sum_{D\in C}\Si(D)$
 \item of a formula: $\Si(F)=\sum_{C\in\downarrow F}\Si(C)$.
\end{itemize}}
than $F$. Since $e\Vdash C\Rightarrow\F(e)\vdash\F(C)$,
$\F(\{K|_{<F},\varnothing,G,M\})\vdash\F(F)$. Induction over
the size of normal forms of $[a]F\in K$ gives that $I\vdash\F([a]F)$.
And since $\{K,\varnothing,G,M\}\Vdash\Delta$, $I\vdash\Delta$.
\end{proof}

As a consequence, a solver can never return both \emph{Sat} and \emph{Unsat}.
{\corollary The solver is predictable.}\\
What is more, without quantifiers, there is an algorithm that always ends up returning either \emph{Sat}
or \emph{Unsat}.

{\theorem\label{comp} A solver can either return \emph{Sat} or \emph{Unsat} on every set of formulas $R$.}
\begin{proof}
We say that $K_1$ is saturated with respect to $K_2$, $G$, $M$ and $\Delta$ if, for all $[a]F\subseteq K_1$,
$a\in M$ and $\{K_1\cup K_2,\Delta,G,M\}\Vdash\downarrow F$.
We assume that a solver cannot reach a saturated state from
$\{K_1\cup K_2,\Delta,G,M\}$ and that $K_1$ is saturated with respect to $K_2$, $G$, $M$ and $\Delta$.
To show that a solver can deduce $\{K_1\cup K_2,\Delta,G,M\}\Vdash\Box$,
we proceed by well-founded induction based on the lexicographic order (size of $K_2\cup \Delta$,
size of $\Delta$).
\begin{itemize}
 \item If $G\nvdash\Box$, for all $[a]F\in K_2$, $a\nsubseteq M$ and $\Delta=\varnothing$,
then, by definition,  $\{K_1\cup K_2,\Delta,G,M\}$ is saturated which contradicts the hypothesis.
 \item If $G\vdash\Box$, $\{K_1\cup K_2,\Delta,G,M\}\impbox$ can be deduced by \textsc{Base}.
 \item If there is $[a]F\in K_2$ such that $a\subseteq M$, then a solver
cannot reach a saturated state from $\{K_1\cup K_2,\Delta\cup\downarrow F,G,M\}$ or it could
reach it from $\{K_1\cup K_2,\Delta,G,M\}$ by \textsc{Instantiation}.
$K_1\cup [a]F$ is saturated with respect to $K_2\setminus[a]F$, $G$, $M$ and $\Delta\cup\downarrow F$
and $\{(K_1\cup [a]F)\cup(K_2\setminus[a]F),\Delta\cup\downarrow F,G,M\}$ is strictly smaller than
$\{K_1\cup K_2,\Delta,G,M\}$. By induction hypothesis,
a solver can deduce $\{K_1\cup K_2,\Delta\cup\downarrow F,G,M\}\impbox$.
As a consequence, it can also deduce $\{K_1\cup K_2,\Delta,G,M\}\impbox$ by \textsc{Instantiation}.
 \item If $\Delta$ can be written $\Delta\cup D\vee C$, then a solver
cannot reach a saturated state from $\A(\{K_1\cup K_2,\Delta,G,M\},D)$ or
$\A(\{K_1\cup K_2,\Delta\cup C,G,M\},\neg D)$ or it could
reach it from $\{K_1\cup K_2,\Delta\cup C,G,M\}$ by \textsc{Sat}.
It is easy to check that $\A(\{K_1\cup K_2,\Delta\cup C,G,M\},\neg D)$ and
$\A(\{K_1\cup K_2,\Delta,G,M\},D)$ are strictly smaller than $\{K_1\cup K_2,\Delta\cup C,G,M\}$
and that we can deduce $\A(\{K_1\cup K_2,\Delta\cup C,G,M\},\neg D)\impbox$ and
$\A(\{K_1\cup K_2,\Delta,G,M\},D)\impbox$ by induction hypothesis.
As a consequence, the solver can deduce $\{K_1\cup K_2,\Delta\cup D\vee C,G,M\}\impbox$ by \textsc{Sat}.
\end{itemize}
\end{proof}

\subsection{Justification of Explicit Labelization}
We want to find a link between the classical trigger mechanism and our new predictable mechanism.
In order to describe a solver without explicit labelization $\T$ with our rule system,
we only need to modify $\A$ so that
assuming a literal adds its atom to the set of encountered atoms:
\begin{itemize}
 \item $\A'(\{K,\Delta,G,M\},L)=\{K,\Delta,G\cup L,M\cup\atom(L)\}$
\end{itemize}

The two following theorems state that a solver that follows the deterministic set of rules can return
\emph{Unsat} on any set of formulas $R$ on which the classical one cannot return \emph{Sat}.
{\theorem If a solver with explicit labelization can return \emph{Unsat} on $R$ then
a solver without explicit labelization cannot return \emph{Sat} on $R$.}
\begin{proof}
Same as Theorem \ref{pred2}.
\end{proof}

{\theorem If a solver without explicit labelization cannot return \emph{Sat} on $R$ then
a solver with explicit labelization can return \emph{Unsat} on $R$.}
\begin{proof}
In the proof of Theorem \ref{comp}, the only step that is modified is the last one.
If $\Delta$ can be written $\Delta\cup C$, then, for every $D\in C$, a solver without explicit labelization
cannot reach a saturated state from $\A'(\{K_1\cup K_2,\Delta,G,M\},D)$ or it could
reach it from $\{K_1\cup K_2,\Delta\cup C,G,M\}$ by \textsc{Sat}.
It is easy to check that 
$\A'(\{K_1\cup K_2,\Delta,G,M\},D)$ is strictly smaller than $\{K_1\cup K_2,\Delta\cup C,G,M\}$
and that, by induction hypothesis, a solver with explicit labelization can prove
$\T(\A'(\{K_1\cup K_2,\Delta,G,M\},D))\impbox$. Since
$\T(\A'(e,D))=\A(\T(e),\T(D))$,
a solver with explicit labelization can deduce, with as many applications of \textsc{Sat} as the number
of elements in $C$ and one application of \textsc{Unsat} that
$\T(\{K_1\cup K_2,\Delta\cup C,G,M\})\impbox$.
\end{proof}

As a consequence, we have handed out a predictable system that models the unpredictable one. It only
returns \emph{Unsat} when a classical solver could not have returned \emph{Sat}.

\section{Adaptation to First-Order Logic}
In this section, we reproduce the same reasoning we did in propositional logic in first-order logic.
We assume that formulas are in negation normal form. That means that a formula can either be:
\begin{itemize}
 \item a literal: $L$.
 \item a unit: $F_1\wedge F_2$. Units are seen as auxiliary atoms, whose assumption implies
assumption of $F_1$ and $F_2$ and whose negation implies assumption of a clause $\neg F_1\vee \neg F_2$.
 \item a clause: $F_1\vee F_2$. As units, clauses are seen as auxiliary atoms.
 \item a skolem: $\langle\overline x,a,\sigma\rangle F$. Skolems are existentially quantified formulas.
$\sigma$ maps variables in $\overline x$ to skolem functions. $a$ is a set of terms, which, as in the 
propositional case, will be assumed to be present when the skolem is assumed.
 \item a lemma: $[\overline x,a,\sigma]F$. Lemmas are existentially quantified formulas. $\overline x$
is the set of quantified variables and $a$ is the set of terms that should be present for $F$ to be
assumed. $\sigma$ is a skolem substitution. It will be used if the lemma is negated and becomes a skolem.
\end{itemize}
\begin{figure}
 \begin{eqnarray*}
 [x,P(x),x\mapsto b](\neg P(x)\wedge\neg Q(x))\vee R(x)\\
 P(c)\vee Q(c)\\
 \neg R(c)
\end{eqnarray*}
\caption{\label{fo-exn}Formulas of Figure \ref{fo-ex} in lazy normal form.}
\end{figure}
We define $\T$ that labels literals with positive labels. Since formulas are in lazy
normal form, every literal occurs positively and is consequently labeled with:
\begin{itemize}
 \item $\T(L)=\langle\varnothing,\terms(L),\sigma_\varnothing\rangle L$ which we write
$\langle\terms(L)\rangle$ for readability.
\end{itemize}
\begin{figure}
 \begin{eqnarray*}
 [x,P(x),x\mapsto b](\langle x,P(x)\rangle\neg P(x)\wedge
\langle x,Q(x)\rangle\neg Q(x))\vee
\langle x,R(x)\rangle R(x)\\
 \langle c,P(c)\rangle P(c)\vee
\langle c,Q(c)\rangle Q(c)\\
 \langle c,R(c)\rangle\neg R(c)
\end{eqnarray*}
\caption{\label{fol-ex}Formulas of Figure \ref{fo-exn} explicitly labeled.}
\end{figure}

\subsection{Environment}
As in the propositional model, environments are quadruplets:
\begin{itemize}
 \item $K$ is a set of lemmas,
 \item $\Delta$ is a set of clauses,
 \item $G$ is a set of ground literals,
 \item $M$ is a set of ground terms.
\end{itemize}
The shallow implication is here defined over formulas as:
\begin{itemize}
 \item $\{K,\Delta,G,M\}\Vdash L$ if and only if $L\in G$,
 \item $\{K,\Delta,G,M\}\Vdash F_1\wedge F_2$ if and only if both $\{K,\Delta,G,M\}\Vdash F_1$
and $\{K,\Delta,G,M\}\Vdash F_2$,
 \item $\{K,\Delta,G,M\}\Vdash F_1\vee F_2$ if and only if either
$\{K,\Delta,G,M\}\Vdash F_1$, $\{K,\Delta,G,M\}\Vdash F_2$, or $F_1\vee F_2\in\Delta$.
 \item $\{K,\Delta,G,M\}\Vdash\langle\_,a,\sigma\rangle F$ if and only if $\{K,\Delta,G,M\}\Vdash F\sigma$
and $a\sigma\subseteq M$,
 \item $\{K,\Delta,G,M\}\Vdash[\overline x,a,\sigma]F$ if and only if $[\overline x,a,\sigma]F\in K$.
\end{itemize}
The $\A$ function has to handle every kind of formulas. It is defined as:
\begin{itemize}
 \item $\A(\{K,\Delta,G,M\},L)=\{K,\Delta,G\cup L,M\}$,
 \item $\A(e,F_1\wedge F_2)=\A(\A(e,F_1),F_2)$,
 \item $\A(\{K,\Delta,G,M\},\langle\_,a,\sigma\rangle F)=
\A(\{K,\Delta,G,M\cup a\sigma\},F\sigma)$,
 \item $\A(\{K,\Delta,G,M\},[\overline x,a,\_]F)=\{K\cup([\overline x,a,\_]F),\Delta,G,M\}$,
 \item $\A(\{K,\Delta,G,M\},F_1\vee F_2)=\{K,\Delta\cup(F_1\vee F_2),G,M\}$.
\end{itemize}
We want to add boolean constraint propagation for efficiency. As a consequence, we introduce a function named $\B$.
It abstracts away the cases where a boolean constraint propagation can be applied:
\begin{itemize}
 \item if $\{K,\Delta,G,M\}\Vdash F_i$, then we have $\{K,\Delta,G,M\}\in\B(\{K,\Delta\cup(F_1\vee F_2),G,M\})$,
 \item if $\{K,\Delta,G,M\}\Vdash\neg F_i$, then we have $\A(\{K,\Delta,G,M\},F_{3-i})\in
\B(\{K,\Delta\cup(F_1\vee F_2),G,M\})$.
\end{itemize}
\subsection{Derivation}
As before, we introduce a set of rules in Figure \ref{fo-rs} to derive satisfiability of environments.
The handling of the sat mechanism has been simplified by the fact that formulas are in lazy normal form, 
merging the previous \textsc{Sat} and \textsc{Unsat} rules into one single \textsc{Sat} rule. The
\textsc{Bcp} rule applies a boolean constraint propagation when possible.
\begin{figure}
\begin{eqnarray*}
&
\inferrule [Base]{
G\vdash\Box
}{
\{K,\Delta,G,M\}\impbox
}\qquad
\inferrule [Bcp]{
e'\impbox\\ e'\in\B(e)
}{
e\impbox
}\\
&
\inferrule [Instantiation]{
[\overline x,a,\sigma]F\in K\\ dom(\sigma)=\overline x\\ a\sigma\subseteq M\\
\A(\{K,\Delta,G,M\},F\sigma)\impbox
}{
\{K,\Delta,G,M\}\impbox
}\\
&
\inferrule [Sat]{
\A(\{K,\Delta,G,M\},F_i)\impbox\\ \A(\A(\{K,\Delta,G,M\},F_{3-i}),\neg F_i)\impbox
}{
\{K,\Delta\cup(F_1\vee F_2),G,M\}\impbox
}
\end{eqnarray*}
\caption{\label{fo-rs} Rule system for first-order formulas.}
\end{figure}

We keep the same notion of saturation:
\begin{itemize}
 \item $G\nvdash\Box$,
 \item $\{K,\Delta,\varnothing,M\}\Vdash\Delta$,
 \item for all $[\overline x,a,\_]F\in K$ and all $\sigma$ such that
$dom(\sigma)=\overline x$ and $a\sigma\subseteq M$,
$\{K,\varnothing,G,M\}\Vdash F\sigma$.
\end{itemize}
\subsection{Properties}
As we did before, we define an encoding from labeled first-order formulas to classical
first-order formulas. $p$ now maps terms to fresh atoms.
\begin{itemize}
 \item $\F(L)=L$,
 \item $\F(F_1\wedge F_2)=\F(F_1)\wedge\F(F_2)$,
 \item $\F(F_1\vee F_2)=\F(F_1)\vee\F(F_2)$,
 \item $\F(\langle\overline x,a,\_\rangle F)=\exists\overline x.\bigwedge_{t\in a} p(t)\wedge\F(F)$,
 \item $\F([\overline x,a,\_]F)=\forall \overline x.\bigwedge_{t\in a} p(t)\rightarrow\F(F)$.
\end{itemize}
We extend it to environments:
\begin{itemize}
 \item $\F(\{K,\Delta,G,M\})=\{\F(F)|F\in K\}\cup\{\F(F)|F\in\Delta\}\cup G\cup\{p(t)|t\in M\}$
\end{itemize}
To link the result of a solver to the satisfiability of the classical first-order formula handed out
by $\F$, we need 3 lemmas.
{\lemma $\F(\A(e,F))$ and $\F(e)\cup\F(F)$ are equisatisfiable.}\\
As in the propositional case, $\A$ has the expected meaning of adding the fact that a formula $F$
is true to the set of already gathered information.
{\lemma If $e\Vdash F$ then $\F(e)\vdash\F(F)$.}\\
The shallow implication is correct.
{\lemma If $e'\in\B(e)$ then $\F(e)$ and $\F(e')$ are equisatisfiable.}\\
Boolean constraint propagation does not change the validity of a set of formulas.

We fist show that the solver is predictable. For the sake of simplicity,
the proofs are omitted (they closely resemble those for the propositional case).
{\theorem If a solver can return \emph{Unsat} on a set of formulas $R$ then we have
$\F(\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\})\vdash\Box$.}
{\theorem If a solver can return \emph{Sat} on a set of formulas $R$ then we have
$\F(\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\})\nvdash\Box$.}
{\corollary The solver is predictable.}

The preceding theorems only constrain cases where the solver can return a result.
There could be sets of formulas $R$ on which a solver can only loop. We want to prove that, without
theories, a solver could always find the expected result (which does not means that there is an algorithm
that will hand over such a result on every $R$).
{\theorem If, for a set of formulas $R$, there is a finite set of instances of
$\F(\{\varnothing,\downarrow\T(R),\varnothing,\varnothing\})$ which is unsatisfiable,
a solver can return \emph{Unsat} on $R$.}\\
By compactness, it is always the case when there is no theory that goes
beyond first-order logic.

Now, to link this predictable solver to classical ones,
we consider the solver without explicit labelization. The $\A$ function is modified so that
assuming a literal adds its sub-terms to the set of encountered terms:
\begin{itemize}
 \item $\A'(\{K,\Delta,G,M\},L) = \{K,\Delta,G\cup L, M\cup\atom(L)\}$
\end{itemize}

{\theorem If a solver with explicit labelization can return \emph{Unsat} on $R$ then
a solver without explicit labelization can return \emph{Unsat} and cannot return \emph{Sat} on $R$.}

Notice that the opposite cannot be true. Indeed, on the set
$R=\{f(c)\vee f(b), [f(c)]\Box, \forall x[f(x)]. f(g(x))\}$, a solver without explicit labelization
can return \emph{Unsat} and cannot return \emph{Sat} since the quantified formula induces an
instantiation loop. But a solver with explicit labelization can obviously not return \emph{Unsat} on
$R$.

\section{Conclusion and Future Work}
While trying to model the trigger mechanism used in some SMT-Solvers, we encountered a problem of
unpredictability. To solve it, we introduced a predictable set of rules that models the trigger
mechanism in first-order logic. We have then related it to the usual, non predictable, mechanism.
We have shown that it is a down leveling, since it can only return \emph{Unsat} when the
classical solvers can return \emph{Unsat} and cannot return \emph{Sat}. But also that it is not overly
restrictive. Indeed, we have produced a first-order translation of triggers in which formulas are
unsatisfiable if and only if the predictable solver can return \emph{Unsat}.

For future work, we would like to use this model to decide if given triggers restrict the use of axioms.
We could come up with some strategies to determine which triggers are more restrictive and
also find some heuristics to generate them automatically.

\bibliographystyle{plain}
\bibliography{trigger_mechanism}

\end{document}
