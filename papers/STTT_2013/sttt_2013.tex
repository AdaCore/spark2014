\documentclass[sttt,draft]{svjour}
% relevant options: draft, referee, final
%
%\usepackage{latexsym}
%\usepackage{graphics}
%\usepackage{amssymb}
%\usepackage{amsfonts,amsmath}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{xspace}
\usepackage{listings}
\lstset{language=Ada}

%
\newcommand{\DO}{\textsc{do-178}}
\newcommand{\DOB}{\textsc{do-178b}}
\newcommand{\DOC}{\textsc{do-178c}}
\newcommand{\hilite}{Hi-Lite}
\newcommand{\gnatprove}{GNATprove\xspace}
\newcommand{\oldspark}{SPARK~2005\xspace}
\newcommand{\newspark}{SPARK~2014\xspace}
\newcommand{\ada}{Ada\xspace}
\newcommand{\adatwtw}{Ada~2012\xspace}

\newcommand{\etc}{\textit{etc.}\xspace}
\newcommand{\ie}{\textit{i.e.,}\xspace}
\newcommand{\adhoc}{\textit{ad hoc}\xspace}
\newcommand{\Eg}{\textit{E.g.,}\xspace}
\newcommand{\eg}{\textit{e.g.,}\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}
\newcommand{\wrt}{w.r.t.\xspace}
\newcommand{\aka}{a.k.a.\xspace}
\newcommand{\resp}{resp.\xspace}

\begin{document}
%
\title{\newspark\ and \gnatprove}
\subtitle{A Competition Report from Builders of an Industrial-Strength Verifying Compiler}
\author{Duc Hoang\inst{1} \and Yannick Moy\inst{1} \and Angela Wallenburg\inst{2}
}                     % Do not remove
\institute{AdaCore, \email{\{duc.hoang, yannick.moy\}@adacore.com}
  \and Altran, \email{angela.wallenburg@altran.com}}

\date{Received: date / Revised version: date}
% The correct dates will be entered by Springer
%
\maketitle
%
\begin{abstract}
Insert your abstract here.
\end{abstract}
%
\section{Introduction}
\label{intro}
High quality software, or low defect software, is often costly to
develop. This is a common experience in safety critical systems
development, whether the development is driven by standards such as
\DO, or by any other need to create highly reliable and long-lived
software. Today, extensive and expensive testing is the primary method
used to gain confidence in such software.

The computing research community has been occupied for decades with
the grand challenge of (building) \emph{the verifying compiler}
\cite{Hoare03theverifying}:
%
\begin{quote} A verifying compiler uses mathematical and logical reasoning
  to check the correctness of the programs that it compiles. The
  criterion of correctness is specified by types, assertions, and
  other redundant annotations associated with the code of the
  program. The compiler will work in combination with other program
  development and testing tools, to achieve any desired degree of
  confidence in the structural soundness of the system and the total
  correctness of its more critical components.
\end{quote}

As predicted in \cite{Hoare03theverifying} this grand challenge has
called for for co-operation among research teams and it has encouraged
and benefitted from competition. An example of such beneficial
competition is the VerifyThis competition, which is the context of
this very report.

Great strides have been made in proof automation. At present, static
so called ``push-button'' program verification is achievable for some
substantial classes of industrial programs. New programming language
features for program verification have been explored and theoretical
models of complex existing language features have been devised to
increase the reasoning capabilities for mainstream programming
languages. See \cite{HatcliffLLMP12} for many insights in the
programming language approach to program verification. However, there
are still some remaining challenges before we can expect verifying
compilers to be as widely used as testing.

There are some notable exceptions where formal software verification
has been successfully used and scaled to large industrial projects. For
example the \oldspark\ language and toolset for static verification
has been applied for many years in on-board aircraft systems, control
systems, cryptographic systems, and rail systems
\cite{sparkbook2012,oneill2012}.

We would like to identify two main hurdles currently in the take-up of
verifying compiler technology:
%
\begin{enumerate}
\item difficulty to reach non-expert users, and
\item lack of convincing cost-benefit argument.
\end{enumerate}
%
In this paper we will describe our approach to solve those two
problems in the design of the \newspark\ language and the associated
formal verification tool \gnatprove. We will use running examples from
the VerifyThis 2012 competition and discuss the results of using our
tools on those problems.

This paper is organised as follows: First we describe the key language
features of \newspark, which is a complete update of the
\oldspark\ language and tools designed with many lessons learned from
the programming language and verification community, and naturally
from experiences in industrial use of \oldspark. Then in
Sect. \ref{hilite} we describe our unique integration of testing and
proving. This was developed in the collaborative research project
\hilite\ \cite{hiliteERTS2012} with Altran, AdaCore, and INRIA, to
create a new tool architecture compiler and verifier based on same the
same front-end \cite{ksd2012}. In Sect. \ref{overflowsemantics} we
describe specific language features to be able to allow naturally
writing specifications. We present in Sect. \ref{automation}
GNATprove, our formal verification tool, that is currently a
prototype, and in Sect \ref{verifythis} its results in the VerifyThis
2012 competition. We conclude with future work.

\section{Key Language Features for Verification}
\label{langfeatures}

explain more the dynamic semantics of these features???

\subsection{Ada 2012}

Ada 2012 introduced new language features for facilitating the specification of
programs, many of which were inspired from the corresponding features in SPARK
(ref to John Barnes rational). In the following, we describe some of these that
we used in the solutions for challenge 1 and challenge 2.

The most useful of these new features is without the preconditions and
postconditions popularised by the Design-by-Contract approach (ref to
Meyer). In challenge 1, we can for example specify that function \verb|LCP|
expects arguments within bounds, and that it returns a bounded result. Note the
use of the new \textit{aspect} syntax in Ada 2012, in which the declaration of
\verb|LCP| is followed by keyword \verb|with| and a list of aspects.

\begin{footnotesize}
\begin{verbatim}
function LCP (A : Text; X, Y : Integer) return Natural with
  Pre  => X in A'Range and then Y in A'Range,
  Post => LCP'Result in 0 .. Index'Last;
\end{verbatim}
\end{footnotesize}

In the postcondition of a function, the new attribute \verb|Result| is used to
refer to the result of the function. Another attribute \verb|Old| is used to
refer to the value of some variables on entry to a subprogram, and we used it
in challenge 2.

The expression of specifications is facilitated by new expression forms in Ada
2012. If-expressions and case-expressions are the expression forms which
correspond to the usual if-statements and case-statements. Note that an
if-expression without else-part \verb|(if A then B)| expresses a logical
implication of \verb|B| by \verb|A|. Quantified expressions
\verb|(for all X in A)| and \verb|(for some X in A)| correspond to the
mathematical universal and existential quantifications, only on a bounded
domain. Expression functions define a function with a single expression, like
in functional programming languages. As expression functions can be part of the
specification of programs (contrary to regular function bodies), they are a
preferred way to abstract complex parts of specifications.

\subsection{SPARK 2014}

The new version of SPARK is based on the features of Ada 2012, to which it adds
new ones, some of which inspired from the SPARK 2005.

Like preconditions and postconditions are the most useful new features of Ada
2012 for specification, the loop invariant pragma is the most useful one in
SPARK 2014. A loop invariant can be expressed anywhere in the main list of
statements in a loop, and it expresses the cumulated effect of the loop up to
that point. For example, here is the loop invariant used in challenge 1:

\begin{footnotesize}
\begin{verbatim}
pragma Loop_Invariant (for all K in 0 .. L - 1 => A (X + K) = A (Y + K));
\end{verbatim}
\end{footnotesize}

Note that a loop invariant in SPARK does not have the same semantics as the
loop invariant introduces by Hoare (ref?). The latter has to hold when reaching
the loop, at each start of iteration of the loop, and when exiting the
loop. The former only has to hold when execution reaches the corresponding
program point. The SPARK semantics is much easier to work with for programmers.

In formal verification, it is very common that loop invariants compare the
value of a variable at loop entry and at the n$^{th}$ iteration of the loop. To
facilitate such specifications, SPARK 2014 introduces the \verb|Loop_Entry|
attribute, which can be applied to such a variable. We've used that feature in
challenge 2.

A loop variant pragma has also been defined in SPARK 2014, to express a
quantity varying monotonically at each iteration of the loop. Like loop
invariants, a loop variant can appear anywhere in the main list of statements
in a loop. For example, here is the loop variant used in challenge 1:

\begin{footnotesize}
\begin{verbatim}
pragma Loop_Variant (Increases => L);
\end{verbatim}
\end{footnotesize}

Note that this variant does not take the usual non-negative decreasing
argument. Instead, it takes a list of increasing or decreasing integer values,
bounded by their type in Ada, and the overall order over this list is the
lexicographic order combined with individual directions. In the example below,
there is only one element in the lists, so it should increase at each run
through the loop. Like for loop invariants, the point where this increase
matters is the program point where the loop variant appears in the code.

Subprogram contracts can become quite large, even with the use of (expression)
functions to abstract common parts of contracts. Therefore, SPARK 2014 allows
the definition of contracts by cases, similar to behaviours in JML (ref?). For
example, the contract of \verb|LCP| can state separately sub-contracts for the
cases where the array is of length zero, or the elements at \verb|X| and
\verb|Y| are different, or \verb|X| and \verb|Y| are equal. This contract may
be used instead of or in addition to a precondition and a postcondition.

\begin{footnotesize}
\begin{verbatim}
function LCP (A : Text; X, Y : Integer) return Natural with
  Contract_Cases =>
    (A (X) /= A (Y) => LCP'Result = 0,
     X = Y          => LCP'Result = A'Last - X + 1,
     others         => LCP'Result > 0);
\end{verbatim}
\end{footnotesize}

Note that the cases above are disjoint and complete, as expected in SPARK: one
and only one case should be applicable at every call. The presence of the
\verb|others| case ensures the completeness here.

\section{Integrated Testing and Proving}
\label{hilite}
As we have mentioned, in the development of the new generation
language and toolset \newspark, we have a particular focus on
providing a good cost-benefit argument and on reaching non-expert
users. The ground work of the solution presented here was done in the
collaborative research project \hilite\ \cite{hiliteERTS2012} with
Altran, AdaCore, and INRIA.

We will describe a few observations of what drives the current
practises in the industry, in order to help us with the cost-benefit
argument. We will also see how progress in the research of behavioural
interface specification languages \cite{HatcliffLLMP12} enables an
approach where test and proof can be nicely integrated.

\subsection{Motivation: Industry Safety Standards and Testing}
Industry standards and certification documents highly influence the
state-of-practise in the development of safety-critical
software. \DOB\ \cite{do178b} is a document that is used as a basis
for certification of airborne software by institutions such as Federal
Aviation Administration (FAA) and European Aviation Safety Agency
(EASA). Though \DOB\ is for avionics, it is often used in other
safety-critical sectors as well. It is regarded as very successful
within the avionics industry itself; since its introduction in 1992 no
commercial aircraft fatality has been attributed to \DOB-certified
software. The majority of objectives in \DOB\ consider
verification. DO-178C is non-prescriptive with regards to programming
languages, software tools, particular development processes etc. The
development of requirements-based tests is mandatory, including normal
range tests cases and robustness (abnormal range) test cases. The
standard requires verification of both high-level requirements and
low-level requirements. Three levels of testing are defined in \DOB:
hardware/software integration testing, software integration testing,
and low-level testing - all based on requirements. The test cases must
fully cover the code and all exercised code should be traceable to
requirements. The standard requires coverage analysis such as
MC/DC. Such structural low-level testing, together with robustness
testing is expensive. For example, a large cost is associated just for
collecting and verifying output of these tests. Our goal here is to
reduce this cost, while still meeting the objectives prescribed by the
standard.

Formal methods can help to verify that no anomalous behaviour will
occur, for example it can be used prove the absence of run-time
errors. Formal methods can also be used to show compliance between a
program's actual and intended behaviour. Furthermore, a proof of
program correctness is comparable to exhaustive analysis achieving
100\% coverage. Though formal methods and other kinds of verification
are recognised as beneficial, they do not contribute to \DOB\
certification credit, and their use has had to be justified by other
means. However, \DOC\ \cite{do178c}, the recently released successor and
replacement of \DOB, allows to replace some of the prescribed testing
activities by formal methods. From RTCA \cite{do178c}:
%
\begin{quote}
  The use of formal methods is motivated by the expectation that, as
  in other engineering disciplines, performing appropriate
  mathematical analyses can contribute to establishing the correctness
  and robustness of a design.
\end{quote}
%
Formal methods are complementary to testing, and may find faults that
are not detected by testing, but they cannot establish verification
evidence for the target hardware. Therefore testing on the target is
still required. However, formal analysis of source code can be used to
show compliance with the low-level requirements. \DOC\ requires an
argument for property preservation between the source code and the
object code for those properties that have been verified formally at
the source level. Since formal program verification and testing are
complementary, we would like to use each method where it is most
efficient. For this we need to make sure that the combination is at
least as strong as testing alone.

\subsection{Executable Contracts}
Programming using contracts is a way to organise your code. By stating
a precondition and a postcondition of a subprogram as for example in
Sect. \ref{langfeatures}, we assign responsibilities. The subprogram
is responsible for the postcondition to be met, as long as it is
called under the assumptions of its precondition, which it relies
upon. Similarly, a caller of this subprogram is responsible for that
the precondition of the subprogram holds, before calling it. It can
then rely on the postcondition of the called program upon return. This
programming discipline encourages a modular design of the
software. Furthermore when verification is concerned, this can be done
in a modular fashion as well. Modularity gives the flexibility to
perform verification during development, rather than waiting until
after integration.

Also implicit contracts...

The notion of preconditions and postconditions was first introduced by
Hoare \cite{}, and later reinvented as \emph{Design by Contract} by
Meyer \cite{}. Traditionally, contracts have been interpreted quite
differently depending on whether used for formal program verification
or for run-time assertion checking. For formal program verification,
assertions have typically been interpreted as formulae in classical
first-order logic. This is not consistent with the run-time assertion
checking semantics.

Much effort has been spent the last decades to popularise formal
program verification. \cite{tseChalin10} did something as unusual as
surveying practitioners, to find that they prefer run-time assertion
checking semantics. Furthermore he developed a semantics to allow
formal executable contracts, i.e. compatible with run-time assertion
checking, in the hope that those users who are already annotating
their code with assert statements, could more easily be convinced to
start writing contracts. \adatwtw\ and thus \newspark has such
semantics.

Some of the benefits of being able to execute a contract:
\begin{itemize}
\item execution semantics for functional properties $\rightarrow$ debug
  annotations like code
\item contracts can be tested
\end{itemize}
Furthermore, there is an advantage in keeping the annotaion language
the same, or almost the same, as the programming language: the users
don't have to learn one more language. If the contract is also formal,
the entry barrier to formal program verification can be lowered by
making it available to those who would write executable contracts.

\subsection{Mixing Test and Proof}

Low-level requirements, in \DO\ terms, are typically expressed in
natural language on subprogram or unit level. Formal executable
contracts, can be used to express those requirements on the
subprogram level. Thanks to the same semantics for test and proof as
we have just discussed, we can use either (or both) of test and proof
to verify a subprogram. Thanks to modular verification, it is then
possible to mix test and proof to use the verification method that is
most cost effective for each module. If the chosen method is testing
the benefits of formal executable contracts are:
\begin{itemize}
\item Low-level requirements expressed as contracts
\item Successful execution of postcondition $\rightarrow$ test successful
\item No need to collect and verify output
\item More run-time checks gives better robustness testing
\end{itemize}
If the chosen verification method for a subprogram is proof, the
benefits of formal executable contracts are:  
\begin{itemize}
\item Low-level requirements expressed as contracts
\item Successful proof of postcondition $\rightarrow$ low-level
  requirement verified for all input
\item Approach allowed by \DOC\ formal methods supplement
\item Proof of absence of some run-time exceptions provides for some
  robustness testing
\item Proving process faster when annotations can be executed (debug failed proof attempts is very time-consuming)
\end{itemize}

But what about soundness of the mixed approach? When some low-level
requirements are tested and and some are proved, remember in
\DOC-terms the combination needs to be as good as if all low-level
requirements were tested.

Central to modular verification is the statement of assumptions and
guarantees. For global correctness, \emph{all} subprograms must
establish their postconditions (under the assumption of their
preconditions), and for \emph{all} calls to a subprogram, its
precondition must be verified by the caller before the call.

In our mixed approach of test and proof, we have these same global
correctness requirements as usual for modular verification. The
difference is that some subprograms may be tested and some be proved,
and we must still make sure that all assumptions are verified. Let us
consider the two cases: 1) a tested subprogram \verb|T| calls a proved
subprogram \verb|P|, and 2) a proved subprogram \verb|P| calls a
tested subprogram \verb|T|. In the first case, when verifying \verb|T|
we must make sure that the precondition of \verb|P| is
established. When testing \verb|T|, this can be done by executing the
precondition of \verb|P|. In the second case, the correctness of
\verb|P| relies on that after having verified the precondition of and
then called \verb|T|, then \verb|T| should return in a state where the
postcondition holds. This assumption on \verb|T| should be verified
when testing \verb|T| by executing the assertion that its postcondiion
holds. Both of these verification cases are only possible because we
have executable contracts.

\subsection{Compiler Implementation}
For \newspark\ we are building the verification tools using the GNAT
compiler, see \cite{ksd2012} for a description and discussion of this
architecture. One advantage here is that the compiler inserts these
additional checks needed to verify at run time assumptions made during
proof.

Yannick: Something about target parameterisation?

\section{Choosing the Right Semantics for Integers}
\label{overflowsemantics}
As mentioned, there has traditionally been a difference in
interpretation of contracts depending on whether used for formal
verification, or for run-time assertion checking. One area where this
difference is of practical significance is in the semantics for
integers. An effect of having the same semantics in assertions as in
the program code, is that run-time exceptions must be considered, and
avoided, in the assertions as well as in the program. As an example,
consider a programmer who wants to state a pre-condition that the
addition of two number fits in a desired integer type:
\verb|with Pre => X + Y in SomeIntegerType|. The problem is that
\verb|X + Y| itself can cause an arithmetic overflow, and worse this
is not relevant to the correctness of neither the program nor the
specification. When executable semantics are used for integer
operations in assertions, there will therefore in practical formal
verification be a large number of extra proof obligations that do not
point to real issues neither in the program code nor the code. In
traditional assertion languages aimed for formal verification,
mathematical universal integers are used for such operation and proof
can safely proceed without involving the user. Furthermore, user
studies \cite{jotChalin04} show that users who are otherwise happy
with run-time assertion checking semantics, still prefer mathematical
semantics for intermediate integer operations in assertions.

From a user perspective mathematical semantics for integer operations
in assertions is a good solution. However, for our hybrid verification
argument described in the previous section to work, it is mandatory to
have the same semantics for test and proof. Fortunately, we here have
the option to implement a solution for this in the compiler GNAT,
which we re building our verification tools on. Also, the Ada standard
does not require the compiler to issue an overflow error when an
intermediate value does not fit into the base type. 

Existing users of \oldspark\ and potential new users of \newspark\
together cover a wide spectrum of strong preferences regarding this
issue. Existing users of \oldspark\ who perform formal verification of
absence of run-time errors for their programs want the traditional
mathematical integers in assertions and executable semantics for the
program. Another user wants the same executable semantics in
assertions and program code, and want to leave the assertions in the
shipped code. Many users could not have executed code that uses a
library for unbounded integers becuase of certification and
performance reasons, etc. Because of these strong needs, we provide
three alternative overflow checking modes in GNAT and \gnatprove:
\begin{enumerate}
\item Strict mode: normal overflow checks
\item Minimized mode: larger base type (64bits) used when needed
\item Eliminated mode: use bignum library in the remaining cases
\end{enumerate}
This gives a flexible solution, where the user chooses between 3
modes. The choice is independent for assertions and code. However, the
same choice for execution and formal verification is required for our
hybrid verification with test and prooof to be sound.
\section{Making Automatic Verification Work}
\label{automation}

As \gnatprove uses the Why3 platform~\cite{why3} to generate VCs and call
provers, it can target as many output formats and automatic or manual provers
as the Why3 platform allows (many!), but we focus on the automatic proof of VCs
through the use of the SMT prover Alt-Ergo~\cite{altergo} which is included in
\gnatprove distribution. There are two steps to make automatic verification
work: first make it possible, then make it efficient.

The choice of programming language is essential to make automatic verification
possible. On the one hand, it should proscribe those features which render
automatic verification impossible or very hard, and on the other hand, it
should contain enough features which facilitate the expression of
specifications. The former is obtained by restricting \newspark to a subset of
\adatwtw without pointers and exceptions. The later is obtained by the features
introduced in \adatwtw and \newspark. \adatwtw was specifically designed to
include preconditions, postcondition, type invariants, \etc so that a user can
specify arbitrarily complex invariant properties on the data and control of her
program, and test these properties at run time. \newspark further adds loop
invariants, loop variants, \etc so that a user can formally prove these
properties.

Efficient formal verification relies on a subtle coordination between the VC
generator and the prover, so that the VCs produced can be efficiently
proved. \gnatprove relies heavily on the features of the Why3
language~\cite{guitton2011boogie} to produce provable VCs. For example, the VCs
are kept small by translating the semantic dependencies between entities at the
Ada source code level into syntactic inclusions between modules at the Why3
intermediate code level, and by using the abstraction feature in Why3 for the
intermediate code that checks for absence of run-time errors. This ensures that
the generated VCs only contain relevant definitions and axioms. As another
example, one can choose to produce fewer but more complex VCs: the default in
\gnatprove is that a VC accounts for all paths leading to an assertion, using
an efficient computation~\cite{leino2005ipl}, instead of generating one VC for
each path leading to an assertion (also available in \gnatprove on option). The
choice of axiomatization of Ada data types (integer types, enumeration types,
record types, array types, \etc) in Why3 also has a determinant effect on the
provability of VCs. We have changed various times these axiomatizations to
better suit the mechanisms inside SMT provers like Alt-Ergo. Similarly, we have
tailored the axiomatization for a generic library of
containers~\cite{dross:2011:tap} to SMT provers.

Finally, modular verification based on pre- and postconditions can very easily
exploit multicore architectures, as the generation of VCs for different units,
or the proof of different VCs, can both be run in parallel. Typically, project
contain hundreds of units, and lead to the generation of thousands of VCs,
which can be run by \gnatprove on as many cores as available. Note also that
\gnatprove uses file timestamps to avoid re-generating VCs for units which have
not been updated, and file hashes to avoid re-proving VCs that have already
been proved. This is crucial when developing either the code or the associated
annotations, to avoid useless rework.

\section{VerifyThis Competition}
\label{verifythis}
In this section we will describe our solutions to two of the
challenges from the 2012 VerifyThis competition. The first challenge
is the longest common prefix problem, \verb|LCP|. The second challenge
is a tree sum, \verb|PrefixSum|, which is a binary tree summation
algorithm implemented in-place on an array. For the latter we have one
complete fixed-size solution suitable for automatic verification using
the current prototype version of \newspark\ and
\gnatprove. Furthermore, we have specified a general version of the
\verb|Upsweep| procedure of the second challenge initially using
\oldspark\ as a reference, then translated into \newspark,
experiencing the benefits of executable annotations.
\subsection{Solution to Challenge 1: Longest Common Prefix}

The longest common prefix solution can be readily coded in \newspark as follows:

\begin{footnotesize}
\begin{verbatim}
subtype Index is Positive range 1 .. 1_000_000;
type Text is array (Index range <>) of Integer;

function LCP (A : Text; X, Y : Integer) return Natural with
  Pre  => X in A'Range and then Y in A'Range,
  Post =>
    (for all K in 0 .. LCP'Result - 1 => A (X + K) = A (Y + K))
      and then
    (X + LCP'Result = A'Last + 1
      or else Y + LCP'Result = A'Last + 1
      or else A (X + LCP'Result) /= A (Y + LCP'Result));

function LCP (A : Text; X, Y : Integer) return Natural is
   L : Natural;
begin
   L := 0;
   while X + L <= A'Last
     and then Y + L <= A'Last
     and then A (X + L) = A (Y + L)
   loop
      pragma Loop_Invariant
        (for all K in 0 .. L - 1 => A (X + K) = A (Y + K));
      pragma Loop_Variant (Increases => L);
      L := L + 1;
   end loop;
   return L;
end LCP;
\end{verbatim}
\end{footnotesize}

The type \verb|Text| is an array of integers with unknown bounds. The input
specification that parameters \verb|X| and \verb|Y| are indices in the array
parameter \verb|A| can be expressed as a precondition involving the Ada
attribute \verb|'Range|, and membership tests \verb|X in ...| The output
specification that the result is the length of the longest common prefix
starting at \verb|X| and \verb|Y| can be expressed as a postcondition in two
parts, using the \adatwtw attribute \verb|'Result| to express the function
result:
\begin{itemize}
\item A quantification stating that the subarrays of \verb|A| of length
  \verb|LCP'Result| starting at \verb|X| and \verb|Y| are equal.
\item A disjunction of cases stating that either one of the two subarrays
  reaches the end of array \verb|A|, or the elements following the two
  subarrays in \verb|A| are different. Note here that the use of the lazy
  boolean connective \verb|or else| is compulsory to make sure that
  \verb|X + LCP'Result| and \verb|Y + LCP'Result| are without bounds when
  accessing \verb|A| in the last line of the postcondition.
\end{itemize}

Running \gnatprove on this code without loop invariant or loop variant results
in the generation of 13 VCs: 1 VC for the postcondition, and 12 VCs for all
run-time checks (6 array index checks, 5 numeric overflow checks, 1 subtype
range check). All VCs related to run-time checks are proved. These VCs
represent both checks in the code and checks in assertions for the array
accesses in the postcondition. The VC for the postcondition is not proved, due
to the presence of a loop in the body of \verb|LCP|.

Proving the postcondition requires the insertion of a loop invariant in the
body of \verb|LCP|, which expresses that the subarrays of \verb|A| of length
\verb|L| starting at \verb|X| and \verb|Y| are equal. Since \verb|L| is the
value returned by \verb|LCP|, this loop invariant matches the first part of the
postcondition when the loop terminates. As expected, the postcondition is
proved with this additional loop invariant. \gnatprove generates 4 additional
VCs to prove that the loop invariant initially holds at the first iteration
through the loop, that it is maintained by subsequent iterations, and that the
two array accesses in the loop invariant expression are within bounds. All 4
additional VCs are also proved.

Finally, proving termination of \verb|LCP| requires the insertion of a loop
variant in the body of \verb|LCP|, which expresses that the value of \verb|L|
always increases between two consecutive iterations through the loop. Since
\verb|L| is of a bounded type (the scalar type \verb|Natural| of natural
numbers), it cannot be infinitely incremented without failing a run-time
check. Since we have already proved that no run-time check fails in \verb|LCP|,
proving the variant proves the termination of \verb|LCP|. The corresponding VC
is proved by \gnatprove.

The final version of \verb|LCP| is proved in 6s on a DELL laptop with 4G RAM
and 3GHz processor.

\subsection{Solution to Challenge 2: Tree Sum}

We have chosen to implement an imperative version of prefix sum instead of a
recursive one, which better matches the constraints commonly found in critical
embedded software where recursion is usually not allowed. In order to make
automatic proof possible, we fix the length of the array to 8. The complete
solution is quite long (186 loc, not counting empty lines), so we only show
here selected parts. The initial solution without annotations is
straighforward, and only 50 lines long. As an example, here is the
implementation of procedure \verb|Upsweep|:

\begin{footnotesize}
\begin{verbatim}
procedure Upsweep (A : in out Input; Output_Space : out Positive) is
   Space : Positive := 1;
   Left  : Natural;
   Right : Natural;
begin
   while Space < A'Length loop
      Left := Space - 1;
      while Left < A'Length loop
         Right     := Left + Space;
         A (Right) := A (Left) + A (Right);
         Left      := Left + Space * 2;
      end loop;
      Space := Space * 2;
   end loop;
   Output_Space := Space;
end Upsweep;
\end{verbatim}
\end{footnotesize}

The postcondition of procedure \verb|Upsweep| states that the array parameter
\verb|A| is put in an intermediate form \wrt its initial value (denoted
\verb|A'Old|). The contract of procedure \verb|Downsweep| states it takes as
input an array parameter \verb|A| in an intermediate form \wrt a \verb|Ghost|
array parameter, and that it outputs in the same parameter \verb|A| the desired
prefix sums of array \verb|Ghost|. By calling in sequence \verb|Upsweep| and
\verb|Downsweep| on an array \verb|A|, with the initial value of \verb|A|
passed as \verb|Ghost| parameter, a caller performs the desired in-place
modification of \verb|A|. Although \newspark does not support yet ghost
parameters, which are only used for proofs, this is here the role of parameter
\verb|Ghost|, hence its name.

\begin{footnotesize}
\begin{verbatim}
procedure Upsweep (A : in out Input; Output_Space : out Positive) with
  Pre  => All_Elements_In (A, Maximum),
  Post => All_Elements_In (A, 8 * Maximum)
    and then Output_Space = 8
    and then Intermediate_Form (A, A'Old);

procedure Downsweep
  (Ghost : Input; A : in out Input; Input_Space : in Positive)
with
  Pre => All_Elements_In (Ghost, Maximum)
    and then All_Elements_In (A, 8 * Maximum)
    and then Input_Space = 8
    and then Intermediate_Form (A, Ghost),
  Post =>
    A (0) = 0
      and then
    A (1) = Ghost (0)
      and then
    A (2) = Ghost (0) + Ghost (1)
      and then
    A (3) = Ghost (0) + Ghost (1) + Ghost (2)
      and then
    A (4) = Ghost (0) + Ghost (1) + Ghost (2) + Ghost (3)
      and then
    A (5) = Ghost (0) + Ghost (1) + Ghost (2) + Ghost (3) + Ghost (4)
      and then
    A (6) = Ghost (0) + Ghost (1) + Ghost (2) + Ghost (3) + Ghost (4)
          + Ghost (5)
      and then
    A (7) = Ghost (0) + Ghost (1) + Ghost (2) + Ghost (3) + Ghost (4)
          + Ghost (5) + Ghost (6);
\end{verbatim}
\end{footnotesize}

The function \verb|Intermediate_Form| gives the exact relationship between the
initial value of the array (parameter \verb|B| below) and its intermediate
value between the calls to \verb|Upsweep| and \verb|Downsweep| (parameter
\verb|A| below). We define it as an expression function in \adatwtw, which has
the benefit that \gnatprove automatically generates a postcondition for
\verb|Intermediate_Form| equivalent to its body. We also give a precondition to
\verb|Intermediate_Form| to prove that its evaluation cannot fail run-time
checks (overflow checks and index checks here).

\begin{footnotesize}
\begin{verbatim}
function Intermediate_Form (A, B : Input) return Boolean with
  Pre => All_Elements_In (A, Maximum * 8)
    and then All_Elements_In (B, Maximum);

function Intermediate_Form (A, B : Input) return Boolean is
  (for all K in A'Range =>
     (if (K + 1) mod 8 = 0 then
        A (K) = B (0) + B (1) + B (2) + B (3) +
                B (4) + B (5) + B (6) + B (7)
     elsif (K + 1) mod 4 = 0 then
        A (K) = B (K) + B (K-1) + B (K-2) + B (K-3)
     elsif (K + 1) mod 2 = 0 then
        A (K) = B (K) + B (K-1)
     else
        A (K) = B (K)));
\end{verbatim}
\end{footnotesize}

Note that the contracts of all previous procedure and functions contain calls
to function \verb|All_Elements_In|, which returns \verb|True| if all elements
of an array are bounded in absolute value, which we also define as an
expression function:

\begin{footnotesize}
\begin{verbatim}
function All_Elements_In (A : Input; Max : Positive) return Boolean is
   (for all K in A'Range => A (K) in -Max .. Max);
\end{verbatim}
\end{footnotesize}

These specifications add 62 lines to the initial 50 lines for the solution. To
prove them with \gnatprove, we add 84 more lines for loop invariants and loop
variants. As an example, here are the loop invariant and loop variant for the
inner loop of procedure \verb|Upsweep|. Inside the loop invariant,
\verb|A'Loop_Entry| denotes the value of \verb|A| on entry to the loop.

\begin{footnotesize}
\begin{verbatim}
pragma Loop_Invariant (
  (Left + 1) mod Space = 0
    and then
  All_Left_Elements_In (A, Left, Space * 2 * Maximum)
    and then
  All_Right_Elements_In (A, Left - 1, Space * Maximum)
    and then
  (Left + 1) mod (Space * 2) = Space
    and then
  (if Left >= A'Length then Left = 8 or Left = 9)
    and then
  (for all K in A'Range =>
    (if K in A'First .. Left - Space
       and then (K + 1) mod (2 * Space) = 0
     then
        A (K) = A'Loop_Entry (K) + A'Loop_Entry (K - Space)
     else
        A (K) = A'Loop_Entry (K))));
pragma Loop_Variant (Increases => Left);
\end{verbatim}
\end{footnotesize}

The final version of prefix sum is partially proved (78 VCs proved, 8 VCs
unproved) in 138s on a DELL laptop with 24G RAM and 24 processors at 2.4GHz.
These 8 unproved VCs are either loop invariants or postconditions, which are
not proved automatically due to the use of the \verb|mod| operator, currently
not well handled in the underlying automatic prover. We have checked all of
them manually.

\subsection{General  Tree Sum}
As mentioned, we chose to implement an imperative version of
\verb|PrefixSum| to fit for critical embedded software; we are happy
with that. Though the presented complete solution makes automatic
proof possible with the prototype version of our tools, which we are
also happy with, the specification could be improved. Here we present
a general specification for the simple property of the \verb|Upsweep|
procedure.  The downside is that it does not yet verify with the
current version of \gnatprove..

This solution: Uses a general fix size, but not explcitly size 8.
Avoids explicit listing of intermediate state in the contract, because
it is too detailed and hard to judge whether it is correct, and it
does not scale, if you would like to change the size to four times for
example

replace the

\begin{footnotesize}
\begin{verbatim}

package Types is
   subtype Index is Natural range 0 .. 7;
   type Input is array (Index) of Integer;
end Types;

with Types; use Types;

package PrefixSum_General is

   Tree_Depth : constant := 3;
   Maximum    : constant := Integer'Last / (Index'Last + 1);

   function Is_Even (K : Integer) return Boolean is (K mod 2 = 0);

   function Summation (A : Input; Start_Pos, End_Pos : Index) return Integer
   with
     Pre => Start_Pos <= End_Pos;

   function Summation (A : Input; Start_Pos, End_Pos : Index) return Integer is
      (if Start_Pos = End_Pos then A (Start_Pos)
       else A (End_Pos) + Summation (A, Start_Pos, End_Pos - 1));

   procedure Upsweep (A : in out Input; Output_Space : out Positive) with
     Pre  => (for all K in A'Range => A (K) in -Maximum .. Maximum),
     Post => (for all K in A'Range => (if Is_Even (K) then A (K) = A'Old (K)))
       and then A (A'Last) = Summation (A'Old, 0, A'Last);

end PrefixSum_General;

\end{verbatim}
\end{footnotesize}
%
(AW: double check: the pre-condition that I had in the \oldspark\
version: \verb|--# pre A'Length = 2 ** Tree_Depth| has not made it
into the \newspark\ version. I would like to state this even if it is
currently not used for proof(?), because it is an important part of
the specification, the algorithm won't work for inputs that don't
fulfill this. Furthermore, it is a good example of various typical
practical non-trivial stuff: 1) non-linear arithmetic, 2) how to avoid
complications for underlying solver a) avoid existential
quantification ala $\exists n: Integer. A'Length = 2^n$), 2 b) avoid
extra proof functions (for the binlog version to avoid the existential
quantification), solution: ask the user for input up-front
\verb|Tree_Depth|, this is not bogging the user down but rather
encourages thinking about the underlying app, and is quite elegant,
and will generate distinct false VCs if not true)
%
\begin{footnotesize}
\begin{verbatim}
package body PrefixSum_General is

   procedure Upsweep (A : in out Input; Output_Space : out Positive) is
      Space : Positive := 1;
      Left  : Natural;
      Right : Natural;
      A_Old : constant Input := A;
   begin
      while Space < A'Length loop
         Left := Space - 1;

         pragma Loop_Invariant
           (A'Length mod Space = 0
              and then
            2 * Space <= A'Length
              and then
            not Is_Even (Left + Space)
              and then
            Left < Space
              and then
            (Left + 1) mod Space = 0
              and then
            (for all K in A'Range =>
              A (K) in -Maximum * Space .. Maximum * Space)
              and then
            (for all K in A'Range =>
              (if Is_Even (K) then A (K) = A'Loop_Entry (K)))
              and then
            (for all K in A'Range =>
              (if (K + 1) mod Space = 0 then
                A (K) = Summation (A'Loop_Entry, K + 1 - Space, K))));
         pragma Loop_Variant (Increases => Space);

         while Left + Space < A'Length loop
            pragma Loop_Invariant
              (Left + Space < A'Length
                 and then
               A'Length mod Space = 0
                 and then
               2 * Space <= A'Length
                 and then
               not Is_Even (Left + Space)
                 and then
               (Left + 1) mod Space = 0
                 and then
               (for all K in A'Range =>
                 (if K < Left then
                   A (K) in -Maximum * Space * 2 .. Maximum * Space * 2
                  else
                   A (K) in -Maximum * Space .. Maximum * Space))
                 and then
               (for all K in A'Range =>
                 (if Is_Even (K) then A (K) = A'Loop_Entry (K)))
                 and then
               (for all K in A'Range =>
                 (if K < Left and (K + 1) mod (Space * 2) = 0 then
                   A (K) = Summation (A_Old, K + 1 - Space * 2, K)
                 elsif Left <= K and (K + 1) mod Space = 0 then
                   A (K) = Summation (A_Old, K + 1 - Space, K)))
                 and then
               A (Left) = Summation (A_Old, Left + 1 - Space, Left)
                 and then
               A (Left + Space) = Summation (A_Old, Left + 1, Left + Space));
            pragma Loop_Variant (Increases => Left);

            Right     := Left + Space;
            A (Right) := A (Left) + A (Right);
            Left      := Left + Space * 2;
         end loop;
         Space := Space * 2;
      end loop;
      Output_Space := Space;
   end Upsweep;

end PrefixSum_General;

\end{verbatim}
\end{footnotesize}

\subsection{Useful Tool Features}

The format of the competition exercized useful features of \gnatprove, which
helped finding errors early in the code or in the annotations. The most useful
of these features is certainly the ability to execute annotations, which allows
testing and debugging annotations as if they were code. It was used during the
competition to quickly locate the reason for an unprovable VC on challenge 1:
the loop test was using a strict comparison operator instead of the correct
non-strict one. To locate the problem, the participating author simply wrote a
test exercizing \verb|LCP| on an input, compiled it with run-time checks, and
run it. The run-time error raised precisely located the failing loop
invariant. Although this example was simple enough to immediately understand
the underlying problem, it would have been possible to use the debugger to
further investigate the issue, which can be extremely useful on real industrial
code. The ability to execute annotations was also useful for challenge 2, which
requires the development of complex loop invariants, to quickly correct
erroneous ones. This feature won the prize of user-assistance tool feature
awarded by the jury of the VerifyThis competition.

Another very useful feature for these challenges was the ability to eliminate
completely all possibilities of numeric overflows in annotations, as described
in Section~\ref{???}. While using this feature results in only 10 more overflow
VCs in challenge 1, which are all proved with the current annotations, it adds
60 overflow VCs in challenge 2, most of which require modifications of
annotations, or addition of new annotations, to be proved. Note that this
feature is compatible with the execution of annotations, as compilation also
takes into account the overflow mode when compiling arithmetic expressions.

Various features of \gnatprove make it very convenient to use inside an
Integrated Development Environment (currently GPS, the GNAT Programming
Studio). The user can choose to call \gnatprove on a selected file, an
individual subprogram, or even a single line of code. This was key to speed up
the modify/verify loop during the competition. When a VC is not proved, the IDE
can also display the corresponding statements in the code, to help figure out
why some assertions do not hold on some paths.

More generally, these small challenges already make use of numerous language
features in \adatwtw and \newspark that facilitate the expression of
specifications: preconditions and postconditions, loop invariants and loop
variants, expression functions, quantified expressions and if expressions,
special attributes \verb|'Result|, \verb|'Old| and \verb|'Loop_Entry|.

\begin{itemize}
\item snapshot of GNATprove results in GPS
\end{itemize}

\section{Ongoing Work}
\label{ongoing}

\gnatprove is the result of a complete redesign of the SPARK language and
associated tools, which started in 2010 with project \hilite.\cite{Hi-Lite}
Altran and AdaCore are collaborating to complete this new version of SPARK by
the start of 2014. On the tool side, current work focuses on flow analysis,
support for investigating unproved VCs, and improvements of the SMT prover.

Flow analysis is the verification of the data dependences of subprograms. This
analysis which has always been a component of SPARK verification is currently
redeveloped for \newspark, based on program dependence
graphs~\cite{horwitz:1988:pldi}. An important novelty is that, while \oldspark
requires that the user annotates programs with data dependence contracts, they
are optional in \newspark, and \gnatprove generates them when not present. A
minimal flow analysis is always required for the soundness of proofs, while a
more complete flow analysis is optional. The minimal flow analysis ensures that
all variables are initialized prior to being read.

Facilitating the investigation of unproved VCs is key to making formal program
verification cost-effective in industry. \gnatprove currently provides various
solutions to that problem: the ability to execute annotations to detect errors
in code and/or annotations; the display of program paths to detect errors or
locate missing annotations; the possibility to call alternate provers to
identify prover shortcomings. In the future, we would like to add the display
of counterexamples generated by the prover, as already provided by some SMT
provers~\cite{CVC3,Z3model}.

We have been exploring two promising ways to improve the results of the
Alt-Ergo SMT prover on the VCs generated in \gnatprove: handling selected
axiomatizations as decision procedures~\cite{dross:2012:smt}, and incrementally
selecting axioms~\cite{cgs09:ipo,kuhlwein:2012:ijcar}. More work is needed to
make these modes the default inside \gnatprove.

mention the following?

\begin{itemize}
\item proof of code containing containers
\item visualization of assumptions made for proof
\item Coq formalization of AST produced by frontend. possible verification of
  the consistency of the generated AST with checks.
\item adaptation for non-executable annotations and proof assistants
\end{itemize}

%
\bibliographystyle{alpha}
\bibliography{sttt_2013}

\end{document}


