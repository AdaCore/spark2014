Report 007-R-15

Default
SECTION I: Summary and Recommendation

Summary of Evaluation

Overall quality is:

Good
Score

Please select the score of the paper.

Mild Accept
Confidence

Please select your confidence.

High
SECTION III: Overview

Reader Interest

1. Is the paper of current interest to a reasonable segment of the journal?

Yes

2. Relative to the current level of reader interest in the paper, how is this
interest likely to change during the next five years?

Growing interest

3. Within its particular field of specialization, is the topic of the paper
considered important?

Yes, definitely
Content

1. Is the paper technically sound?
(not necessary for style review)

Yes

2. How would you describe the technical depth of the paper?

Appropriate for someone working in the field

3. Does the paper make a tangible contribution to the state-of-the-art in its
field?

Yes, definitely

4. Is the bibliography adequate?

Yes

5. To what extent is the material in the paper likely to be used by other
researchers and practitioners?

Large
Presentation

1. Is the abstract an appropriate and adequate digest of the work presented?

Yes

2. Does the introduction clearly state the background and motivation in terms
understandable to the non-specialist?

Yes

3. How would you rate the overall organization of the paper?

Could be improved (see comments)

4. Relative to the technical content, is the length of the paper appropriate?

No, should be lengthened

5. Is the English satisfactory

Yes

6. How readable is the paper for a computer scientist or engineer who is not a
specialist in this particular field

Readable with ordinary effort

7. Disregarding the technical content, how would you regard the quality of
presentation?

Good
Section IV: Detailed Comments for Author(s)

Mandatory, please elaborate on your judgement.

The paper provides an overview of SPARK 2014, and documents the authors’
experience in using the tool during the 2012 VerifyThis competition. The SPARK
Approach has a long history, with its origins dating back to the late 80’s.
SPARK 2014 represents a significant development, with new language features and
significant improvements to the reasoning aspects of the tool. The combination
of proof and executable contracts looks to be very powerful, as well as usable
–
allowing the synergies of test and proof to be exploited within a single
framework.

My recommendation is for “acceptance”; however, I would like aspects of the
paper to be elaborated. What is provided is of a high standard, what I am
calling for is more detail. Given that the page limit is 20, then this should
not be a problem:

1. I would like to see more details on the annotation execution
mechanism, especially given that it won a prize, e.g. step through a
buggy invariant showing how the bug is revealed.

2. A lot of stats on proof attempts (successes, failures, annotations
supplied) – would be useful if these were summarised in a table.

3. Essentially two challenge problems were tackled (although two versions
of Tree Sum problem were investigated) – why were these challenges
selected over the other members of the VerifyThis 2012 Challenge set?

4. The current version of SPARK includes an interactive proof environment,
i.e. the SPADE Proof Checker. The SPADE PC is by no means state-of-the-art,
but still has industrial users who might be left wondering after reading the
paper what support for interactive proof will be provided in SPARK 2014?
Why3 can obviously interface with interactive provers, just not clear what
options will be available within SPARK 2014.

5. Section 6.2 makes reference to “84 more lines for loop invariants and loop
variants”. An example invariant is provided, but would be nice to see more
of the invariants and variants –currently the paper only uses 11 of the 20
page limit – scope for appendices.
