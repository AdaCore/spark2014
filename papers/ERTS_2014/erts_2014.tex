\documentclass[10pt,a4paper,twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage[usenames,dvipsnames]{color}
\usepackage{listings}
\newcommand{\CodeSymbol}[1]{\textcolor{Bittersweet}{#1}}
\lstset{
   language=Ada,
   keywordstyle=\color{RedViolet}\ttfamily\bf,
   showspaces=false,
   basicstyle=\ttfamily,
   commentstyle=\color{red}\textit,
   stringstyle=\color{MidnightBlue}\ttfamily,
   showtabs=false,
   showstringspaces=false,
   morekeywords=[1]Pre,
   morekeywords=[1]Post,
   morekeywords=[1]Test\_Case,
   morekeywords=[1]Contract\_Cases,
   morekeywords=[1]some,
   morekeywords=[1]Old,
   morekeywords=[1]Global,
   morekeywords=[1]Depends,
   morekeywords=[1]Loop\_Invariant,
   morekeywords=[1]Loop\_Variant,
   morekeywords=[1]Loop\_Entry,
   morekeywords=[1]Increases,
   literate={(}{{\CodeSymbol{(}}}1
            {)}{{\CodeSymbol{)}}}1
            {>}{{\CodeSymbol{$>$}}}1
            {>=}{{\CodeSymbol{$\ge$}}}1
            {<}{{\CodeSymbol{$<$}}}1
            {<=}{{\CodeSymbol{$\le$}}}1
            {=}{{\CodeSymbol{$=$}}}1
            {:}{{\CodeSymbol{$:$}}}1
            {.}{{\CodeSymbol{$.$}}}1
            {;}{{\CodeSymbol{$;$}}}1
            {/=}{{\CodeSymbol{$\ne$}}}1
            {=>}{{\CodeSymbol{$\Rightarrow$}}}1
            {->}{{\CodeSymbol{$\rightarrow$}}}1
            {<->}{{\CodeSymbol{$\leftrightarrow$}}}1
}

\newcommand{\DO}{\textsc{do-178}\xspace}
\newcommand{\DOB}{\textsc{do-178b}\xspace}
\newcommand{\DOC}{\textsc{do-178c}\xspace}
\newcommand{\hilite}{Hi-Lite\xspace}
\newcommand{\openetcs}{openETCS\xspace}
\newcommand{\gnatprove}{GNATprove\xspace}
\newcommand{\oldspark}{SPARK~2005\xspace}
\newcommand{\newspark}{SPARK~2014\xspace}
\newcommand{\spark}{SPARK\xspace}
\newcommand{\ada}{Ada\xspace}
\newcommand{\adatwtw}{Ada~2012\xspace}
\newcommand{\altergo}{Alt-Ergo\xspace}

\newcommand{\etc}{\textit{etc.}\xspace}
\newcommand{\ie}{\textit{i.e.}\xspace}
\newcommand{\adhoc}{\textit{ad hoc}\xspace}
\newcommand{\Eg}{\textit{E.g.}\xspace}
\newcommand{\eg}{\textit{e.g.}\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}
\newcommand{\wrt}{w.r.t.\xspace}
\newcommand{\aka}{a.k.a.\xspace}
\newcommand{\resp}{resp.\xspace}

\lstset{basicstyle={\scriptsize \sffamily}}
\newcommand{\SPARK}[1]{\lstinline[language=Ada,basicstyle={\footnotesize
      \sffamily},framesep=0pt]$#1$}

\begin{document}

\title{Rail, Space, Security: Three Case Studies for SPARK 2014}

\author{%
\large Claire Dross$^4$, Pavlos Efstathopoulos$^1$, David Lesens$^2$, David Mentré$^3$ and Yannick Moy$^4$\\
\normalsize 1: Altran UK Limited, 22 St Lawrence Street, Bath BA1 1AN (United Kingdom),\\
\normalsize 2: Astrium Space Transportation, 51-61 route de Verneuil F-78130 Les Mureaux (France),\\
\normalsize 3: Mitsubishi Electric R\&D Centre Europe, 1 allée de
Beaulieu, CS 10806, F-35708 Rennes (France),\\
\normalsize 4: AdaCore, 46 rue d'Amsterdam, F-75009 Paris (France)}

\date{}

\maketitle

\paragraph{Abstract}
SPARK is a subset of the Ada programming language targeted at safety
and security critical applications. \newspark is a major evolution of
the SPARK language and toolset, that integrates formal program
verification in the existing development and verification processes,
in order to decrease the cost of verification for software subject to
certification constraints. We present industrial case studies in three
different certification domains that show the benefits of using formal
verification with \newspark.

\paragraph{Keywords}
System formal development, Verification and validation,
Certification and dependability

\section{Introduction}

\newspark is a major evolution of the SPARK subset of Ada and associated formal
verification toolset with two main objectives:
%
\begin{enumerate}
\item being accessible to non-expert users, and
\item being compatible with testing.
\end{enumerate}

In this paper, we describe how \newspark achieves these objectives, based on
practical use of the language and associated formal verification tool
\gnatprove on three industrial case studies developed in the context of the
\hilite~\footnote{\url{http://www.open-do.org/projects/hi-lite/}} and
\openetcs~\footnote{\url{http://openetcs.org/}} research projects.

\section{SPARK 2014}

%%\subsection{SPARK: Past and Present}

SPARK is a subset of the Ada programming language targeted at safety and
security critical applications. SPARK builds on the strengths of Ada for
creating highly reliable and long-lived software. SPARK restrictions ensure
that the behavior of a SPARK program is unambiguously defined, and simple
enough that formal verification tools can perform an automatic diagnostic of
conformance between a program specification and its implementation. The SPARK
language and toolset for formal verification has been applied for many years in
on-board aircraft systems, control systems, cryptographic systems, and rail
systems~\cite{sparkbook2012,oneill2012}. The new version \newspark builds on
the new specification features added in \adatwtw~\cite{ada2012rationale}, so
formal specifications are now understood by the usual development tools and can
be executed.

\subsection{Key Language Features}

The most useful feature in \newspark is the ability to specify a contract on
subprograms. Subprogram contracts were popularized in the Design-by-Contract
approach~\cite{meyer:1988:OSC} as a means to separate responsibilities in
software between a caller and a callee. The callee's \textit{precondition}
states the responsibility of its caller, while the callee's
\textit{postcondition} states the responsibility of the callee itself.  For
example, the following contract for procedure \SPARK{Swap} specifies that it
should be called with index parameters within the range of the array parameter,
and that \SPARK{Swap} will ensure on return that the corresponding values in
the array have been swapped. Attribute \SPARK{Old} in the postcondition is used
to refer to values on entry to the subprogram.

\begin{lstlisting}
procedure Swap (A : in out Arr; X, Y : Idx) with
  Pre  => X in A'Range and Y in A'Range,
  Post => A(X) = A(Y)`Old and A(Y) = A(X)`Old;
\end{lstlisting}

In \newspark, subprogram contracts may additionally specify global variables
read and written in the subprogram, as well the flow of information from inputs
(parameters and global variables read) to outputs (parameters and global
variables written). For example, the following contract for procedure
\SPARK{Swap} specifies that the subprogram writes global variable
\SPARK{Backup}, that the value of \SPARK{Backup} on return depends only on the
input value of \SPARK{A}, and that the value of \SPARK{A} on return depends on
the input values of all parameters.

\begin{lstlisting}
procedure Swap (A : in out Arr; X, Y : Idx) with
  Global  => (Output => Backup),
  Depends => (Backup => A,
              A     => (A, X, Y));
\end{lstlisting}

Instead of preconditions and postconditions, or in addition to them, subprogram
contracts may be specified by a set of disjoint and complete cases. For
example, the following contract for procedure \SPARK{Swap} states separate
sub-contracts for the cases where the elements at indexes \SPARK{X} and
\SPARK{Y} are equal or different. The first case specifies that, if
\SPARK{A(X)} equals \SPARK{A(Y)} on entry, then \SPARK{A} should not be
modified by the call. The second case specifies that, if \SPARK{A(X)} is
different from \SPARK{A(Y)} on entry, then \SPARK{A} should be modified by the
call.

\begin{lstlisting}
procedure Swap (A : in out Arr; X, Y : Idx) with
  Contract_Cases =>
    (A(X) = A(Y) => A = A'Old,
     A(X) /= A(Y) => A /= A'Old);
\end{lstlisting}

New expressions make it easier to express contracts. If-expressions and
case-expressions are the expression forms which correspond to the usual
if-statements and case-statements. Note that an if-expression without else-part
\SPARK{(if A then B)} expresses a logical implication of \SPARK{B} by
\SPARK{A}. Quantified expressions \SPARK{(for all X in A)} and \SPARK{(for some
  X in A)} correspond to the mathematical universal and existential
quantifications, only on a bounded domain. Expression functions define a
function with a single expression, like in functional programming languages. As
expression functions can be part of the specification of programs (contrary to
regular function bodies), they provide a powerful way to abstract complex parts
of contracts.

The second most useful feature in \newspark (after contracts) is the ability to
specify properties of loops. A loop invariant expresses the cumulated effect
of the loop up to that point. For example, the following loop invariant
expresses that the array \SPARK{A} has been zeroed out up to the current loop
index \SPARK{J}, and that the rest of the array has not been modified.
Attribute \SPARK{Loop_Entry} is used to refer to values on entry to the loop.

\begin{lstlisting}
pragma Loop_Invariant
  (for all K in A'Range =>
    (if K <= J then
       A(K) = 0
     else
       A(K) = A'Loop_Entry(K)));
\end{lstlisting}

A loop variant expresses that a quantity varies monotonically at each iteration
of the loop, which can be used to show loop termination. For example, the
following loop variant expresses that scalar variable \SPARK{J} increases at
each loop iteration.

\begin{lstlisting}
pragma Loop_Variant (Increases => J);
\end{lstlisting}

\subsection{Benefits of Executable Contracts}
\label{subsec:ExecutableContracts}

Traditionally, contracts have been interpreted quite differently depending on
whether they were used for run-time assertion checking or for formal program
verification. For run-time assertion checking, contracts have been interpreted
as assertions on entry and exit of subprograms. For formal program
verification, assertions have typically been interpreted as formulas in
classical first-order logic. This was the situation with SPARK prior to
\newspark. Practitioners have struggled with this interpretation, which was not
consistent with the run-time assertion checking semantics.\cite{tseChalin10}

\newspark reconciles the logic semantics and executable semantics of contracts,
so users can now execute contracts, debug them like code, and test them when
formal verification is too difficult to achieve. Furthermore, by keeping the
annotation language the same as the programming language, users don't have to
learn one more language.

Except for the Global and Depends contracts, all the contracts and assertion
pragmas presented previously lead to run-time assertions. If a given property
is not satisfied at run time, an exception is raised with a message indicating
the failing property, for example on the procedure \SPARK{Swap}:

\begin{footnotesize}
\begin{verbatim}
failed precondition from swap.ads:4
failed postcondition from swap.ads:5
contract cases overlap for subprogram swap
swap.ads:5 contract cases incomplete
failed contract case at swap.ads:7
Loop_Invariant failed at swap.adb:5
Loop_Variant failed at swap.adb:4
\end{verbatim}
\end{footnotesize}

Another key benefit of executable contracts is that they can be used by other
tools working at the level of code. For example, the CodePeer~\cite{codepeer}
static analysis tool uses contracts and assertion pragmas to issue more precise
messages. Most notably, this allows also combining the results of formal
verification and testing, when only part of a program is formally
analyzed.~\cite{hiliteERTS2012}

\subsection{Key Tool Features}

\gnatprove is the formal verification tool that analyzes \newspark code. It
performs two different analyses:

\begin{enumerate}
\item flow analysis of the program;
\item proof of program properties.
\end{enumerate}

Flow analysis checks correct access to data in the program: correct access to
global variables (as specified in Global and Depends contracts) and correct
access to initialized data. It is a fast static analysis (typically comparable
with compilation time) based on the computation of the Program Dependence
Graphs.~\cite{Horwitz:1988:ISU:53990.53994}

Proof is used to demonstrate that the program is free from run-time errors, and
that the specified contracts are correctly implemented. It internally generates
mathematical formulas for each property, that are given to the automatic prover
\altergo.~\footnote{\url{http://alt-ergo.ocamlpro.com/}} If \altergo manages to
prove the formula in the given time, then the property is known to
hold. Otherwise, more work is required from the user to understand why the
property is not proved. 

As proof requires interactions between the user and the tool until the
specification can be proved automatically, the efficiency and the granularity
at which the tool can be applied are critical. For efficiency, \gnatprove uses
a compilation-like model, where only parts that are impacted by a change need
to be reanalyzed, where the dependencies are both syntactic (coarse-grain) and
semantic (fine-grain). Also, the generation of formulas uses an efficient
algorithm~\cite{leino:2005:ipl} that avoids the possible combinatorial
explosion of the classical algorithm, and a small timeout of 1s is used by
default for the prover. For convenient interaction with the user during the
development of specifications, \gnatprove allows focusing on a single unit, a
single subprogram inside this unit, or even a single line inside this
subprogram.

A very useful feature of \gnatprove to investigate unproved properties is its
ability to display the paths in the program that lead to unproved
properties. This path can be displayed in
GPS~\footnote{\url{http://www.adacore.com/gnatpro/toolsuite/gps/}} or in
Eclipse~\footnote{\url{http://www.adacore.com/gnatpro/toolsuite/gnatbench/}},
the two Integrated Development Environments which support \newspark. The user
can also change the parameters of the tool to perform more precise proofs, at
the expense of longer running time.

%% \subsection{Combining Testing and Proof}

%% Formal methods are complementary to testing, and may find faults that
%% are not detected by testing, but they cannot establish verification
%% evidence for the target hardware. Therefore testing on the target is
%% still required. However, formal analysis of source code can be used to
%% show compliance with the low-level requirements. \DOC requires an
%% argument for property preservation between the source code and the
%% object code for those properties that have been verified formally at
%% the source level. Since formal program verification and testing are
%% complementary, we would like to use each method where it is most
%% efficient. For this we need to make sure that the combination is at
%% least as strong as testing alone.~\cite{hiliteERTS2012}.

\section{Train Control Systems}

% openETCS case study

The \openetcs\footnote{\url{http://openetcs.org/}} European project
aims at making an open-sourced, open-proofs reference model of ETCS
(European Train Control System). ETCS is a radio-based train control
system aiming at unifying train signaling and control over all
European countries. Organized in several levels, ETCS can range from,
at Level 0, a simple ATP (Automatic Train Protection) system
monitoring train speed to, at Level 3, a fully featured radio-based
train control system where trains inform a Radio Block Centre about
their location and receive Movement Authorities, using cab signaling
instead of track-side signaling.

We made some experiments with \newspark to see if one could formalize
the ETCS System Requirement Specification (SRS, ERA UNISIG
SUBSET-026).

We should acknowledge that using \newspark for formalizing
\emph{system} requirements (and not only software requirements) is a
bit excessive and out of scope for the language. We made nonetheless
this formalization attempt for two reasons. Firstly, we wanted to give
a formal semantics to this system specification and \newspark
first-order logic used in contracts seemed suitable for
this task. The goal of this formalization was to formally verify some
properties at the specification level.  Secondly, some of
the content of the ETCS specifications is quite low-level, therefore
not as far from software requirements as one would expect.

\subsection{Description of the Software}

We made several experiments but due to space constraints we will only
detail one of them.

This example is the coding of step functions, \aka functions
constant by interval, used in the \textit{Speed and distance monitoring}
section (SRS §3.13). Such functions are used to model for example
speed restrictions along distance. One of our main goal is to model
the merge of two speed restrictions, taking at each point the most
restrictive (\ie smaller) one.

To encode step functions, we used the following data structure:
\begin{lstlisting}
type Num_Delimiters_Range is range 0 .. 10;

type Function_Range is new Natural;

type Delimiter_Entry is record
   Delimiter : Function_Range;
   Value     : Float;
end record;

type Delimiter_Values is array
  (Num_Delimiters_Range) of Delimiter_Entry;

type Step_Function_t is record
   Num_Delim : Num_Delimiters_Range;
   Step      : Delimiter_Values;
end record;
\end{lstlisting}

A step function of type \SPARK{Step_Function_t} can have up to 11
steps (stored in array \SPARK{Step}) separated by 10 delimiters (in
\SPARK{Num_Delimiters_Range},
delimiter 0 being the initial value of the step function). Each
delimiter of type \SPARK{Delimiter_Entry} contains the delimiter
position (\SPARK{Delimiter}) and the associated constant value
(\SPARK{Value}) for the function. The currently used number of
delimiters is stored in \SPARK{Num_Delim}.

We defined several subprograms that query or update step functions:
\begin{itemize}
\item \SPARK{Get_Value(SFun, X)} returns the value of step function \SPARK{SFun}
  at point \SPARK{X};
\item \SPARK{Minimum_Until_Point(SFun, X)} returns the minimum of the step
  function \SPARK{SFun} until point \SPARK{X};
\item \SPARK{Restrictive_Merge(SFun1, SFun2, Merge)} merges step functions
  \SPARK{SFun1} and \SPARK{SFun2} into step function \SPARK{Merge}.
\end{itemize}

\subsection{Formalization of Properties}

We wanted to check full functional correctness of this critical unit. We used
contracts to express the specifications of all subprograms.

For example, in following function \SPARK{Minimum_Until_Point}, we
specified that given a valid (\ie with strictly increasing delimiters)
step function \SPARK{SFun} and a point \SPARK{X}, the returned value
(\SPARK{Minimum_Until_Point'Result}) is the minimum until point \SPARK{X} (1)
and effectively belongs to the domain of the step function (2).

\begin{lstlisting}
function Minimum_Until_Point
    (SFun : Step_Function_t; X : Function_Range)
                             return Float
with
Pre  => Is_Valid(SFun),
Post =>
  -- (1) Returned value is the minimum until point X
  (for all i in
    Num_Delimiters_Range'First..SFun.Num_delim =>
     (if X >= SFun.Step(i).Delimiter then
      Minimum_Until_Point'Result
         <= SFun.Step(i).Value))
  and
  -- (2) Returned value is a value of the step
  --     function until point X
  ((for some i in
     Num_Delimiters_Range'First..SFun.Num_delim =>
      (X >= SFun.Step(i).Delimiter
       and
         (Minimum_Until_Point'Result
             = SFun.Step(i).Value))));
\end{lstlisting}

Our next example is more complex.
In procedure \SPARK{Restrictive_Merge} we specified that, given two
valid step functions \SPARK{SFun1} and
\SPARK{SFun2} without too many delimiters, the resulting step function is a
valid one (1), it contains all the delimiters of \SPARK{SFun1} (2) and
\SPARK{SFun2} (3) and for each of those delimiters, the value of the step
function is the minimum of both initial step functions (4).

\begin{lstlisting}
procedure Restrictive_Merge
  (SFun1, SFun2 : in  Step_Function_t;
   Merge        : out Step_Function_t)
with
Pre =>
  Is_Valid(SFun1) and Is_Valid(SFun2)
    and
  SFun1.Num_Delim + SFun2.Num_Delim <=
    Num_Delimiters_Range'Last,
Post =>
  -- (1) Output is a valid step function
  Is_Valid(Merge)
    and
  -- (2) All SFun1 delimiters are valid in Merge
  (for all i in
     Num_Delimiters_Range'First..SFun1.Num_Delim =>
   (for some j in
     Num_Delimiters_Range'First..Merge.Num_Delim =>
      (Merge.Step(j).Delimiter
        = SFun1.Step(i).Delimiter)))
    and
  -- (3) All SFun2 delimiters are valid in Merge
  (for all i in
     Num_Delimiters_Range'First..SFun2.Num_Delim =>
   (for some j in
     Num_Delimiters_Range'First..Merge.Num_Delim =>
      (Merge.Step(j).Delimiter
        = SFun2.Step(i).Delimiter)))
    and
  -- (4) For each delimiter of Merge, its value is the
  --     minimum of SFun1 and SFun2
  (for all i in
     Num_Delimiters_Range'First..Merge.Num_Delim =>
   (Merge.Step(i).Value
    = Min(Get_Value(SFun1, Merge.Step(i).Delimiter),
          Get_Value(SFun2, Merge.Step(i).Delimiter))));
\end{lstlisting}

Please also notice that through the use of \SPARK{in} and \SPARK{out}
parameters, only \SPARK{Merge} can be written to and \SPARK{SFun1} and
\SPARK{SFun2} should be kept unmodified.

As last note, our contracts could have been lightened by attaching the
\SPARK{Is_Valid} function as a type invariant to
\SPARK{Step_Function_t} data structure. This is not currently
supported in \newspark but will in future releases.

\subsection{Formal Verification Results}

The first goal of this experiment was to check if \newspark was
expressive enough to describe the objects of the requirements:
requirement text, transition tables, breaking curve equations, \etc
Overall, we were quite satisfied, as we were able to express most of
the requirements in a formal way. The very expressive data structures
of \newspark (records, arrays, enumerations, \etc) were very helpful
compared to other specification languages like B~Method\cite{b-book}
(lacking usable record structure) or Frama-C's ACSL\cite{acsl}
(lacking record with variant part or easy limited range data type
definition). We found that it lead to quite readable specifications.

The second goal was to evaluate the automatic proving capabilities of \newspark
on some parts of the specification.

On step functions, we were able to prove all subprogram
contracts except the one of \SPARK{Restrictive_Merge}. In this procedure, the
postcondition and the loop invariant could not be automatically
proved by \altergo. The main reason is that the proof context is too
big and \altergo gets lost in all possible quantification
instantiations. We have checked that some parts of the loop invariant
could be automatically proved if the proof context was manually pruned
of irrelevant hypotheses. Moreover, we compiled and tested the
contracts and formal annotations, making us more confident about their
correctness.

We should also notice that in all those subprograms, we needed about
the same number of lines of formal annotations than of executable
code.

\subsection{Lessons Learned}

As said previously, we were rather pleased by the expression
capabilities of \newspark, making specification and code writing
rather easy and, more important, clearer for the reader. The ability
to define new data types for specific ranges and incompatible with
other types is crucial in this regard.

Another important finding is that the code should be written with
proof in mind. For example, in one of the step function procedure, we
wrote a loop with an early exit. However \altergo was unable to prove
this loop because it lacks induction reasoning, even if all elements
of the induction could be easily pointed out to the prover. We had to
change the code with a loop without early exit, the proof then
becoming trivial.

A third finding is that contracts that can be automatically proved are
not the most natural contracts, \ie contracts a reviewer would
understand more easily. For example, for \SPARK{Restrictive_Merge}
procedure, we would have preferred to write that the resulting function
is the minimum of both input functions for all possible input
values. It would have been impossible to prove this contract. Other
formal approaches with formal refinement like B~Method would probably
be able to formalize such contract, at the expense of manual proofs.

Our last finding, not entirely surprising, is that writing the correct
invariant for a complex loop is not an easy task, as we experimented
it for \SPARK{Restrictive_Merge} procedure. It can necessitate several
hours of work of skilled people, trained in the proof environment and
the reaction of the automatic prover. In such case, the ability to
compile and test the loop invariant is very useful to help ``debug''
the invariant.

Overall, we think that the programmer should be trained to exploit the
feedback provided by the proof environment, much like a programmer
exploits feedback of debuggers and tests to debug his/her program.
Moreover, as complete code proof can become very costly, a proof
methodology must be defined to avoid spending to much time on proofs
that would be broken afterward due to other code changes.


\section{Flight Control and Vehicle Management in Space}

\subsection{Description of the Software}

A typical space applicative flight program is made up of two parts, which we
both considered in our case study:
Flight control (or more generally numerical command and control algorithm) and
Mission and Vehicle Management.

\subsubsection{Numerical Command and Control Algorithms}

Numerical command and control algorithms take as inputs floating point values,
perform some numerical computations (with the classical basic mathematical
operators such as additions, subtractions, multiplications, divisions, absolute
values, trigonometry or operations on vectors and arrays, \etc) and return
floating point results. Such algorithms have generally a retro-action loop, \ie
internal states.

It is generally not possible to define interesting functional contracts for
such code. Indeed, the functional contract of the equation
``X := A * Y + Cos (Z)''
is just itself (\ie it is not possible to specify in a more abstract way this
equation). Then, instead of defining functional contracts, the objective on
this kind of software is the proof of absence of run-time errors (such as
division by zero) and the correctness of variable ranges (such as, for
instance, a velocity shall always be between 0 and 25 km/s).

\newspark has been first experimented on a solar wing management software (for a spacecraft such as the ATV / Automated Transfer Vehicle).
This piece of code uses a mathematical library which implementation is not in \newspark, implying that it could not be formally proved, but only tested. However, the interface of this mathematical library is in \newspark. The contracts defined on the mathematical library can then be used to prove the application code.

\begin{lstlisting}
function Sin (X : T_Float) return T_Float
with
  Pre  => (X >= -C_2Pi) and (X <= C_2Pi),
  Post => (Sin'Result >= -1.0) and (Sin'Result <= 1.0);
\end{lstlisting}

\subsubsection{Mission and Vehicle Management}

The Mission and Vehicle Management of a spacecraft is described by the ECSS (European Cooperation for Space Standardization) standard
{\bf ECSS-E-ST-70-01C ``Space engineering - Spacecraft on-board control procedures''}.
This standard defines the general principles of an On Board Control Procedure
(OBCP). An OBCP is in practice represented by a simplified programming language
interpreted on-board the spacecraft. This interpreter is generally at the
highest level of criticality of the spacecraft. The implementation of this
interpreter in \newspark is table driven and relies greatly on generic packages
(allowing an easy customization of the code)
and discriminants
(ensuring a strict typing of the code, even in case of heterogeneous communication between components of the system).

%%\begin{itemize}
%%\item The generic packages allow an easy customization of the code:
%%
%%\begin{lstlisting}
%% generic
%%    -- the list of events
%%    type T_Event_Id is (<>);
%%\end{lstlisting}
%%\item The discriminants ensures a strict typing of the code, even in case of heterogeneous communication between components of the system:
%%
%%\begin{lstlisting}
%% type T_Monitoring is
%%   (Simple, Window, Protected_Window);
%%
%% type T_Event_Status
%%   (Monitoring : T_Monitoring := Simple) is
%%    record
%%       Detection_Time : T_Float;
%%       case Monitoring is
%%       when Simple => null;
%%       when Window | Protected_Window =>
%%          Start_Window : T_Float;
%%          End_Window   : T_Float;
%%       end case;
%%    end record;
%%\end{lstlisting}
%%\end{itemize}

\subsection{Formalization of Properties}

The contracts defined on algorithmic code are mainly related to the ranges of variables.

%%\begin{lstlisting}
%%   subtype T_Angle_180 is T_Float
%%   range -180 .. 180;
%%
%%   function Normalise (X : in T_Float)
%%   return T_Angle_180
%%   with Pre => (X >= -720.0) and
%%               (X <=  720.0);
%%\end{lstlisting}

The contracts defined on mission and vehicle management code have (among others) the following objectives:

\begin{itemize}
\item Ensuring the permanent consistency of the software tables
\item Ensuring the permanent consistency between the Mission and Vehicle Management function and the other functionalities (such as, for instance, the solar wing management)
\item Ensuring the respect of some functional properties such as the mutual exclusion of execution of some automated procedures
\item Ensuring the absence of run-time errors
\end{itemize}

%%\begin{lstlisting}
%%   procedure Reset_Event
%%     (Event_Id :        T_Event_Id;
%%      Events   : in out T_Events)
%%   with
%%     Post =>
%%       Get_Status (Event_Id, Events) = Inactive)
%%       and then
%%       (for all Other_Id in T_Event_Id =>
%%         (if Other_Id /= Event_Id then
%%           Get_Status (Other_Id, Events) =
%%           Get_Status (Other_Id, Events'Old))));
%%\end{lstlisting}

\subsection{Formal Verification Results}

All the contracts have been checked by dynamic testing. This phase is quite classical, except for the fact that the testing includes the preconditions and the postconditions defined in the software. Then, \gnatprove has been applied.

The following table provides for each component:
The number of subprograms fully in \newspark (``Ok''),
the number of bodies not in \newspark (``BN''),
the number of specifications not in \newspark (``SN''),
the number of bodies not yet in \newspark (``BNY'') and
the number of specifications not yet in \newspark (``SNY''):

\vspace{5mm}

\begin{tabular}{|l|c|c|c|c|c|}
\hline
Component   & Ok  & BN  & SN & BNY & SNY \\
\hline
Library     &  15 &   0 &  0 &   0 &   0 \\
\hline
Algorithms  &  30 &   0 &  0 &   0 &   0 \\
\hline
Time        &   3 &   0 &  0 &   0 &   0 \\
\hline
Variable    &  85 &   0 &  0 &   0 &   0 \\
\hline
Variables   & 140 &   0 &  0 &   0 &   0 \\
\hline
Events      &  24 &   0 &  0 &   0 &   0 \\
\hline
Expressions & 331 &   0 &  0 &   0 &   0 \\
\hline
Parameters  &  62 &   0 &  0 &   0 &   0 \\
\hline
Units       &  76 &   0 &  0 &  13 &  13 \\
\hline
Sequences   & 192 &  28 & 15 &   3 &   3 \\
\hline
OBCP        & 547 & 447 & 30 &  13 &  13 \\
\hline
\end{tabular}

\vspace{5mm}

The origins of subprograms not yet in \newspark are the following:
class wide types (53 subprograms),
tagged type (81 subprograms) and
attribute (10 subprograms).
These origins are related to Object Oriented Programming. The analysis of Object Oriented software is foreseen but has not yet been implemented.

The origins of subprograms not in \newspark are the following:

\begin{itemize}
\item access (87 subprograms).
      Accesses are used to store objects in a table.
      This kind of design can not be proved by \gnatprove.
\item unchecked conversion (377 subprograms).
      The unchecked conversion are used in a library allowing reading external inputs.
      All the concerned subprograms are very small and shall be validated by intensive testing because there are out of the perimeter of \newspark.
\end{itemize}

The following table provides for each component: the number of lines of code (``size''), the number of preconditions (``pre''), the number of postconditions (``post'') and the duration of analysis in seconds (``duration''):

\vspace{5mm}

\begin{tabular}{|l|c|c|c|c|}
\hline
Component   & Size & Pre & Post & Duration \\
\hline
Library     &  694 &  34 &   39 &   233 \\
\hline
Algorithms  &  795 &   8 &    2 &   653 \\
\hline
Time        &   13 &   0 &    2 &    10 \\
\hline
Variable    &  260 &  41 &   30 &   118 \\
\hline
Variables   &  438 &  43 &   31 &   274 \\
\hline
Events      &  249 &  16 &   17 &   371 \\
\hline
Expressions & 1253 &  93 &   79 &  1992 \\
\hline
Parameters  &   75 &   0 &    1 &   279 \\
\hline
Units       &  463 &  13 &    8 &  2921 \\
\hline
Sequences   &  276 &   5 &    5 &  7803 \\
\hline
OBCP        &  714 &  33 &   15 & 13705 \\
\hline
\end{tabular}

\subsection{Analysis of the non proved checks}

The following table provides for each type of checks, their number and the number proved:

\vspace{5mm}

\begin{tabular}{|l|c|c|c|}
\hline
Features            & Checks & Proved & \%  \\
\hline
division check      & 22     & 22     & 100 \\
\hline
overflow check      & 164    & 164    & 100 \\
\hline
precondition        & 1410   & 1400   & 99  \\
\hline
postcondition       & 369    & 344    & 93  \\
\hline
range check         & 232    & 194    & 87  \\
\hline
assertion           & 967    & 961    & 99  \\
\hline
index check         & 184    & 46     & 25  \\
\hline
discriminant check  & 2334   & 2327   & 99  \\
\hline
loop initialization & 14     & 12     & 86  \\
\hline
loop  preservation  & 14     & 14     & 100 \\
\hline
\end{tabular}

\vspace{5mm}

The analysis of the non proved checks is the following.

Some algorithmic functions (e.g.trigonometric functions) are not completely known by \gnatprove and then can not be used in proofs.

\gnatprove has some difficulties to take into account rounding.
In the following example, the second assertion is not proved.
\begin{lstlisting}
pragma Assert (Y in -11160.002 .. 11160.002);
Round_Y := Round_Closest (Y);
pragma Assert (Round_Y in -11160.0 .. 11160.0);
\end{lstlisting}
\gnatprove currently does not prove non linear equation.
In the following example, the last assertion is not proved.
\begin{lstlisting}
pragma Assert (X in 0.0 .. 180.0);
pragma Assert (Y in -180.0 .. 0.0);
pragma Assert (Z in 0.0 .. 1.0);
pragma Assert (X + Y >= 0.0);
Result := X + Y * Z;
pragma Assert (Result in 0.0 .. 360.0);
\end{lstlisting}
\gnatprove is not yet able to verify the index of an array which dimension is defined by a type discriminant.
%%, for example:
%%\begin{lstlisting}
%%   subtype R is Integer range 1 .. 100;
%%   type T_Array is array (R range <>) of Boolean;
%%
%%   type T_Record (L : R) is record
%%      A : T_Array (1 .. L);
%%   end record;
%%
%%   function G (X : T_Record) return Boolean is
%%     (for all I in X.A'Range => X.A (I));
%%\end{lstlisting}
%%In function ``G'', the index check ``X.A (I)'' is not proved even if ``I'' is defined in the range of ``X.A''
%%An improvement of \gnatprove is in progress in order to deal with such case.

The remaining non proved checks are due to a too complex subprogram.
These subprograms shall be split in several smaller subprograms to be proved.

\subsection{Lessons Learned}

During the development of this case study, the following process has been defined:

\begin{enumerate}
\item Writing of the contracts of each subprogram
\item Development of the body and of the tests
\item Test of the software with executable contracts, and potentially correction.
			In 50\% of the cases, the error comes from the code, and in the other
			50\%, the error comes from the contract itself.
\item Formal proof of contracts.
			The exhaustive formal proof of a contract is very often not achieved at the first run.
			The reason(s) may be sometimes very difficult to understand
			\begin{itemize}
			\item Errors in the code are generally quite easy to find (as it is
						the classical activity of an engineer)
			\item Too weak contracts are almost always very difficult to detect without
						the help of an expert in \newspark
			\item Conclusions on a tool limitation shall almost always be confirmed by
						a senior expert on \newspark
			\end{itemize}
\end{enumerate}

The final feedback on this case study was that:
\begin{itemize}
\item The quality of the code has been dramatically improved thanks to both executable contracts and formal proof.
\item The writing of contracts for testing should become a natural activity of any software developer
\item Understanding why a proof (which may seem sometimes really obvious) does not work may require the involvement of an expert in \newspark
\item The writing of effective contracts for formal proof requires a dedicated training and sometimes the involvement of an expert in \newspark
\end{itemize}

The following needs are then expressed for \gnatprove in order to make possible its efficient use in an industrial context:
\begin{itemize}
\item ability to prove generic units once (instead of proving each instance like done currently)
\item need to use a sound model of floating-points instead of real numbers
\item some loop invariants generated automatically
\end{itemize}

\section{Biometric Access to a Secure Enclave}

% Tokeneer case study

\subsection{Description of the Software}

Tokeneer~\footnote{\url{www.adacore.com/sparkpro/tokeneer}} is a highly secure
biometric software system that was originally developed by Altran. The system
provides protection to secure information held on a network of workstations
situated in a physically secure enclave. The Tokeneer project was commissioned
by the US National Security Agency (NSA) to demonstrate the feasibility of
developing systems to the level of rigor required by the higher assurance
levels of the Common Criteria. The requirements of the system were captured
using the Z notation and the implementation was in \oldspark. The original
development artefacts, including all source code, are publicly available.

During this study, the source code for Tokeneer has been translated
into \newspark. The core system now consists of approximately 10,000
lines of \newspark code. There are also approximately 3,700 lines of
supporting code written in Ada which mimick the drivers to
peripherals connected to the core system.

\subsection{Converting \oldspark to \newspark}

For the majority of the code, translating \oldspark to \newspark was
very straight forward since most of the original annotations map
directly to the new ones. This section will focus on the more
interesting occasions where the conversion was non-trivial.

Often, it is convenient to introduce a function which exists
solely for the sake of proof and does not contribute at all in
the final executing program. The constructs which achieve this
functionality for \oldspark and \newspark respectively are proof
functions and ghost functions. In \oldspark, the behavior of a proof
function was defined with user rules, which are axioms expressed in a special
syntax and given to the proof system. In \newspark, this
behavior is simply given by the body of the ghost function.

The Global aspect has an additional mode \SPARK{Proof\_In} in \newspark \wrt
\oldspark. This mode is used to specify global variables of a subprogram which
appear solely within contracts and assertions. Therefore, the translation
required separating global variables of mode \SPARK{in} that were used
exclusively inside annotations (translated as \SPARK{Proof\_In} global
variables), from those that were used in code (translated as \SPARK{Input}
global variables).

Parts of the code were specially annotated to be ignored during formal
verification, because they contained constructs which were outside the Ada
subset supported by \oldspark. As \newspark supports a bigger subset of Ada
than \oldspark, a lot of this code is now formally analyzable. The two
constructs most often encountered that fall under this category are string
concatenation and array slices.

The information that values of variables respect the constraints of their type
is available for proofs with the new toolset. This simplifies both the work of
the programmer and the code itself. Consider the following code segment:

\begin{lstlisting}
for I in LogFileIndexT loop
  if LogFilesStatus(I) = Used then
    if UsedLogFiles.Length = 0 then
      UsedLogFiles.Head := LogFileIndexT'First;
      UsedLogFiles.LastI := LogFileIndexT'First;
      UsedLogFiles.Length := 1;
      UsedLogFiles.List(UsedLogFiles.Head) := I;
    else
      for J in LogFileIndexT
        range 1..UsedLogFiles.LastI
      loop
        ...
\end{lstlisting}

In \oldspark, it was necessary to add 25 lines of assertions to repeat that the
values of variables like \SPARK{I} and components like
\SPARK{UsedLogFiles.Head} are within the bounds allowed by their type, as this
information was lost inside loops. The new tools are more sophisticated and
preserve more of the context.

%% However, at this point, it should be pointed out that since the
%% development of the Tokeneer project the \oldspark tools have greatly
%% evolved and some of the original annotations might actually now be
%% redundant.

\subsection{Formalization of Properties}

The contracts that have been added in the Tokeneer source code consist
of information flow contracts expressed as Depends aspects and
functional behavioral contracts expressed as Pre and Post aspects.

The Depends aspects facilitate flow analysis of the code. Flow
analysis detects improper initialization, identifies ineffective
assignments and ensures secure flow of information.

The Pre and Post aspects enable the prover to show that the code is
free from run-time exceptions, such as buffer overflow or
divide-by-zero and assist in proving that key security properties are
guaranteed by the implementation.

\begin{tabular}{|l|c|}
\hline
Aspect/Pragma       & Number of occurrences  \\
\hline
\hline
Global              & 197 \\
\hline
Refined\_Global     & 71 \\
\hline
Depends             & 202 \\
\hline
Refined\_Depends    & 40 \\
\hline
Pre                 & 28 \\
\hline
Post                & 41 \\
\hline
Assume              & 3 \\
\hline
Loop\_Invariant     & 10 \\
\hline
\end{tabular}

\subsection{Formal Verification Results}

The original source code of Tokeneer was proven to be free of run-time
exceptions and some key security properties were proven to hold but
full functional proof was not performed on the entirety of the code.

\subsubsection{Fully specifying and proving a package}

In order to measure the expressiveness and proving power of the
\newspark tools, a specific package, on which functional behaviour
proof had not been attempted, was selected and then fully augmented
with functional behaviour annotations. Package \SPARK{admin}, which is
the package that was augmented, contains the state of the
administrator of the system and a set of operations that
administrators can perform.

To illustrate how functional behaviour contracts were added, we will
consider subroutine \SPARK{OpIsAvailable} of package \SPARK{admin}. An
administrator can be either a \SPARK{UserOnly}, a \SPARK{Guard}, an
\SPARK{AuditManager} or a \SPARK{SecurityOfficer}. Each type of
administrator has a set of predefined operations that it is allowed to
perform. Function \SPARK{OpIsAvailable} takes as input an
administrator and a string that is read from the keyboard and
determines if this string corresponds to an operation available to the
administrator. If the operation is indeed available, then this
operation is returned, otherwise \SPARK{NullOp} is returned.

\begin{lstlisting}
function OpIsAvailable
  (TheAdmin : T; KeyedOp : Keyboard.DataT)
  return OpAndNullT;
--# pre IsPresent(TheAdmin);
--# return R =>
--#   (R /= NullOp ->
--#     (R = OverrideLock <->
--#       prf_rolePresent(TheAdmin) = PrivTypes.Guard));
\end{lstlisting}
Here, the \oldspark postcondition serves only as a test case. It
ensures that if a non null operation was returned and if that
operation was \SPARK{OverrideLock} then the administrator was of type
\SPARK{Guard}. This annotation is incomplete since it does not specify
any other kind of valid combinations of administrator types and their
corresponding operations (\eg the administrator being of type
\SPARK{SecurityOfficer} and the operation being
\SPARK{UpdateConfigData} or \SPARK{ShutdownOp}) or under which
circumstances \SPARK{NullOp} should be returned.
The \oldspark tools also prove all properties associated with
the non-augmented \SPARK{admin} package but a total of 12 user rules had
to be provided. The
effort associated with proving the completed version of this
postcondition would have been significant and hence this was not attempted.

\begin{lstlisting}
function OpIsAvailable
  (TheAdmin : T; KeyedOp : Keyboard.DataT)
  return OpAndNullT;
with
  Pre  => IsPresent(TheAdmin),
  Post => (for some Op in Opt =>
             Str_Comp(KeyedOp, Op)
               and AllowedOp(TheAdmin, Op)
               and OpIsAvailable'Result = Op)
          xor OpIsAvailable'Result = NullOp;
\end{lstlisting}
This \newspark Post aspect states that we have two mutually
exclusive cases. If there exists some operation in \SPARK{Opt} that
matches the string read from the keyboard and this operation is
allowed for the current administrator then the result of function
\SPARK{OpIsAvailable} is this operation, otherwise, the result is
\SPARK{NullOp}.

The \newspark tools discharge all 24 verification conditions
associated with the augmented \SPARK{admin} package in a matter of
seconds.

\subsubsection{Overall provability}

More than 95\% of the checks that were associated with the converted
code were automatically discharged. The remaining 5\% consisted of
checks that either derived from code that was previously not
analyzable (and hence no provision was in place to assist in their
provability) or required something similar to the \oldspark user rules
to assist the prover in discharging them (this can potentially also be
achieved through utilizing a combination of pragmas Assert and
Assume). The typical cases that require additional assumptions are
those on which combinations of several non-trivial mathematical
transformations would have to be applied when performing a manual
proof.

\subsection{Lessons Learned}

While augmenting package \SPARK{admin}, it was noticed that formulating
the functional behaviour annotations based on the low level Z
specifications was very intuitive. This suggests that it might be
possible for future projects to skip this step and directly provide
\newspark annotated specifications.

An interesting case of how executable semantics affect the way code
and annotations have to be written was uncovered while attempting to
prove package \SPARK{AuditLog}. Converting \oldspark annotations into
their \newspark equivalents introduced several run-time checks that
previously did not exist. The extra checks are a byproduct of the
contracts and assertions being
executable~\ref{subsec:ExecutableContracts}. Some of these checks were
not automatically discharged. A more in depth investigation revealed
that an invariant was missing from the original specifications. This
invariant described the property of always using at least one log file
($UsedLogFile.Lenfth >= 1$).\footnote{\url{www.open-do.org/wp-content/uploads/2013/05/Industrial_Case_Studies_Final_Report.pdf}}.

When analyzing a single package in isolation, it was easy to
understand which verification conditions were proved and which were
not. However, when more than one files were analyzed in a single run,
due to the magnitude of the output, it became increasing complicated
to retain supervision of both individual and overall
provability. Having a tool that summarizes the results and informs
about remaining undischarged checks would greatly assist. For
instance, this would enable users to focus their efforts only on
proving packages for which more than 95\% automated proof was
achieved and resort to testing for the rest.

\section{Common Findings and Dissimilarities}

We will discuss the common findings between the three case studies,
denoting instrinsic properties of \newspark, and the dissimilarities,
which may be explained by differences in domains, backgrounds,
processes, \etc

\section{Conclusion}

We will summarize the three case studies, and present the planned future
evolutions of \newspark.

\section{Acknowledgment}

Part of this work was funded by the ``Direction Générale de la
compétitivité, de l'industrie et des services'' (DGCIS) (Grant
No. 112930309) in the context of the ITEA2 project \openetcs.

\bibliographystyle{plain}
\bibliography{erts_2014}

\end{document}


% LocalWords:  openETCS ETCS UNISIG Centre SRS
