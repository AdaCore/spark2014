\documentclass{llncs} \usepackage[utf8]{inputenc} \usepackage{url}
\usepackage{xspace} \usepackage{hyperref} \usepackage{listings}
\usepackage{amsmath} \usepackage{graphicx} \usepackage{zed-csp}

\newcommand{\DO}{\textsc{do-178}\xspace}
\newcommand{\DOB}{\textsc{do-178b}\xspace}
\newcommand{\DOC}{\textsc{do-178c}\xspace}
\newcommand{\hilite}{Hi-Lite\xspace}
\newcommand{\gnatprove}{GNATprove\xspace}
\newcommand{\oldspark}{SPARK~2005\xspace}
\newcommand{\newspark}{SPARK~2014\xspace}
\newcommand{\spark}{SPARK\xspace} \newcommand{\ada}{Ada\xspace}
\newcommand{\adatwtw}{Ada~2012\xspace}
\newcommand{\vectorcast}{VectorCast\xspace}

\newcommand{\etc}{\textit{etc.}\xspace}
\newcommand{\ie}{\textit{i.e.,}\xspace} \newcommand{\adhoc}{\textit{ad
    hoc}\xspace} \newcommand{\Eg}{\textit{E.g.,}\xspace}
\newcommand{\eg}{\textit{e.g.,}\xspace} \newcommand{\etal}{\textit{et
    al.}\xspace} \newcommand{\wrt}{w.r.t.\xspace}
\newcommand{\aka}{a.k.a.\xspace} \newcommand{\resp}{resp.\xspace}

\lstdefinestyle{tinystyle} {basicstyle=\scriptsize\tt,
  keywordstyle=\bf, commentstyle=\rmfamily\it, escapeinside={(*}{*)}}
\lstset{style=tinystyle}

\lstdefinelanguage{SPARK}{ language = [95]Ada, morekeywords = {pre,
    post, assert, assume, check, derives, hide, global, inherit, from,
    own, initializes, main_program, input, output, in_out,
    refined_pre, refined_post, some, depends}, comment=[l][commentstyle]{--\ },
  showstringspaces=false }

\lstset{language=SPARK}

\begin{document}

\title{Optimising Verification Effort with \newspark}

\author{Pavlos Efstathopoulos, Andrew Hawthorn}
\institute{ALTRAN, 22 St Lawrence Street, Bath BA1 1AN (United Kingdom)}

\maketitle

\begin{abstract}
This paper considers the problems of subprogram specification,
implementation and verification in the context of SPARK 2014.  We
touch lightly on specification and implementation and focus on how to
combine formal verification and test efficiently.

The method of specification and implementation are covered briefly as
the methods used affect how formal methods can be applied. We explain
how different depths of formal analysis can be used but focus on the
case where full functional specifications are provided.

We then consider a number of scenarios where proof, test or a
combination of both can be used to verify the functional behaviour of
software. For each scenario, we identify the most effective method of
verification and demonstrate it using the SPARK 2014 toolset and or a
commercial unit testing tool.

We conclude by summarising our views on the most effective combination
of proof and test and any limitations in current tooling.

\end{abstract}

\paragraph{Keywords}
Formal methods, Verification and validation, Certification,
Dependability, DO-178C

\section{Introduction}
The introduction of executable contracts in Ada 2012 brings a new
dimension to the debate over which is most efficient: proof or
test. The Hi-Lite project was designed to demonstrate this extension
and coverered the question of how proven subprograms can reliably call
tested subprograms and visa versa \cite{hiliteERTS2012}. This paper
looks at the issue from an industrial perspective to try to identify
where it is most efficient to prove or test subprograms.

Test is clearly the most preferred method of verifying software at the
moment but the regulated industries have been trying to use formal
methods where they can ever since software was first written. The
acceptance of formal methods seems to be increasing, for example, the
latest version of the aerospace standard \DO provides explicit
guidance on the use of formal methods.

Given the general view that test is the best method of verification,
we introduce here a number of scenarios where proof can complement and
replace test with either minimal additional effort or less effort than
using test alone.

The majority of the scenarios defined here rely on the use of Ada 2012
contracts to specify the functionality of a subprogram, we therefore
spend a little time understanding how expressive they are and what
additional cost (if any) is attributable to their use.


\section{Spectrum of formal verification in \newspark}

Formal verification can be applied to varying levels to help reduce
the number of bugs introduced and maximise the number of bugs found.

\newspark provides many features to support such program analysis,
this section only introduces the features that directly support the
combination of proof and test.

\newspark is the next incarnation of \oldspark \cite{sparkbook2012}
that is effectively a complete re-write of the language and the
toolset. One of the main drivers behind this update is \adatwtw - the
executable contracts and generic aspect definitions being particularly
useful.

The features of \newspark that are particularly relevant to the proof
and test combination are:
\begin{itemize}
   \item language subsetting;
   \item flow analysis;
   \item the use of theorem provers to demonstrate absence of run-time
     errors;
   \item partial and full specification using pre- and
     post-conditions; and
   \item the use of global contracts.
\end{itemize}

\subsection{\newspark language subset}
The \newspark language subset is designed with the same philosophy as
\oldspark but because of advances in technology far more features of
\ada can be practically formally reasoned about. The \newspark
language subset will therefore be a lot larger than \oldspark.

The key language features that are not in the subset are:

\begin{itemize}
   \item no access types (pointers);
   \item expressions (hence functions) must not have side-effects;
   \item no aliasing (but renaming is permitted);
   \item no gotos;
   \item no controlled types;
   \item no tagged types (for now...);
   \item no tasking (for now...); and
   \item no exceptions.
\end{itemize}

These restrictions are necessary for proof but also help test by
removing classes of faults that are difficult to find during
testing. For example, aliasing of globals may not be spotted at unit
test because the aliasing does not have an effect and may not be
spotted at system test because the alisasing has such a subtle effect.

For this reason, the authors recommend that the \newspark language
subset is used irrespective of whether or not proof or test is being
used to verify a subprogram.

\subsection{\newspark Flow analysis}
Flow analysis is the term we use for identifying uninitialized and
unused variables and ineffective statements.  It is important for
proof and test because the proof relies on all variables being
initialised and test results can be skewed in the presence of
uninitialised variables. Coverage analysis can also benefit from flow
analysis because it can identify ineffective statements.

For these reasons, the authors recommend that flow analysis is carried
out on all subprograms irrespective of whether or not proof or test is
being used to verify a subprogram.

\subsection{Proof of absence of run-time errors}

Proof of absence of run-time errors verifies that no exceptions will
be raised. This covers the following Ada checks:

\begin{itemize}
   \item overflow check;
   \item range check;
   \item index check;
   \item division check;
   \item discriminant check and
   \item length check.
\end{itemize}

See the Ada Language Reference Manual for the precise definitions.

For these reasons, the authors recommend that proof of absenct of
run-time errors is carried out on all subprograms irrespective of
whether or not proof or test is being used to verify a subprogram.

\subsection{\adatwtw Pre- and postconditions}

\ada \emph{Pre} and \emph{Post}-conditions can be used for a variety
of purposes. At their simplest they can be used to support proof of
absence of run-time errors (\eg by constraining the ranges of inputs
and outputs). They can also be used to specify specific properties of
a program (\eg a safety property is always true). They can also be
used to fully specify the behaviour of a subprogram (\ie the effect of
the subprogram is fully defined in the postcondition).

The following example is of a subprogram which has its behaviour fully
specified.

\begin{lstlisting}[language=SPARK]
A_Counter : Integer;

procedure Inc_A_Counter (N : in Integer)
   with Pre  => N >= 0,
        Post => A_Counter = A_Counter'Old + N;
\end{lstlisting}

The executable nature of the pre- and postconditions means that we
have an in-built method of checking that the result of a subprogram
call meets its specification. This is an extremely powerful feature
that can be used both informally and formally.

In \newspark these contracts can be refined in the body but these
refinements are less interesting from a proof and test perspective.

\subsection{\newspark Global contract}

\newspark introduces a new \ada aspect \emph{Global} which is used to
specify the global variables and their modes that a subprogram may
use. The Global aspect can be used without Pre and Post to define a
very basic contract \eg a Global aspect defines which globals a
subprogram will modify and which will be unmodified.

The Global aspect is important from a proof and test perspective
because it can be used to demonstrate ``non-interference''. Where
``non-interference'' means that a subprogram only updates the
parameters and globals that are defined in its contract.

The following example extends the first by defining the globals for
Inc\_A\_Counter. The \newspark tools check that the subprogram
complies with its Global annotation so in this case they guarantee
that Inc\_A\_Counter does not read or write to B\_Counter.

\begin{lstlisting}[language=SPARK]
A_Counter : Integer;
B_Counter : Integer;

procedure Inc_A_Counter (N : in Integer)
   with Global => (Output => A_Counter),
        Pre    => N >= 0,
        Post   => A_Counter = A_Counter'Old + N;
\end{lstlisting}


\section{Expressiveness of Ada contracts}

In this section we consider how easy it is to represent specifications
that would normally be written in \emph{Z} in Ada expressions. We
start with Z because it is a popular specification language for
software systems that need to use formal methods.

The following Z schema has been translated to demonstrate how some of
the most used constructs in formal specifications are represented in
\adatwtw contracts:

\begin{schema}{ValidEnrol}
Enrol\\ \where

        issuerCerts \cap \{ CAIdCert \} \neq \emptyset

\also

\\ \forall cert : issuerCerts @

           cert.isValidatedBy \neq Nil

\\ \t1 \land (\exists issuerCert : issuerCerts @

        issuerCert \in {CAIdCert}

\\ \t2 \land The \ cert.isValidatedBy = issuerCert.subjectPubK

\\ \t2 \land cert.id.issuer = issuerCert.subject )

\end{schema}

\begin{lstlisting}[language=SPARK]
function ValidEnrol (CAIdCert : in ID) return Boolean
   with Global => (Input => issuerCerts),
        Pre    => (for some issuerCert in issuerCerts => cert = CAIdCert),
        Post   => ValidEnrol'Result = (for all cert in issuerCerts =>
                    (cert.isValidatedBy /= NullCert
                     and (for some issuerCert in issuerCerts =>
                            (issuerCert = CAIDCert
                             and cert.isValidatedBy = issuerCert.subjectPubK
                             and cert.id.issuer = issuerCert.subject))));
\end{lstlisting}

This example is taken from the Tokeneer project which is available for
public download from the AdaCore website. It demonstrates how close Z
specifications are to executable code and indeed the above example
could be written as an \adatwtw expression function which would then
not need a body.

This is a good example of where writing the specification in a
particular way can reduce the development effort and/or support rapid
prototyping. With the function written as it is, a body needs to be
written but if efficiency is not an issue or a prototype is required
it could be written as an expression function and then no more
development effort is required.

From this perspective, writing expression functions should be the
preferred method for specifying the software. However, this removes
the semantic gap between the specification and the code. In some
contexts this may be considered very useful but it could lead to
specification faults being missed. This is an interesting topic but
will not be developed further here.

ToDo: We then consider the practical expressiveness of \newspark pre-
and post-conditions in comparison with Z using Tokeneer as an example
application. There are 157 schemas in Tokeneer.


\section{Scenario identification}

We now consider a number of scenarios where proof and test may be
combined to demonstrate code compliance with a formal
specification. We assume the user has used the \newspark subset,
carried out flow analysis and completed proof of absence of run-time
errors.

The following list provides good coverage of the types of scenarios
most users are likely to find themselves in. Unless explicitly stated
otherwise, each scenario assumes a full specification is provided in
pre-/post-conditions and proof initially fails.

\begin {enumerate}
\item \emph{Prove by strengthening assertions} - try to fully prove
  the code by strengthening preconditions and adding assertions until
  full proof is achieved. No testing is involved in this scenario.

\item \emph{Test without proof} - decide that proof is too difficult
  to achieve (for example, due to the code having complicated
  constructs like multiple nested loops) and resort to testing right
  from the beginning. No proof is involved in this scenario.

\item \emph{Prove some, test some} - attempt to prove the code, fail
  and resort to testing. At this point the user has two different
  options:

  \begin{enumerate}
  \item Perform exclusively testing (prove no properties).

  \item Prove only a subset of the properties of the code and test the
    remaining. For instance, prove freedom of run-time exceptions and
    test functional behaviour-related contracts.
  \end{enumerate}

\item \emph{Use test to debug contracts} - make a first unsuccessful
  attempt to prove the code and afterwards utilize testing to identify
  potential issues with the contracts or the implementation. The tests
  might provide hints as to how the user can alter the code to render
  it provable. In this scenario, testing reveals the actions that need
  be performed to achieve full proof. [Angela's solution to the
  ?VSTTE? competition.]

\item \emph{Contracts can not be written} - not able to formulate a
  contract. [interfacing, externals or something that is hard to put
  into a contract (\eg performance/complexity)].

\item \emph{Proof results not useable} - be required (by a standard)
  to test the code. However, as an addition, performing proof could
  improve the safety case and grant more confidence on the code. In
  this scenario the user would try to prove as much as possible, but
  would not insist when proof is too hard. [Tokeneer]
\end{enumerate}

When more than one units have to be analysed, any combination of the
above could potentially occur. Naming but a few such examples, it
would be possible to have:
\begin{itemize}
\item a subprogram Q for which a full formal specification cannot be
  provided. Consequently Q is tested. Subprogram P, which has to be
  proven, calls Q. A partial specification is therefore added to Q to
  assist with the proof of P.

\item a subprogram that has only been tested is utilized in the proof
  of one of its callers.
\end{itemize}



\section{Scenario evaluation}

\subsection{Prove by strengthening assertions}
In this section, we will attempt to prove 3 functions. The entire
process that was followed will be presented. The chosen functions have
precise mathematical definitions and consequently it was hypothesised
that fully proving them should be possible. The functions are the
following:
\begin{enumerate}
\item Function \emph{Is\_Prime} takes a natural number as its single
  parameter and returns true if that number is a prime and false if it
  is not. A natural number (\ie $1, 2, 3, 4, \dots$) is called a prime
  if it has exactly two positive divisors, $1$ and the number itself.

\item Function \emph{Are\_Coprime} takes two natural numbers as
  parameters and returns true if these numbers are coprime and false
  if they are not. Two naturals X and Y are called coprime if the only
  natural that evenly divides both of them is $1$.

\item Function \emph{Factorial} takes a natural number as its
  parameter and returns this number's factorial. The factorial of a
  natural number is the product of that number and all natural numbers
  below it (\Eg $5! = 5 * 4 * 3 * 2 * 1$).
\end{enumerate}

\subsubsection{Generating and proving the code}
As a first attempt, the following code was written:
\lstinputlisting[language=Ada, numbers=left, title=Initial Spec]
{Code/proven/Initial_Attempt/proven.ads}
\lstinputlisting[language=Ada, numbers=left, title=Initial Body]
{Code/proven/Initial_Attempt/proven.adb}

Functions \emph{Is\_Prime} and \emph{Are\_Coprime} were proven
straight away while the following messages that relate to function
\emph{Factorial} were issued:

proven.adb:47:19: overflow check not proved

proven.adb:47:19: range check not proved

\noindent
To resolve these, it must be shown that:
\begin{enumerate}
\item the value returned by the expression $N * Factorial (N - 1)$ is
  within the range $Natural'First .. Natural'Last$.

\item the result of $N - 1$ is within the range $Natural'First
  .. Natural'Last$.
\end{enumerate}
Unfortunately, property 1 does not hold for the current code. If
parameter $N$ exceeds a certain value, then the result of
\emph{Factorial} will not fit within a Natural and an overflow
exception will be raised at runtime.

In order to overcome these issues, a precondition, an assumption and a
new subtype had to be introduced to the code. The precondition creates
an obligation, for all callers of \emph{Factorial}, that $N \leq
10$. The assumption informs the tools that $Factorial (N - 1) \leq
362880$, since $(10 - 1)! = 9! = 362880$. Finally, the subtype
constrains the value returned by the function to the range $1
.. 362880$. After strengthening the code, all verification conditions
are discharged.

\lstinputlisting[language=SPARK, title=Strengthened Spec, firstline=13,
  lastline=21]{Code/proven/Strengthened/proven.ads}
\lstinputlisting[language=SPARK, title=Strengthened Body, firstline=35,
  lastline=46]{Code/proven/Strengthened/proven.adb}

\subsubsection{Notable observations}
The initial assumption that was made was that the selected functions
would be proof-friendly due to their mathematically well-defined
nature. This was indeed the case. However, recursive definitions (such
as the definition of function \emph{Factorial}) can considerably
complicate the proving process (a non-recursive equivalent of the
existing contract could not be generated).


\subsection{Test without proof}
The costs associated with fully proving a unit might occasionally
overshadow the benefits entailed. Testing can provide a certain
confidence in the validity of the code without requiring for a lot or
resources to be consumed. This section provides an example where
testing was deemed to be more efficient and attempts to identify more
cases where this is true.

\subsubsection{Mergesort}
The code that follows is an Ada implementation of the top-down version
of a well known sorting algorithm called mergesort.
\lstinputlisting[language=SPARK, title=Mergesort's
  Spec]{Code/tested/mergesort.ads} \lstinputlisting[language=SPARK,
  title=Mergesort's Body]{Code/tested/mergesort.adb}

\subsubsection{\vectorcast tool and testing results}
In order to establish that no errors were introduced during the
conversion of the pseudo-code into source code, a tool called
\vectorcast was utilized. \vectorcast reads the Ada source code and
assists in the generation of a test harness.

TODO: Give a more detailed description of \vectorcast and emphasise
that creating the test harness was effortless, despite using the tool
for the first time.

Even thought the tests that were added were very basic (a total of 3
pairs of inputs and their expected outputs were written), 100\%
statement coverage and 96\% branch coverage was achieved. All tests
yielded the expected results.

\subsubsection{Cases where proof does not add much value}
Well-established algorithms such as A* (A star), quicksort, \etc have
been used by many programmers throughout the years and have been
mathematically shown to hold true. Spending time in annotating the
implementations of such algorithms in order to force them through
proof tools is arguably not worth the effort. In such cases,
performing some basic tests to ensure that no porting errors were made
should be sufficient.

\subsection{Prove some, test some}
Having an accurate contract and a flawlessly annotated implementation,
unfortunately, does not always guarantee that all properties of the
code will be fully verified.  Theorem provers are the best option
currently available for performing automated reasoning and even though
they improve on a daily basis they are still far from perfect.  This
section presents two examples and shows two different courses of
action that a user can follow when proof is not (directly) achievable.

\subsubsection{Fall back to testings}
Current theorem provers are great with linear arithmetic but struggle
with non-linear arithmetic as shown in this example.
\lstinputlisting[language=SPARK, title=Spec Of Example
  One]{Code/proof_failed/example_one/example_one.ads}
\lstinputlisting[language=SPARK, title=Body Of Example
  One]{Code/proof_failed/example_one/example_one.adb} The given code
should be provable with its current annotations but the tools are not
able to discharge the overflow check associated with line
10. Restructuring the code and/or the annotations could potentially
enable the tools to achieve full proof. However, for this example, due
to the simplicity of the code, performing a manual review and writing
some basic tests was deemed to be more cost-effective.

\subsubsection{Perform a partial proof}
Proof is easily applied to leaf procedures and functions but can be
more tricky for higher level procedures. In the following example all
of the functions declared in the specification were proven
automatically. Test was used to demonstrate the top-level Sort
procedure.
\lstinputlisting[language=SPARK, title=Spec Of Example
Two]{Code/proof_failed/example_two/sorting.ads}
\lstinputlisting[language=SPARK, title=Body Of Example
Two]{Code/proof_failed/example_two/sorting.adb}


\subsubsection{Points of interest arising from attempting to verify}
When the tools are unable to discharge a verification condition and
the user is confident that the existing annotations should be
rendering it provable, trying the following might help:
\begin{itemize}
\item Increase the time spent by the prover on each verification
  condition.

\item Restructure the code and/or annotations to facilitate proof.
\end{itemize}

Predicting if a prover will be able to discharge a certain
verification condition is not always possible. Results might
occasionally even differ between provers. Non the less, there are
certain areas where provers are known to perform well (linear
arithmetics) and other areas where automated proof is harder to
achieve (non-linear arithmetics). The more accustomed a user becomes
to the tools, the easier it becomes to predict what will be
automatically provable. Performing proof when it is expected to be
easy and testing the remainder of the code is theorised to be the most
time-efficient code-validating method.

\subsection{Use test to debug contracts}
Unit test can be used to debug contracts, in some cases, unit tests
may identify invalid pre- or postconditions more quickly than review.

Todo: Expand this section.

\subsubsection{Example code}
\subsubsection{Describe approach to verification}
\subsubsection{Report results of verification}
\subsubsection{Report any points of interest arising from attempting to verify}

\subsection{Contracts can not be written}

There are a number of situations, particularly at the boundary of a
system, where full functional specifications can not be written. In
this case partial specifications may be required - these provide the
view of the outside world required for the formal model. In this case,
a combination of partial proof and test is ideal although pure test
would be sufficient.

Todo: Expand this section.

\subsubsection{Example code}
\subsubsection{Describe approach to verification}
\subsubsection{Report results of verification}
\subsubsection{Report any points of interest arising from attempting to verify}

\subsection{Proof results not useable}

In some certification contexts the proof results may not be useable so
how can you justify proving code to your managers? - For some types of
code the cost of proof is negligible but good at spotting bugs.

Todo: Expand this section.

\subsubsection{Example code}
\subsubsection{Describe approach to verification}
\subsubsection{Report results of verification}
\subsubsection{Report any points of interest arising from attempting to verify}

\section{Summary}

The introduction of \newspark heralds a leap towards the ultimate goal
of making the use of formal methods more cost effective than
traditional methods of software development. The ability to easily
switch between test and proof and the automation of proof tasks
provides the potential to identify code faults much earlier and
thereby dramatically reduce verification effort. There are some
tooling limitations that mean this goal is not yet met but many of
these have simple engineering solutions.

\subsection{How can proof and test most effectively be combined?}
Todo: Complete this section. Where proof is free executing contracts
to help debugging them

\subsection{Summary of limitations of current tooling}

Todo: Complete this section.

Todo: NB each of these points should be introduced earlier in this
doc.

What additional tooling support is required to make it easier/more
generally applicable.

Unit testing: At least Ada 2012 support required in unit testing
tools. Unit test tools should support the execution of contracts and
allow the result of a postcondition execution in place of "expected
outputs". Unit test tools should support turning on and off execution
of specific contracts (to support formal testing)

Proof: non-linear proof floating point proof

Proof and test: Need for assumption management.

\bibliographystyle{plain}
\bibliography{proof_and_test}

\end{document}
