\documentclass{llncs}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{graphicx}

\newcommand{\DO}{\textsc{do-178}\xspace}
\newcommand{\DOB}{\textsc{do-178b}\xspace}
\newcommand{\DOC}{\textsc{do-178c}\xspace}
\newcommand{\hilite}{Hi-Lite\xspace}
\newcommand{\gnatprove}{GNATprove\xspace}
\newcommand{\oldspark}{SPARK~2005\xspace}
\newcommand{\newspark}{SPARK~2014\xspace}
\newcommand{\spark}{SPARK\xspace}
\newcommand{\ada}{Ada\xspace}
\newcommand{\adatwtw}{Ada~2012\xspace}

\newcommand{\etc}{\textit{etc.}\xspace}
\newcommand{\ie}{\textit{i.e.,}\xspace}
\newcommand{\adhoc}{\textit{ad hoc}\xspace}
\newcommand{\Eg}{\textit{E.g.,}\xspace}
\newcommand{\eg}{\textit{e.g.,}\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}
\newcommand{\wrt}{w.r.t.\xspace}
\newcommand{\aka}{a.k.a.\xspace}
\newcommand{\resp}{resp.\xspace}

\lstdefinestyle{tinystyle}
   {basicstyle=\scriptsize\tt,
    keywordstyle=\bf,
    commentstyle=\rmfamily\it,
    escapeinside={(*}{*)}}
\lstset{style=tinystyle}

\begin{document}

\title{Practical approaches to the combination of proof and testing with \newspark}

\author{Pavlos Efstathopoulos}
\institute{ALTRAN, 22 St Lawrence Street, Bath BA1 1AN (United Kingdom)}

\maketitle

\begin{abstract}
This paper identifies a number of scenarios where software may
be proven, tested or a combination of both is utilised to verify the
software. For each scenario, the most effective method of verification
is identified and demonstrated using the \newspark toolset and/or
VectorCast.
\end{abstract}

\paragraph{Keywords}
System formal development, Verification and validation,
Certification and dependability

\section{Introduction}
Outline the context and describe why we believe the combination of proof
and test can be better than using exclusively one or the other. Refer to Yannick's
``Testing or Formal Verification: DO-178C Alternatives and Industrial Experience''

The ideal scenario, in a user's perspective, would be for the entirety of the code
to be fully proven. This would provide the utmost confidence in the code's validity
and would eliminate all costs associated with testing. Unfortunately, a plethora of
reasons usually render this impossible.

The cost associated with formal proof, both in the sense of effort and money spent,
increases as code gets more complicated. Test is easier, cheaper and can be performed
by non-experts.

Define a method for identifying scenarios, describe all of the scenarios,
and justify their completeness.


\section{Scenario identification}
Given a certain piece a code, a user might:

\begin {itemize}
  \item try to fully prove the code and keep strengthening preconditions
    and adding assertions until full proof is achieved. No testing is
    involved in this scenario.

  \item decide that proof is too difficult to achieve (for example, due
    to the code having complicated constructs like multiple nested
    loops) and resort to testing right from the beginning. No proof
    is involved in this scenario.

  \item attempt to prove the code, fail and resort to testing. At this
    point the user has two different options:

    \begin{enumerate}
      \item Perform exclusively testing (prove no properties).

      \item Prove only a subset of the properties of the code and
        test the remaining. For instance, prove freedom of run-time
        exceptions and test functional behaviour-related contracts.
    \end{enumerate}

  \item make a first unsuccessful attempt to prove the code and afterwards
    utilize testing to identify potential issues with the contracts or
    the implementation. The tests might provide hints as to how the user
    can alter the code to render it provable. In this scenario, testing
    reveals the actions that need be performed to achieve full proof.
    [Angela's solution to the ?VSTTE? competition.]

  \item not be able to formulate a contract. [interfacing, externals or something
    that is hard to put into a contract (/Eg performance/complexity)].

  \item be required (by a standard) to test the code. However, as an addition,
    performing proof could improve the safety case and grant more confidence on the
    code. In this scenario the user would try to prove as much as possible, but would
    not insist when proof is too hard.
    [Tokeneer]
\end{itemize}

When more than one units have to be analysed, any combination of the above could
potentially occur. Naming but a few such examples, it would be possible to have:
\begin{itemize}
  \item a subprogram Q for which a full formal specification cannot be provided.
    Consequently Q is tested. Subprogram P, which has to be proven, calls Q.
    A partial specification is therefore added to Q to assist with the proof of P.

  \item a subprogram that has only been tested is utilized in the proof of one of its
    callers.
\end{itemize}



\section{Prove the code by strengthening assertions}
In this section, we will attempt to prove 3 functions. The entire process that
was followed will be presented. The chosen functions have precise mathematical
definitions and consequently it was hypothesised that fully proving them should
be possible. The functions are the following:
\begin{enumerate}
  \item Function \emph{Is\_Prime} takes a natural number as its single parameter
    and returns true if that number is a prime and false if it is not. A natural
    number (\ie $1, 2, 3, 4, \dots$) is called a prime if it has exactly two
    positive divisors, $1$ and the number itself.

  \item Function \emph{Are\_Coprime} takes two natural numbers as parameters and returns
    true if these numbers are coprime and false if they are not. Two naturals X and Y
    are called coprime if the only natural that evenly divides both of them is $1$.

  \item Function \emph{Factorial} takes a natural number as its parameter and returns
    this number's factorial. The factorial of a natural number is the product of that
    number and all natural numbers below it (\Eg $5! = 5 * 4 * 3 * 2 * 1$).
\end{enumerate}

\subsection{Generating and proving the code}
As a first attempt, the following code was written:
\lstinputlisting[language=Ada, numbers=left, title=Initial Spec]
                {Code/proven/Initial_Attempt/proven.ads}
\lstinputlisting[language=Ada, numbers=left, title=Initial Body]
                {Code/proven/Initial_Attempt/proven.adb}
Functions \emph{Is\_Prime} and \emph{Are\_Coprime} were proven straight away while the
following messages that relate to function \emph{Factorial} were issued:

proven.adb:47:19: overflow check not proved

proven.adb:47:19: range check not proved

\noindent
To resolve these, it must be shown that:
\begin{enumerate}
  \item the value returned by the expression $N * Factorial (N - 1)$ is within
    the range $Natural'First .. Natural'Last$.

  \item the result of $N - 1$ is within the range $Natural'First .. Natural'Last$.
\end{enumerate}
Unfortunately, property 1 does not hold for the current code. If parameter
$N$ exceeds a certain value, then the result of \emph{Factorial} will not fit
within a Natural and an overflow exception will be raised at runtime.

In order to overcome these issues, a precondition, an assumption and a new
subtype had to be introduced to the code. The precondition creates an obligation,
for all callers of \emph{Factorial}, that $N \leq 10$. The assumption informs the tools
that $Factorial (N - 1) \leq 362880$, since $(10 - 1)! = 9! = 362880$. Finally, the
subtype constrains the value returned by the function to the range $1 .. 362880$.
After strengthening the code, all verification conditions are discharged.

\lstinputlisting[language=Ada, title=Strengthened Spec, firstline=13,
                 lastline=21]{Code/proven/Strengthened/proven.ads}
\lstinputlisting[language=Ada, title=Strengthened Body, firstline=35,
                 lastline=46]{Code/proven/Strengthened/proven.adb}

\subsection{Notable observations}
The initial assumption that was made was that the selected functions would be
proof-friendly due to their mathematically well-defined nature. This was indeed
the case. However, recursive definitions (such as the definition of function
\emph{Factorial}) can considerably complicate the proving process (a non-recursive
equivalent of the existing contract could not be generated).



\section{Resort to testing right away}
The costs associated with fully proving a unit might occasionally overshadow
the benefits entailed. Testing can provide a certain confidence in the validity of
the code without requiring for a lot or resources to be consumed. This section provides
an example where testing was deemed to be more efficient and attempts to identify more
cases for which this might be applicable.

\subsection{Mergesort}
The code that follows is an Ada implementation of the top-down version of a well
known sorting algorithm called mergesort.
\lstinputlisting[language=Ada, title=Mergesort's Spec]{Code/tested/mergesort.ads}
\lstinputlisting[language=Ada, title=Mergesort's Body]{Code/tested/mergesort.adb}

\subsection{VectorCAST's tool and testing results}
In order to establish that no errors were introduced during the conversion of the
pseudo-code into source code, a tool called VectorCAST was utilized. VectorCAST
reads the Ada source code and assists in the generation of a test harness.

TODO:  Give a more detailed description of VectorCAST and emphasise that creating the
test harness was effortless, despite using the tool for the first time.

Even thought the tests that were added were very basic (a total of 3 pairs
of inputs and their expected outputs were written), 100\% statement coverage and 96\%
branch coverage was achieved. All tests yielded the expected results.

\subsection{Cases where proof does not add much value}
Well-established algorithms such as A* (A star), quicksort, \etc have
been used by many programmers throughout the years and have been mathematically
shown to hold true. Spending time in annotating the implementations of such algorithms
in order to force them through proof tools is arguably not worth the effort. In such cases,
performing some basic tests to ensure that no porting errors were made should be sufficient.



\section{When proof fails}
Having an accurate contract and a flawlessly annotated implementation, unfortunately,
does not always guarantee that all properties of the code will be fully verified.
Theorem provers are the best option currently available for performing automated
reasoning and even though they improve on a daily basis they are still far from perfect.
This section presents two examples and shows two different courses of action
that a user can follow when proof is not (directly) achievable.

\subsection{Fall back to testings}
\lstinputlisting[language=Ada, title=Spec Of Example One]{Code/proof_failed/example_one/example_one.ads}
\lstinputlisting[language=Ada, title=Body Of Example One]{Code/proof_failed/example_one/example_one.adb}
The given code should be provable with its current annotations but the tools are not
able to discharge the overflow check associated with line 10. Restructuring the code
and/or the annotations could potentially enable the tools to achieve full proof. However,
for this example, due to the simplicity of the code, performing a manual review and writing
some basic tests was deemed to be more cost-effective.

\subsection{Perform a partial proof}
\lstinputlisting[language=Ada, title=Spec Of Example One]{Code/proof_failed/example_two/sorting.ads}
\lstinputlisting[language=Ada, title=Body Of Example One]{Code/proof_failed/example_two/sorting.adb}


\subsection{Points of interest arising from attempting to verify}
When the tools are unable to discharge a verification condition and the
user is confident that the existing annotations should be rendering it provable,
trying the following might help:
\begin{itemize}
  \item Increase the time spent by the prover on each verification condition.

  \item Restructure the code and/or annotations to facilitate proof.
\end{itemize}

Predicting if a prover will be able to discharge a certain verification condition is not
always possible. Results might occasionally even differ between provers. Non the less,
there are certain areas where provers are known to perform well (linear arithmetics) and
other areas where automated proof is harder to achieve (non-linear arithmetics). The more
accustomed a user becomes to the tools, the easier it becomes to predict what will be
automatically provable. Performing proof when it is expected to be easy and testing
the remainder of the code is theorised to be the most time-efficient code-validating
method.



\section{}
\subsection{Example code}
\subsection{Describe approach to verification}
\subsection{Report results of verification}
\subsection{Report any points of interest arising from attempting to verify}

\section{Summary}

\subsection{Can proof and test be practically combined?}

\subsection{Where can the most value be derived?}

\subsection{Additional tooling}
What additional tooling support is required to make it easier/more
generally applicable.


\bibliographystyle{plain}
\bibliography{proof_and_test}

\end{document}
