\section{Introduction}

\subsection{Background}

SPARK is a subset of the Ada programming language targeted at safety- and
security-critical applications. SPARK builds on the strengths of Ada for
creating highly reliable and long-lived software. SPARK restrictions ensure
that the behavior of a SPARK program is unambiguously defined, and simple
enough that formal verification tools can perform an automatic diagnosis of
conformance between a program specification and its implementation. The SPARK
language and toolset for formal verification has been applied over many years
to on-board aircraft systems, control systems, cryptographic systems, and rail
systems~\cite{sparkbook2012,oneill2012}. The latest version, SPARK 2014, builds
on the new specification features added in Ada 2012~\cite{ada2012rationale}, so
formal specifications are now understood by the usual development tools and can
be executed.  The definition of the language subset is motivated by the
simplicity and feasability of formal analysis and the need for an unambiguous
semantics.

Static analysis tools are available that provide flow analysis, symbolic
execution and proof of SPARK programs. The academic tool Bakar
Kiasan~\footnote{\url{http://www.sireum.org/index.html}} developed by Kansas
State University allows executing symbolically a SPARK program with or without
contracts, to detect possible run-time errors and contract violations, and in
some cases also prove that no such errors can occur. The industrial tool
GNATprove~\footnote{\url{http://www.adacore.com/sparkpro}} co-developed by
Altran and AdaCore performs flow analysis to check correct access to data in
the program (correct access to global variables as specified in data and
information flow contracts and correct access to initialized data) and proof to
demonstrate that the program is free from run-time errors and that the
specified contracts are correctly implemented.

\subsection{Motivations}

A major reason for using SPARK for developing critical software is the ability
to prove statically that no run-time error, such as arithmetic overflow, buffer
overflow and division-by-zero, can occur. Besides the additional confidence in
the software that this result brings, it can be used in some certification
domains to lower the verification effort in some other areas like testing. For
example, the most recent version DO-178C of the avionics certification standard
allow using both tests or proofs as acceptable verification
methods~\cite{ieeesoftware2013}. It is also commonly used as an argument to
justify the suppression of run-time checks in the final executable, typically
for getting an increase in execution speed.

The reasonings above rely on the fact that a program proved free of run-time
errors cannot fail a run-time check during execution. This depends on the
correctness of the compiler and analyzers used. Although correctness is not
typically proved for tools used in practice on industrial projects, a special
certification activity aims at giving sufficient confidence that the tools
behave correctly, a process known as tool qualification.

A critical element for the qualification of both the GNAT compiler and the
GNATprove analyzer that we develop at AdaCore is that they correctly interpret
the semantics of SPARK with respect to the placement of checks. The compiler
works by producing first a semantically analyzed abstract syntax tree (AST) of
the program, decorated with flags that point to locations where run-time checks
should be inserted. This AST is then expanded into a lower level representation
with explicit run-time checking code. As the analysis of GNATprove is based off
the same AST used for compilation (using the same compilation
\textit{frontend}), we initially chose to depend on check flags for proof. But
we quickly realized that some flags were missing in the AST, corresponding to
cases where the compiler expansion phase did not depend on these flags for
correct code generation. We temporarily switched to ignoring check flags
completely, which proved unpractical for several reasons: it duplicates the
work already done in the compiler in all analyzers (ours, and as mentioned
below those of our partners), which is both costly and error-prone, and unless
analyzers re-implement the optimizations of the compiler, it leads to useless
checks during analysis, which increases analysis time and memory footprint. For
these reasons, we have since rebased analysis on check flags, after having
precisely identified which check flags were supposed to be set by the frontend,
and modified the frontend to implement this requirement.

Since that last change, the compiler and analyzers all share the AST produced
by the frontend, decorated with check flags that point to locations where
run-time checks should be inserted. But we have discovered in various occasions
cases where flags were missing, which lead to a correction of the frontend. The
last such occasion was the recent implementation of a Tetris in SPARK for a
demo at a customer gathering: after proving that the program was free of
run-time errors, the first test on the actual board stopped unexpectedly due to
a range check failing during execution. There was indeed a possible check
failure in the code (later corrected) on a new attribute recently introduced in
SPARK, which was not detected during proof because the corresponding check flag
was not set by the frontend.

Thus, it is of critical importance to be able to guarantee that all check flags
are set on the AST produced by the frontend, as defined in SPARK language
semantics. This was the main motivation for the work described here.

\subsection{Contributions}
The major contributions of this paper are:
\begin{itemize}
\item The formalization of the dynamic semantics for a core subset of the SPARK
  2014 language in the Coq proof assistant, including scalar subtypes and
  derived types, array types, record types, calls, and locally defined
  subprograms.
\item The formalization of a subset of the run-time checks: overflow checks,
  range checks, array index checks and division by zero checks; and the proof
  of their completeness: if language-defined checks do not fail, a program
  cannot go wrong according to its formal semantics.
\item The proof that existing frontend optimizations that suppress checks only
  do so for checks that cannot fail.
\item The implementation of a tool translating SPARK programs into Coq, and
  automatically checking whether the check flags in the AST produced by the
  GNAT frontend are sufficient to guard against the program going wrong.
\item Experiments where the above tool was applied to small SPARK programs,
  showing that the check flags in the AST were indeed as expected in the
  language semantics.
\end{itemize}
