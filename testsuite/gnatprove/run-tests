#! /usr/bin/env python

from e3.env import Env
from e3.fs import find
from e3.testsuite import logger, Testsuite
from e3.testsuite.control import AdaCoreLegacyTestControlCreator, TestControl
from e3.testsuite.driver import TestDriver
from e3.testsuite.driver.adacore import AdaCoreLegacyTestDriver
from e3.testsuite.testcase_finder import ParsedTest, ProbingError, TestFinder
import e3.yaml
import os
import os.path
import re
import sys
from typing import List

# name for the entry in the test_env dict for the subprogram to call
call_entry = "call_name"
# name for the entry in the test_env dict for arguments to prove_all/do_flow calls
args_entry = "call_args"


class SPARKControlCreator(AdaCoreLegacyTestControlCreator):
    """Class that decides the status (XFAIL, SKIP, etc) of a test. This is the
    same as the standard "test.opt" mechanism, except that we also look into
    the yaml file for the "large" attribute."""

    def create(self, driver: TestDriver) -> TestControl:
        if (
            "large" in self.condition_env
            and self.condition_env["large"]
            and "large" not in self.system_tags
        ):
            return TestControl("large test", skip=True, xfail=False)
        return super().create(driver)

    def __init__(
        self, system_tags: List[str], env=None, opt_filename: str = "test.opt"
    ) -> None:
        super().__init__(system_tags, opt_filename)
        self.condition_env = {} if env is None else env


class ProofTestDriver(AdaCoreLegacyTestDriver):
    """Driver for all SPARK tests. This test generates a test.py if not already
    there. The generated test.py contains a call to the method in
    self.test_env[call_entry], with the arguments in
    self.test_env[args_entry]."""

    copy_test_directory = True

    @property
    def test_control_creator(self):
        assert isinstance(self.env.discs, list)
        return SPARKControlCreator(self.env.discs, self.test_env)

    def get_script_command_line(self):
        script_file = self.working_dir("src", "test.py")
        if not os.path.isfile(script_file):
            assert call_entry in self.test_env
            assert args_entry in self.test_env
            argdict = self.test_env[args_entry]
            with open(script_file, "w") as fn:
                fn.write("from test_support import *" + "\n")
                fn.write("args = " + str(argdict) + "\n")
                fn.write(self.test_env[call_entry] + "(**args)" + "\n")
        self.test_control.opt_results["CMD"] = script_file
        return super().get_script_command_line()


class SPARKTestFinder(TestFinder):
    """Class to find the tests. The [probe] method determines if a folder is a
    valid test. To do that it takes into account various command line arguments
    that allow users to select tests. It also reads the test.yaml file of the
    test if present, and loads it into the test environment. Finally, it sets
    some settings, such as the "call_entry" and "args_entry" fields of the test
    environment."""

    def __init__(self, root_dir, testlist=[], pattern="", only_large=False):
        """
        Initialize a SPARKTestFinder instance.
        """
        self.testlist = testlist
        self.root_dir = root_dir
        self.only_large = only_large
        if pattern:
            self.pattern = re.compile(pattern.encode("utf-8"))
        else:
            self.pattern = None

    def file_contains_regex(self, pattern, fn):
        """
        Return True iff the file [fn] contains [pattern], which is a compiled
        regex.
        """
        with open(fn, "rb") as f:
            for line in f:
                if pattern.search(line):
                    return True
        return False

    def test_contains_pattern(self, test, pattern):
        """
        Return True iff the test contains an .adb/s file that contains
        [pattern], which is a compiled regex.
        """
        return any(
            self.file_contains_regex(pattern, fn) for fn in find(test, "*.ad[bs]")
        )

    def probe(self, testsuite, dirpath, dirnames, filenames):
        """
        See documentation of e3.testsuite for the arguments of this method. We
        check if we consider [dirpath] a valid test of the testsuite, and
        return a ParsedTest object in that case, and [None] otherwise.
        """
        parent_name = os.path.dirname(dirpath)
        testname = os.path.basename(dirpath)
        allowed_testdirs = ["tests", "internal"]
        # If the dir is not a direct subdir of <root_dir/tests>, skip it
        if (
            os.path.basename(parent_name) not in allowed_testdirs
            or os.path.dirname(parent_name) != self.root_dir
        ):
            return None
        # If bogus test dir such as git folder, skip it
        if testname == ".git":
            return None
        # If testlist was passed and the dir is not in testlist, skip it
        if self.testlist and testname not in self.testlist:
            return None
        # If pattern was passed and dir doesn't contain files with the pattern,
        # skip it.
        if self.pattern and not self.test_contains_pattern(dirpath, self.pattern):
            return None

        # We read the test.yaml file if present and load it into the
        # environment
        test_env = None
        try:
            yaml_file = os.path.join(dirpath, "test.yaml")
            if "test.yaml" in filenames:
                test_env = e3.yaml.load_with_config(yaml_file, Env().to_dict())
        except e3.yaml.YamlError:
            raise ProbingError("invalid syntax for test.yaml in '{}'".format(testname))
        if test_env is None:
            test_env = {}

        # If this is not a large test, but only large was requested, skip
        # test
        if self.only_large and "large" not in test_env:
            return None

        # If the test contains a test.py, we use the AdaCoreLegacyTestDriver,
        # otherwise we use the proof/flow driver
        if "test.py" in filenames or "test.cmd" in filenames:
            if "prove_all" in test_env or "do_flow" in test_env:
                logger.warning(
                    '{}: "test.py" file is present, so "prove_all" '
                    'and "do_flow" ignored in "test.yaml"'.format(
                        testname
                    )
                )
        else:
            # if it's a flow test, we set the call to do_flow, and if no
            # do_flow entry is present, we define empty args.
            # We emit a warning if "prove_all" is present
            if "__flow" in testname:
                test_env[call_entry] = "do_flow"
                if "prove_all" in test_env:
                    logger.warning(
                        '{}: "prove_all" in "test.yaml" ignored for flow test'.format(
                            testname
                        )
                    )
                test_env[args_entry] = (
                    test_env["do_flow"] if "do_flow" in test_env else {}
                )
            # same for proof
            else:
                test_env[call_entry] = "prove_all"
                if "do_flow" in test_env:
                    logger.warning(
                        '{}: "do_flow" in "test.yaml" ignored for proof test'.format(
                            testname
                        )
                    )
                test_env[args_entry] = (
                    test_env["prove_all"] if "prove_all" in test_env else {}
                )
        # This is a valid test, return the ParsedTest object
        return ParsedTest(testname, ProofTestDriver, test_env, dirpath)


class SPARKTestsuite(Testsuite):
    """Testsuite for SPARK."""

    @property
    def test_finders(self):
        return [
            SPARKTestFinder(
                self.root_dir,
                testlist=self.testlist,
                pattern=self.main.args.pattern,
                only_large=self.env.only_large,
            )
        ]

    def add_options(self, parser):
        parser.add_argument(
            "--cache", action="store_true", help="Use memcached to run testsuite faster"
        )
        parser.add_argument(
            "--diffs", action="store_true", help="Synonym of --show-error-output/-E"
        )
        parser.add_argument("--disc", type=str, help="discriminants to be used")
        parser.add_argument(
            "--inverse-prover",
            action="store_true",
            help="run testsuite in inverse-prover mode",
        )
        parser.add_argument(
            "--benchmark",
            type=str,
            help="run testsuite in benchmark mode for given prover",
        )
        parser.add_argument(
            "--no-gaia-output",
            action="store_true",
            help="The opposite of --gaia-output (which is on by default).",
        )
        parser.add_argument(
            "--pattern",
            type=str,
            help="Argument is a python regex. Run only tests whose \
                  .adb/ads files match the regex.",
        )
        parser.add_argument(
            "--rewrite",
            action="store_true",
            help="Rewrite test baselines according to current outputs",
        )
        parser.add_argument(
            "--testlist",
            type=str,
            help="Argument is a file which contains one test \
                  name per line. Run only those tests.",
        )
        parser.add_argument(
            "--only-large",
            action="store_true",
            help="Run only large tests; implies --disc=large",
        )

    def compute_environ(self):
        python_lib = os.path.join(self.root_dir, "lib", "python")
        pypath = "PYTHONPATH"
        if pypath in os.environ:
            os.environ["PYTHONPATH"] += os.path.pathsep + python_lib
        else:
            os.environ["PYTHONPATH"] = python_lib
        if self.main.args.cache:
            os.environ["cache"] = "true"
        if self.main.args.inverse_prover:
            os.environ["inverse_prover"] = "true"
        if self.main.args.benchmark:
            os.environ["benchmark"] = self.main.args.benchmark
        return dict(os.environ)

    def set_up(self):
        super(SPARKTestsuite, self).set_up()
        if self.main.args.diffs:
            self.main.args.show_error_output = True
        if not self.main.args.no_gaia_output:
            self.main.args.gaia_output = True
        self.env.discs = self.env.discriminants
        if self.main.args.disc:
            self.env.discs += self.main.args.disc.split(",")
        if self.main.args.inverse_prover:
            self.env.discs += ["inverse-prover"]
        if self.main.args.only_large:
            self.env.only_large = True
            self.env.discs += ["large"]
        else:
            self.env.only_large = False
        self.env.rewrite_baselines = self.main.args.rewrite
        self.env.test_environ = self.compute_environ()
        if self.main.args.testlist:
            with open(self.main.args.testlist, "r") as f:
                self.testlist = [s.strip() for s in f]
        else:
            self.testlist = []


if __name__ == "__main__":
    sys.exit(SPARKTestsuite().testsuite_main())
