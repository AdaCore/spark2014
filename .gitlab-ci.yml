# In this CI, we should only work in reaction to a Merge Request
workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: always

variables:
   # The common part of the URL for cloning from within a CI
   GIT_CLONE_BASE: https://gitlab-ci-token:${CI_JOB_TOKEN}@${CI_SERVER_HOST}:${CI_SERVER_PORT}

   PACKAGE_BASE_NAME: spark2014.tar.gz
   PACKAGE_ABSOLUTE_NAME: $CI_PROJECT_DIR/$PACKAGE_BASE_NAME

stages:
  - build
  - test

###############
# Common bits #
###############

.common_setup_repos: &setup_repos
    # Setup the 'anod vcs' for this repo
    - cd /it/wave
    - anod vcs --add-repo spark2014 $CI_PROJECT_DIR

    # Figure out if we're on a sync branch
    - BRANCH=master
    - if [[ $CI_COMMIT_BRANCH =~ ^sync/ ]]; then
         BRANCH=$CI_COMMIT_BRANCH;
      elif [[ $CI_MERGE_REQUEST_SOURCE_BRANCH_NAME =~ ^sync/ ]]; then
         BRANCH=$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME;
      fi

    # Setup the 'anod vcs' for the other repos.
    # Get them from the default branch, or from the same
    # branch as this if it exists.
    - for subproject in sparklib spark-internal-testsuite why3 ; do
         cd /tmp ;
         git clone $GIT_CLONE_BASE/eng/spark/$subproject ;
         cd $subproject ;
         echo "#### for project $subproject..." ;
         if `git show-ref $BRANCH > /dev/null` ; then
             echo "### ...using branch $BRANCH" ;
             git checkout $BRANCH ;
         else
             echo "### ...using the default branch" ;
         fi ;
         cd /it/wave ;

         anod_name=$subproject ;
         if [ $subproject = "spark-internal-testsuite" ]; then
            anod_name=spark2014-internal-testsuite ;
         fi ;

         anod vcs --add-repo $anod_name /tmp/$subproject ;
      done ;
    # Tune to use our build & test plan
    - anod tune --plan $CI_PROJECT_DIR/plans/ci.plan

.spark2014_test:
  services:
     - image:sandbox
     - cpu:8
     - mem:16
  stage: test
  script:
    # Unpack the artifact then delete it
    - tar zxf $PACKAGE_ABSOLUTE_NAME -C /
    - rm -f $PACKAGE_ABSOLUTE_NAME

    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # Tell anod that the package has already been built
    - mkdir -p fingerprints
    - touch fingerprints/x86_64-linux.spark2014.download_bin.json.assume-unchanged
    - touch fingerprints/x86_64-linux.spark2014.install.json.assume-unchanged

    # Test using anod
    - anod run $ANOD_ENTRY_POINT

    # Process the results
    - e3-testsuite-report
       --failure-exit-code 1
       --xunit-output $CI_PROJECT_DIR/xunit_output.xml
       x86_64-linux/$ANOD_BUILDSPACE/results/new/ || FAILED=true
    - cp -r /it/wave/x86_64-linux/$ANOD_BUILDSPACE/results/new/ $CI_PROJECT_DIR/testsuite-results

    - if [ ! -z ${FAILED+x} ]; then echo "There was at least one testcase failure" && exit 1; fi

  artifacts:
     when: always
     paths:
        - xunit_output.xml
        - testsuite-results
     reports:
       junit: xunit_output.xml

#########
# Build #
#########

build:
  services:
     - image:sandbox
     - cpu:8
     - mem:16
  stage: build
  script:
    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # Build using anod
    - cd /it/wave

    - anod run build

    # Create the package
    - tar czf $PACKAGE_ABSOLUTE_NAME -C /
        it/wave/x86_64-linux/spark2014/install

  artifacts:
    paths:
      - $PACKAGE_BASE_NAME

########
# Test #
########

spark2014:
  extends: .spark2014_test
  when: always
  variables:
    ANOD_ENTRY_POINT: test
    ANOD_BUILDSPACE: spark2014-test

spark2014_large:
  extends: .spark2014_test
  when: manual
  variables:
    ANOD_ENTRY_POINT: test_large
    ANOD_BUILDSPACE: spark2014-test-large

#################
# Test of ACATS #
#################

acats:
  services:
     - image:sandbox
     - cpu:8
     - mem:16
  stage: test
  script:
    # Unpack the artifact then delete it
    - tar zxf $PACKAGE_ABSOLUTE_NAME -C /
    - rm -f $PACKAGE_ABSOLUTE_NAME

    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # also check out acats repo
    - cd /tmp
    - git clone $GIT_CLONE_BASE/eng/toolchain/acats
    - cd /it/wave
    - anod vcs --add-repo acats /tmp/acats;

    # Tell anod that the package has already been built
    - mkdir -p fingerprints
    - touch fingerprints/x86_64-linux.spark2014.download_bin.json.assume-unchanged
    - touch fingerprints/x86_64-linux.spark2014.install.json.assume-unchanged

    # Test using anod
    - anod run test_acats

    # Process the results
    - e3-testsuite-report
       --failure-exit-code 1
       --xunit-output $CI_PROJECT_DIR/xunit_output.xml
       x86_64-linux/acats-4-gnatprove-baseline-test/results/new/ || FAILED=true

    - if [ ! -z ${FAILED+x} ]; then echo "There was at least one testcase failure" && exit 1; fi

  artifacts:
     paths:
        - xunit_output.xml
     reports:
       junit: xunit_output.xml

################
# Build of Doc #
################

build_docs:
  stage: build
  services:
     - image:sandbox
  rules:
    - changes:
      - docs/**/*
      when: always
  artifacts:
    when:
      always
    paths:
      - spark/pdf/spark2014_rm.pdf
      - spark/pdf/spark2014_ug.pdf
      - spark/html/lrm
      - spark/html/ug
  script:
    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # Build using anod
    - cd /it/wave
    - anod build spark2014-doc
    - cp -r /it/wave/x86_64-linux/spark2014-doc/install/share/doc/spark $CI_PROJECT_DIR
