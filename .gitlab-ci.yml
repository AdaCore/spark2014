include:
  - project: eng/codepeer/ci-registry
    file: /gnatsas-on-spark.yml
  - component: $CI_SERVER_FQDN/eng/gitlab-templates/check-issue@~latest
    inputs:
      stage: check
  - component: $CI_SERVER_FQDN/eng/gitlab-templates/pre-commit@~latest
    inputs:
      stage: check

# In this CI, pipelines are triggered when pushing to a Merge Request and when
# merging a MR to a protected branch (only for the gnatsas job).
workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" || ($CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_REF_PROTECTED == "true") || $CI_PIPELINE_SOURCE == "schedule"
      when: always
    # Run on pipelines created by selecting "Run pipeline" in the GitLab UI,
    # from the projectâ€™s "Build > Pipelines" section.
    - if: $CI_PIPELINE_SOURCE == "web"
    - when: never

variables:
   PACKAGE_BASE_NAME: spark2014.tar.gz
   PACKAGE_ABSOLUTE_NAME: $CI_PROJECT_DIR/$PACKAGE_BASE_NAME
   PACKAGE_EXPORT: /tmp/spark2014-export

stages:
  - build
  - test
  - check

###############
# Common bits #
###############

.basic-setup: &setup_repos
    # If the package exists, move it to /tmp so as not to influence "anod vcs"
    - if [ -f $PACKAGE_ABSOLUTE_NAME ] ; then mv $PACKAGE_ABSOLUTE_NAME /tmp ; fi

    # Use generic_anod_ci here.
    - generic_anod_ci $GENERIC_ANOD_CI_OPTIONS
    - cat /tmp/ci_env.sh
    - . /tmp/ci_env.sh

    # Tune to use our build & test plan
    - anod tune --plan $CI_PROJECT_DIR/plans/ci.plan

    # Go to the sandbox dir
    - cd $ANOD_DEFAULT_SANDBOX_DIR

.deploy_package_and_touch_fingerprints: &deploy_package
    # Deploying the package is a two-step process. First we unpack the tarball,
    # by restoring its location at packing time in $PACKAGE_EXPORT.
    # Then we copy the components into the sandbox via anod-copy-components.
    - tar zxf /tmp/$PACKAGE_BASE_NAME -C /
    - anod-copy-components $PACKAGE_EXPORT $ANOD_DEFAULT_SANDBOX_DIR


.spark2014_test:
  services:
     - image:pe-base
     - cpu:16
  stage: test
  script:
    # script to load helper functions for log sections
    - source scripts/ci_predef.sh

    # add internal testsuite for which we want to use most recent
    # sources for testing
    - GENERIC_ANOD_CI_OPTIONS="--add-dep eng/spark/spark-internal-testsuite"

    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # remove gnat from vcs if present for testing; this is allowed to fail when
    # gnat is not present
    - anod vcs --remove gnat || true

    - *deploy_package

    # place cache in proper location; avoid project dir to avoid slowdown of source packaging
    - mkdir -p $CI_PROJECT_DIR/gnatprove_cache
    - mv $CI_PROJECT_DIR/gnatprove_cache /tmp
    - export GNATPROVE_CACHE="file:/tmp/gnatprove_cache"
    # set location of sources for coverage
    - ANOD_BUILDSPACE_SOURCES=`anod eval spark2014-core build_space_name --primitive build --qualifier=coverage,assertions`
    - export COVERAGE_ROOT_DIR=$ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE_SOURCES/src
    - export COVERAGE_SOURCE_DIR=$CI_PROJECT_DIR
    # Test using anod
    - anod run $ANOD_ENTRY_POINT

    # Process the results
    - ANOD_BUILDSPACE=`anod eval spark2014 build_space_name --primitive test --qualifier=$ANOD_QUALIFIERS`
    - testsuite_reports || exit_code=$?
    - mv $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE/results/new/ $CI_PROJECT_DIR/testsuite-results
    - mv $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE/src/cobertura-report/ $CI_PROJECT_DIR/coverage

    # Reestablish cache
    - mv /tmp/gnatprove_cache $CI_PROJECT_DIR/gnatprove_cache

    # Coverage HTML report
    - section_start "coverage_report" "Generate Coverage HTML report"
    - export HTMLTARGETDIR=$CI_COMMIT_BRANCH
    - if [[ $CI_PIPELINE_SOURCE == "merge_request_event" ]]; then export HTMLTARGETDIR=MRs/$CI_MERGE_REQUEST_IID ; fi
    - if [[ $CI_PIPELINE_SOURCE == "schedule" ]]; then export HTMLTARGETDIR=weekly ; fi
    - publish-pages $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE/src/html-report --target-subdir $HTMLTARGETDIR --expires 30
    - section_end "coverage_report"
    - exit $exit_code

  artifacts:
     when: always
     paths:
        - xunit-*.xml
        - testsuite-results
        - coverage/cobertura.xml
     reports:
       junit: xunit-*.xml
       coverage_report:
          coverage_format: cobertura
          path: coverage/cobertura.xml
  cache:
    - key: alwaysthesame
      paths:
        - gnatprove_cache

#########
# Build #
#########

build:
  services:
     - image:pe-base
     - cpu:8
  stage: build
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" || $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - when: never
  script:
    - GENERIC_ANOD_CI_OPTIONS="--add-dep eng/spark/sparklib
                               --add-dep eng/spark/spark-internal-testsuite
                               --add-dep eng/toolchain/gnat
                               --add-dep eng/spark/why3"
    - if [[ $CI_PIPELINE_SOURCE == "schedule" ]]; then GENERIC_ANOD_CI_OPTIONS="$GENERIC_ANOD_CI_OPTIONS --continuous-builder-mode"; fi
    - *setup_repos

    # Build using anod
    - anod run build

    # Create the package
    - SB_WITHOUT_LEADING_SLASH=`echo $ANOD_DEFAULT_SANDBOX_DIR | cut -b2-`
    - anod-copy-components --standalone-export $ANOD_DEFAULT_SANDBOX_DIR $PACKAGE_EXPORT
    - tar czf $PACKAGE_ABSOLUTE_NAME -C/ $PACKAGE_EXPORT

  artifacts:
    paths:
      - $PACKAGE_BASE_NAME

########
# Test #
########

spark2014:
  extends: .spark2014_test
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: always
    - when: never
  variables:
    ANOD_ENTRY_POINT: test
    ANOD_QUALIFIERS: assertions,coverage,cleanup-mode=none,cache

spark2014_large:
  extends: .spark2014_test
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
    - when: never
  allow_failure: true
  variables:
    ANOD_ENTRY_POINT: test_large
    ANOD_QUALIFIERS: assertions,only_large,coverage,cleanup-mode=none,cache

spark2014_nocache:
  extends: .spark2014_test
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - when: never
  allow_failure: true
  variables:
    ANOD_ENTRY_POINT: test_nocache
    ANOD_QUALIFIERS: assertions,coverage,cleanup-mode=none

###############################
# Tests of ACATS and SPARKlib #
###############################

.other_test:
  services:
     - image:pe-base
     - cpu:16
  stage: test
  script:
    - *setup_repos
    - *deploy_package
    - anod run $ANOD_TARGET
    - testsuite_reports

  artifacts:
     paths:
        - xunit-*.xml
        - __results*
     reports:
       junit: xunit-*.xml

acats:
  extends: .other_test
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: always
    - when: never
  variables:
    GENERIC_ANOD_CI_OPTIONS: "--add-dep eng/toolchain/acats"
    ANOD_TARGET: test_acats

sparklib:
  extends: .other_test
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: always
    - when: never
  variables:
    GENERIC_ANOD_CI_OPTIONS: "--add-dep eng/spark/sparklib"
    ANOD_TARGET: test_sparklib

################
# Build of Doc #
################

build_docs:
  stage: build
  services:
     - image:pe-base
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      changes:
        - docs/**/*
      when: always
    - when: never
  artifacts:
    when:
      always
    paths:
      - spark/pdf/spark2014_rm.pdf
      - spark/pdf/spark2014_ug.pdf
      - spark/html/lrm
      - spark/html/ug
  script:
    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # Build using anod
    - anod build spark2014-doc
    - cp -r $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/spark2014-doc/install/share/doc/spark $CI_PROJECT_DIR
    - export HTMLTARGETDIR=$CI_COMMIT_BRANCH
    - if [[ $CI_PIPELINE_SOURCE = "merge_request_event" ]]; then export HTMLTARGETDIR=MRs/$CI_MERGE_REQUEST_IID ; fi
    - publish-pages $CI_PROJECT_DIR/spark/html/lrm --target-subdir doc/lrm/$HTMLTARGETDIR --expires 30
    - publish-pages $CI_PROJECT_DIR/spark/html/ug --target-subdir doc/ug/$HTMLTARGETDIR --expires 30

pre-commit:
  services:
     - image:pe-base
     #Memory is bound to CPU and we need more than the 1Gig that 1 cpu provides
     - cpu:4
  before_script:
    - GENERIC_ANOD_CI_OPTIONS="--add-dep eng/toolchain/gnat"
    - generic_anod_ci $GENERIC_ANOD_CI_OPTIONS
    - cat /tmp/ci_env.sh
    - . /tmp/ci_env.sh
    - cd $ANOD_DEFAULT_SANDBOX_DIR
    - anod install gnat --latest
    - anod install libgpr2 --latest
    - anod install vss-text -Qedge --latest
    - anod install vss-extra -Qedge --latest
    - eval $(anod printenv gnat)
    - eval $(anod printenv libgpr2)
    - eval $(anod printenv vss-text -Qedge)
    - eval $(anod printenv vss-extra -Qedge)
    - mkdir /tmp/sarif-ada
    - e3-cathod source sarif-ada-src --latest --install /tmp/sarif-ada
    - export GPR_PROJECT_PATH=/tmp/sarif-ada/gnat:$GPR_PROJECT_PATH
    - cd $CI_PROJECT_DIR
    - ln -s $ACI_SUBPROJECTS_ROOT/gnat gnat2why/gnat_src
    - make -C gnat2why setup
