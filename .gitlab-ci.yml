# In this CI, we should only work in reaction to a Merge Request
workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: always

variables:
   # The common part of the URL for cloning from within a CI
   GIT_CLONE_BASE: https://gitlab-ci-token:${CI_JOB_TOKEN}@${CI_SERVER_HOST}:${CI_SERVER_PORT}

   PACKAGE_BASE_NAME: spark2014.tar.gz
   PACKAGE_ABSOLUTE_NAME: $CI_PROJECT_DIR/$PACKAGE_BASE_NAME

stages:
  - build
  - test

###############
# Common bits #
###############

.basic-setup: &setup_repos
    # If the package exists, move it to /tmp so as not to influence "anod vcs"
    - if [ -f $PACKAGE_ABSOLUTE_NAME ] ; then mv $PACKAGE_ABSOLUTE_NAME /tmp ; fi

    # Use generic_anod_ci here.
    - generic_anod_ci $GENERIC_ANOD_CI_OPTIONS
    - cat /tmp/ci_env.sh
    - . /tmp/ci_env.sh

    # Tune to use our build & test plan
    - anod tune --plan $CI_PROJECT_DIR/plans/ci.plan

    # Go to the sandbox dir
    - cd $ANOD_DEFAULT_SANDBOX_DIR

.deploy_package_and_touch_fingerprints: &deploy_package
    # Unpack the package
    - tar zxf /tmp/$PACKAGE_BASE_NAME -C /

    # Tell anod that the package has already been built
    - mkdir -p fingerprints
    - COMPONENT=`anod eval spark2014 build_space_name --primitive build --qualifier=coverage,assertions`
    - touch fingerprints/x86_64-linux.$COMPONENT.download_bin.json.assume-unchanged
    - touch fingerprints/x86_64-linux.$COMPONENT.install.json.assume-unchanged


.spark2014_test:
  services:
     - image:e3
     - cpu:8
     - mem:16
  stage: test
  script:
    # Move the package out of the way, so it does not influence "anod vcs"
    - mv $PACKAGE_ABSOLUTE_NAME /tmp

    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # remove gnat from vcs if present for testing; this is allowed to fail when
    # gnat is not present
    - anod vcs --remove gnat || true

    # Do not rebuild spark2014-doc
    - anod install spark2014-doc --latest

    - *deploy_package

    # set caching location
    - mkdir -p $CI_PROJECT_DIR/gnatprove_cache
    - export GNATPROVE_CACHE="file:$CI_PROJECT_DIR/gnatprove_cache"
    # set location of sources for coverage
    - ANOD_BUILDSPACE_SOURCES=`anod eval spark2014 build_space_name --primitive build --qualifier=coverage,assertions`
    - export COVERAGE_ROOT_DIR=$ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE_SOURCES/src
    # Test using anod
    - anod run $ANOD_ENTRY_POINT

    # Process the results
    - ANOD_BUILDSPACE=`anod eval spark2014 build_space_name --primitive test --qualifier=$ANOD_QUALIFIERS`
    - cp -r $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE/results/new/ $CI_PROJECT_DIR/testsuite-results
    - cp -r $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE/src/dhtml-report/ $CI_PROJECT_DIR/coverage
    - testsuite_reports

  artifacts:
     when: always
     paths:
        - xunit-*.xml
        - testsuite-results
        - coverage/cobertura/cobertura.xml
     reports:
       junit: xunit-*.xml
       coverage_report:
          coverage_format: cobertura
          path: coverage/cobertura/cobertura.xml
  cache:
    - key: alwaysthesame
      paths:
        - gnatprove_cache

#########
# Build #
#########

build:
  services:
     - image:e3
     - cpu:8
     - mem:16
  stage: build
  script:
    - GENERIC_ANOD_CI_OPTIONS="--add-dep eng/spark/sparklib
                               --add-dep eng/spark/spark-internal-testsuite
                               --add-dep eng/spark/why3"
    - *setup_repos

    # Build using anod
    - anod run build

    # Create the package
    - SB_WITHOUT_LEADING_SLASH=`echo $ANOD_DEFAULT_SANDBOX_DIR | cut -b2-`
    - PACKNAME=`anod info build spark2014 --show build_space --qualifier=assertions,coverage`
    - tar czf $PACKAGE_ABSOLUTE_NAME -C /
        $SB_WITHOUT_LEADING_SLASH/x86_64-linux/$PACKNAME/install

  artifacts:
    paths:
      - $PACKAGE_BASE_NAME

issue_present:
  services:
     - image:e3
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
  stage: build
  script:
    - require_issue

########
# Test #
########

spark2014:
  extends: .spark2014_test
  when: always
  variables:
    ANOD_ENTRY_POINT: test
    ANOD_QUALIFIERS: assertions,coverage,cleanup-mode=none,cache

spark2014_large:
  extends: .spark2014_test
  when: manual
  variables:
    ANOD_ENTRY_POINT: test_large
    ANOD_QUALIFIERS: assertions,only_large,coverage,cleanup-mode=none,cache

#################
# Test of ACATS #
#################

acats:
  services:
     - image:e3
     - cpu:8
     - mem:16
  stage: test
  script:
    # Setup the sanbox
    # Add acats explicitly for this build.
    - GENERIC_ANOD_CI_OPTIONS="--add-dep eng/toolchain/acats"
    - *setup_repos

    # Deploy the installed package
    - *deploy_package

    # Test using anod
    - anod run test_acats

    # Process the results
    - testsuite_reports

  artifacts:
     paths:
        - xunit-*.xml
     reports:
       junit: xunit-*.xml

################
# Build of Doc #
################

build_docs:
  stage: build
  services:
     - image:e3
  rules:
    - changes:
      - docs/**/*
      when: always
  artifacts:
    when:
      always
    paths:
      - spark/pdf/spark2014_rm.pdf
      - spark/pdf/spark2014_ug.pdf
      - spark/html/lrm
      - spark/html/ug
  script:
    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # Build using anod
    - anod build spark2014-doc
    - cp -r $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/spark2014-doc/install/share/doc/spark $CI_PROJECT_DIR
