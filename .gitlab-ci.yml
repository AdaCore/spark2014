include:
  - project: eng/codepeer/ci-registry
    file: /gnatsas-on-spark.yml

# In this CI, pipelines are triggered when pushing to a Merge Request and when
# merging a MR to a protected branch (only for the gnatsas job).
workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" || ($CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_REF_PROTECTED == "true") || $CI_PIPELINE_SOURCE == "schedule"
      when: always
    # Run on pipelines created by selecting "Run pipeline" in the GitLab UI,
    # from the projectâ€™s "Build > Pipelines" section.
    - if: $CI_PIPELINE_SOURCE == "web"
    - when: never

variables:
   PACKAGE_BASE_NAME: spark2014.tar.gz
   PACKAGE_ABSOLUTE_NAME: $CI_PROJECT_DIR/$PACKAGE_BASE_NAME

stages:
  - build
  - test
  - check

###############
# Common bits #
###############

.basic-setup: &setup_repos
    # If the package exists, move it to /tmp so as not to influence "anod vcs"
    - if [ -f $PACKAGE_ABSOLUTE_NAME ] ; then mv $PACKAGE_ABSOLUTE_NAME /tmp ; fi

    # Use generic_anod_ci here.
    - generic_anod_ci $GENERIC_ANOD_CI_OPTIONS
    - cat /tmp/ci_env.sh
    - . /tmp/ci_env.sh

    # Tune to use our build & test plan
    - anod tune --plan $CI_PROJECT_DIR/plans/ci.plan

    # Go to the sandbox dir
    - cd $ANOD_DEFAULT_SANDBOX_DIR

.deploy_package_and_touch_fingerprints: &deploy_package
    # Unpack the package
    - tar zxf /tmp/$PACKAGE_BASE_NAME -C /

    # Tell anod that the package has already been built
    - mkdir -p fingerprints
    - COMPONENT=`anod eval spark2014 build_space_name --primitive build --qualifier=coverage,assertions`
    - touch fingerprints/x86_64-linux.$COMPONENT.download_bin.json.assume-unchanged
    - touch fingerprints/x86_64-linux.$COMPONENT.install.json.assume-unchanged


.spark2014_test:
  services:
     - image:pe-base
     - cpu:16
  stage: test
  script:
    # Move the package out of the way, so it does not influence "anod vcs"
    - mv $PACKAGE_ABSOLUTE_NAME /tmp

    # add sparklib and internal testsuite for which we want to use most recent
    # sources for testing
    - GENERIC_ANOD_CI_OPTIONS="--add-dep eng/spark/sparklib
                               --add-dep eng/spark/spark-internal-testsuite"

    - if [[ $CI_PIPELINE_SOURCE == "schedule" ]]; then GENERIC_ANOD_CI_OPTIONS="$GENERIC_ANOD_CI_OPTIONS --continuous-builder-mode"; fi

    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # remove gnat from vcs if present for testing; this is allowed to fail when
    # gnat is not present
    - anod vcs --remove gnat || true

    # Do not rebuild spark2014-doc
    - anod install spark2014-doc --latest

    - *deploy_package

    # set caching location
    - mkdir -p $CI_PROJECT_DIR/gnatprove_cache
    - export GNATPROVE_CACHE="file:$CI_PROJECT_DIR/gnatprove_cache"
    # set location of sources for coverage
    - ANOD_BUILDSPACE_SOURCES=`anod eval spark2014-core build_space_name --primitive build --qualifier=coverage,assertions`
    - export COVERAGE_ROOT_DIR=$ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE_SOURCES/src
    - export COVERAGE_SOURCE_DIR=$CI_PROJECT_DIR
    # Test using anod
    - anod run $ANOD_ENTRY_POINT

    # Process the results
    - ANOD_BUILDSPACE=`anod eval spark2014 build_space_name --primitive test --qualifier=$ANOD_QUALIFIERS`
    - cp -r $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE/results/new/ $CI_PROJECT_DIR/testsuite-results
    - cp -r $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE/src/cobertura-report/ $CI_PROJECT_DIR/coverage

    - testsuite_reports
    # Coverage HTML report
    - export HTMLTARGETDIR=$CI_COMMIT_BRANCH
    - if [[ $CI_PIPELINE_SOURCE == "merge_request_event" ]]; then export HTMLTARGETDIR=MRs/$CI_MERGE_REQUEST_IID ; fi
    - if [[ $CI_PIPELINE_SOURCE == "schedule" ]]; then export HTMLTARGETDIR=weekly ; fi
    - publish-pages $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/$ANOD_BUILDSPACE/src/html-report --target-subdir $HTMLTARGETDIR --expires 30
    - 'echo "Coverage report: https://pages.gitlab.adacore-it.com/eng/spark/spark2014/$HTMLTARGETDIR/index.html"'

  artifacts:
     when: always
     paths:
        - xunit-*.xml
        - testsuite-results
        - coverage/cobertura.xml
     reports:
       junit: xunit-*.xml
       coverage_report:
          coverage_format: cobertura
          path: coverage/cobertura.xml
  cache:
    - key: alwaysthesame
      paths:
        - gnatprove_cache

#########
# Build #
#########

build:
  services:
     - image:pe-base
     - cpu:8
  stage: build
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" || $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - when: never
  script:
    - GENERIC_ANOD_CI_OPTIONS="--add-dep eng/spark/sparklib
                               --add-dep eng/spark/spark-internal-testsuite
                               --add-dep eng/toolchain/gnat
                               --add-dep eng/spark/why3"
    - if [[ $CI_PIPELINE_SOURCE == "schedule" ]]; then GENERIC_ANOD_CI_OPTIONS="$GENERIC_ANOD_CI_OPTIONS --continuous-builder-mode"; fi
    - *setup_repos

    # Build using anod
    - anod run build

    # Create the package
    - SB_WITHOUT_LEADING_SLASH=`echo $ANOD_DEFAULT_SANDBOX_DIR | cut -b2-`
    - PACKNAME=`anod info build spark2014 --show build_space --qualifier=assertions,coverage`
    - tar czf $PACKAGE_ABSOLUTE_NAME -C /
        $SB_WITHOUT_LEADING_SLASH/x86_64-linux/$PACKNAME/install

  artifacts:
    paths:
      - $PACKAGE_BASE_NAME

issue_present:
  services:
     - image:pe-base
  stage: check
  needs: [] # Execute regardless of the other stages
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: always
    - when: never
  script:
    - require_issue

precommit_checks:
  stage: check
  needs: [] # Execute regardless of the other stages
  services:
    - image:e3
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: always
    - when: never
  script:
    - /it/bin/set_git_config.sh
    - python -mvenv /tmp/venv
    - . /tmp/venv/bin/activate
    - python -mpip install pre-commit
    - cd $CI_PROJECT_DIR
    - pre-commit run -a --show-diff-on-failure

########
# Test #
########

spark2014:
  extends: .spark2014_test
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: always
    - when: never
  variables:
    ANOD_ENTRY_POINT: test
    ANOD_QUALIFIERS: assertions,coverage,cleanup-mode=none,cache

spark2014_large:
  extends: .spark2014_test
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
    - when: never
  allow_failure: true
  variables:
    ANOD_ENTRY_POINT: test_large
    ANOD_QUALIFIERS: assertions,only_large,coverage,cleanup-mode=none,cache

spark2014_nocache:
  extends: .spark2014_test
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: manual
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - when: never
  allow_failure: true
  variables:
    ANOD_ENTRY_POINT: test_nocache
    ANOD_QUALIFIERS: assertions,coverage,cleanup-mode=none

#################
# Test of ACATS #
#################

acats:
  services:
     - image:pe-base
     - cpu:16
  stage: test
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: always
    - when: never
  script:
    # Setup the sanbox
    # Add acats explicitly for this build.
    - GENERIC_ANOD_CI_OPTIONS="--add-dep eng/toolchain/acats"
    - *setup_repos

    # Deploy the installed package
    - *deploy_package

    # Test using anod
    - anod run test_acats

    # Process the results
    - testsuite_reports

  artifacts:
     paths:
        - xunit-*.xml
        - __results*
     reports:
       junit: xunit-*.xml

################
# Build of Doc #
################

build_docs:
  stage: build
  services:
     - image:pe-base
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      changes:
        - docs/**/*
      when: always
    - when: never
  artifacts:
    when:
      always
    paths:
      - spark/pdf/spark2014_rm.pdf
      - spark/pdf/spark2014_ug.pdf
      - spark/html/lrm
      - spark/html/ug
  script:
    # Setup the "anod vcs as appropriate"
    - *setup_repos

    # Build using anod
    - anod build spark2014-doc
    - cp -r $ANOD_DEFAULT_SANDBOX_DIR/x86_64-linux/spark2014-doc/install/share/doc/spark $CI_PROJECT_DIR
    - export HTMLTARGETDIR=$CI_COMMIT_BRANCH
    - if [[ $CI_PIPELINE_SOURCE = "merge_request_event" ]]; then export HTMLTARGETDIR=MRs/$CI_MERGE_REQUEST_IID ; fi
    - publish-pages $CI_PROJECT_DIR/spark/html/lrm --target-subdir doc/lrm/$HTMLTARGETDIR --expires 30
    - publish-pages $CI_PROJECT_DIR/spark/html/ug --target-subdir doc/ug/$HTMLTARGETDIR --expires 30
    - 'echo "SPARK LRM: https://pages.gitlab.adacore-it.com/eng/spark/spark2014/doc/ug/$HTMLTARGETDIR/index.html"'
    - 'echo "SPARK UG: https://pages.gitlab.adacore-it.com/eng/spark/spark2014/doc/lrm/$HTMLTARGETDIR/index.html"'
